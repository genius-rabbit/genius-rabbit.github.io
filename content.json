{"meta":{"title":"Delta","subtitle":"技术是纯净的","description":"吾之所向 一往无前 愈挫愈勇 再接再厉","author":"delta","url":"https://www.delta1037.cn"},"pages":[{"title":"About","date":"2017-08-23T10:22:54.000Z","updated":"2019-08-03T13:37:22.316Z","comments":false,"path":"about/index.html","permalink":"https://www.delta1037.cn/about/index.html","excerpt":"","text":"bio座右铭吾志所向 一往无前 愈挫愈勇 再接再厉 GitHub deltaRabbit Email geniusrabbit@qq.com geniusrabbit.liubo@gmail.com School High school:立洋外国语学校 School:华中科技大学 Home home:河南 My Blog 博客站点"}],"posts":[{"title":"CentOS 6安装gitlab服务端","slug":"CentOS-6安装gitlab服务端","date":"2019-10-18T07:58:34.000Z","updated":"2019-10-18T07:59:31.374Z","comments":true,"path":"2019/10/18/CentOS-6安装gitlab服务端/","link":"","permalink":"https://www.delta1037.cn/2019/10/18/CentOS-6安装gitlab服务端/","excerpt":"","text":"一、配置基础环境1234yum install openssh-serveryum install postfixservice postfix startchkconfig postfix on 二、下载安装gitlabgitlab安装包下载地址：centos 6系统的下载地址:https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6centos 7系统的下载地址:https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7安装：1rpm -i gitlab-ce-9.5.9-ce.0.el6.x86_64.rpm 三、配置gitlab修改gitlab配置文件指定服务器ip和自定义端口，将external_url后面的值修改为http://ip:port（例如http://192.168.7.89:8010，如果不指定端口则是默认的端口80）1vim /etc/gitlab/gitlab.rb 如果服务端开启了防火墙，则需要开放相应的端口1iptables -I INPUT -p tcp --dport 8010 -j ACCEPT 按照新的配置文件重新配置gitlab，并重新启动12gitlab-ctl reconfiguregitlab-ctl restart 查看gitlab运行状态12345678910111213141516gitlab-ctl status# 得到如下输出run: gitaly: (pid 10798) 24009s; run: log: (pid 4490) 24327srun: gitlab-monitor: (pid 10820) 24009s; run: log: (pid 5099) 24297srun: gitlab-workhorse: (pid 10824) 24008s; run: log: (pid 4654) 24321srun: logrotate: (pid 24622) 2407s; run: log: (pid 4894) 24309srun: nginx: (pid 10887) 24007s; run: log: (pid 4803) 24315srun: node-exporter: (pid 10896) 24007s; run: log: (pid 5007) 24303srun: postgres-exporter: (pid 10908) 24006s; run: log: (pid 5383) 24279srun: postgresql: (pid 10918) 24006s; run: log: (pid 3780) 24391srun: prometheus: (pid 10926) 24005s; run: log: (pid 5271) 24285srun: redis: (pid 10943) 24005s; run: log: (pid 3615) 24398srun: redis-exporter: (pid 10947) 24005s; run: log: (pid 5181) 24291srun: sidekiq: (pid 10959) 24004s; run: log: (pid 4393) 24333srun: unicorn: (pid 10987) 24003s; run: log: (pid 4292) 24339s bug0:`GLIBC_2.14’ not found如果出现报错/lib64/libc.so.6: version `GLIBC_2.14’ not found，则需要升级glibc1234567891011121314# 下载安装包wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gztar zxvf glibc-2.14.tar.gzcd glibc-2.14mkdir buildcd build# 编译安装../configure --prefix=/opt/glibc-2.14make -j4make install# 设置链接库目录export LD_LIBRARY_PATH=/opt/glibc-2.14/lib","categories":[],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://www.delta1037.cn/tags/gitlab/"},{"name":"CentOS","slug":"CentOS","permalink":"https://www.delta1037.cn/tags/CentOS/"}]},{"title":"Install Oracle Database 9i on CentOS 5 (i386)","slug":"Install-Oracle-Database-9i-on-CentOS-5-i386","date":"2019-10-14T03:17:38.000Z","updated":"2019-10-14T03:18:49.031Z","comments":true,"path":"2019/10/14/Install-Oracle-Database-9i-on-CentOS-5-i386/","link":"","permalink":"https://www.delta1037.cn/2019/10/14/Install-Oracle-Database-9i-on-CentOS-5-i386/","excerpt":"","text":"Oracle Database 9i的官方安装环境为RHEL3，RHEL4。由于项目需要，需要同时安装Oracle Database 9i和日志采集工具rsyslog，rsyslog仅支持RHEL/CENTOS 5及其以上的版本，最终在CentOS 5 (i386)版本上安装成功。 一、软件下载： Oracle9i Database Release 2 Enterprise/Standard Edition for Intel Linux（ship_9204_linux_disk）：迅雷 百度网盘提取码：ve9y 补丁： compat-libcwait-2.1-1.i386.rpm compat-oracle-rhel4-1.0-5.i386.rpm j2re-1_3_1_19-linux-i586.bin 二、开始安装1、关闭SELinux12gedit /etc/selinux/configset SELINUX=disabled 2、 安装JRE123chmod +x j2re-1_3_1_19-linux-i586.bin./j2re-1_3_1_19-linux-i586.binmv jre1.3.1_19 /usr/local/ 3、安装缺少的依赖1234567891011121314151617181920# 检查依赖缺失rpm -q compat-db compat-gcc-34 compat-gcc-34-c++ \\ compat-libgcc-296 compat-libstdc++-296 compat-libstdc++-33 \\ gcc gcc-c++ glibc glibc-common glibc-devel glibc-headers libgcc make libXp# 使用yum安装依赖yum install compat-db*yum install compat-gcc*yum install gcc*yum install compat-libgcc*yum install compat-libstdc++*yum install gnome-libs*yum install libaio*yum install openmotif*yum install xorg-x11-deprecated-libs*yum install glibc-devel*# 安装补丁rpm -Uvh compat-libcwait-2.1-1.i386.rpmrpm -Uvh compat-oracle-rhel4-1.0-5.i386.rpm --nodeps 4、配置环境123456cd /usr/libln -s libstdc++-3-libc6.2-2-2.10.0.so libstdc++-libc6.1-1.so.2ln -s libgdbm.so.2.0.0 libdb.so.2cd /usr/binln -s gcc34 gcc32 5、添加oracle组和用户1234groupadd oinstall #添加oinstall组groupadd dba # 添加dba组useradd -g oinstall -G dba oracle #新建用户并添加到组passwd oracle #按照输出设置密码 6、建立安装目录123456cd /optmkdir oracle # 创建oracle目录chown –R oracle.oinstall oracle #修改oracle目录权限cd oraclemkdir 920 # 创建9i安装目录 7、 配置环境变量和系统设置以oracle用户登陆，打开/u01/oracle/.bash_profile，在文件末尾追加如下内容1234567891011121314ORACLE_BASE=/opt/oracle; export ORACLE_BASEORACLE_HOME=$ORACLE_BASE/920; export ORACLE_HOMEORACLE_SID=orcl; export ORACLE_SIDLD_LIBRARY_PATH=$ORACLE_HOME/lib; export LD_LIBRARY_PATHORACLE_OEM_JAVARUNTIME=/usr/local/jre1.3.1_19; export ORACLE_OEM_JAVARUNTIMEPATH=$PATH:$ORACLE_HOME/bin; export PATHif [ $USER = \"oracle\" ]; then if [ $SHELL = \"/bin/ksh\" ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fifi 以root用户登陆，打开/etc/sysctl.conf，在文件末尾追加如下内容，并执行sysctl -p生效12345678kernel.shmmni = 4096kernel.sem = 250 32000 100 128fs.file-max = 65536net.ipv4.ip_local_port_range = 1024 65000net.core.rmem_default=262144net.core.wmem_default=262144net.core.rmem_max=262144net.core.wmem_max=262144 打开/etc/security/limits.conf，在文件末尾追加如下内容1234oracle soft nofile 65536oracle hard nofile 65536oracle soft nproc 16384oracle hard nproc 16384 8、文件准备a）从网上下载oracle Database 9i有三个文件123ship_9204_linux_disk1.cpio.gzship_9204_linux_disk2.cpio.gzship_9204_linux_disk3.cpio.gz b）对压缩文件解压123gunzip ship_9204_linux_disk1.cpio.gzgunzip ship_9204_linux_disk2.cpio.gzgunzip ship_9204_linux_disk3.cpio.gz c）使用如下命令解压得到Disk1、Disk2和Disk3文件夹123cpio -idmv &lt; ship_9204_linux_disk1.cpiocpio -idmv &lt; ship_9204_linux_disk2.cpiocpio -idmv &lt; ship_9204_linux_disk3.cpio 9、 开始安装进入Disk1目录，执行./ runInstaller开始图形界面的安装程序，选择自己喜欢的版本进行安装，一路next就可以 备注：1、终端界面可能出现Inside isCluster, bCluster bfr return is : false，不影响后续使用2、在最后的configuration阶段会发生错误如下 此时退出安装程序，进行如下操作 1234567cd $ORACLE_HOMErm JREln -s $ORACLE_BASE/jre/1.3.1 JREcd JRE/binln -s java jrecd i386/native_threads/ln -s java jre 然后再执行./ runInstaller走一遍安装流程即可 三、使用1、建立数据库进入/u01/oracle/product/bin目录，运行dbca命令，进入建立数据库的图形界面，根据界面提示进行操作 2、使用过程中可能会遇到的问题a）startup 出现LRM-00109: could not open parameter file …：12cd /opt/oracle /admin/sxf/pfile #sxf是dbca新建的数据库名cp init.ora.* /opt/oracle/920/dbs/initmyoracle.ora b）startup出现ORA-01990: error opening password file ‘/opt/oracle/920/dbs/orapw’12cd /opt/oracle/920/binorapwd file=/opt/oracle/920/dbs/orapw passwd=sxf123 entries=1024 四、个人经验1、以CentOS 5（x86_64）无法完成amd64_db_9204_Disk1.cpio.gz的安装2、以CentOS 4（x86_64）可以完成amd64_db_9204_Disk1.cpio.gz的安装 五、参考文献1、Installing Oracle 9i on RHEL5. (x86)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"Oracle Database 9i","slug":"Oracle-Database-9i","permalink":"https://www.delta1037.cn/tags/Oracle-Database-9i/"},{"name":"CentOS 5","slug":"CentOS-5","permalink":"https://www.delta1037.cn/tags/CentOS-5/"}]},{"title":"Linux启动过程分析","slug":"Linux启动过程分析","date":"2019-10-14T03:09:25.000Z","updated":"2019-10-14T03:16:23.398Z","comments":true,"path":"2019/10/14/Linux启动过程分析/","link":"","permalink":"https://www.delta1037.cn/2019/10/14/Linux启动过程分析/","excerpt":"","text":"第一阶段-BIOS计算机通电后，首先会区读取ROM芯片中的开机程序（基本输入输出系统/BIOS） 1.1 硬件自检BIOS程序首先检查计算机硬件是否满足运行的基本条件–硬件自检（POST） CMOS：存储硬件的各项参数。 1.2 启动顺序硬件自检完成后，BIOS把控制权交给下一阶段的启动程序。 这时，BIOS需要知道下一阶段的启动程序在哪个设备，也就是BIOS需要有一个外部存储设备排序，排在前边的设备就是优先转交控制权的设备。这个排序叫启动顺序。 第二阶段-主引导记录BIOS把控制权交给排在第一位的存储设备。 计算机读取此设备的第一个扇区（最前边的512个字节，叫做主引导记录），如果这个扇区最后两个字节是0x55和0xAA，表明设备可以启动；如果不是，表明设备不能启动，控制权交给启动顺序中的下一个 设备。 2.1 主引导记录结构 范围/字节 作用 1-446 调用操作系统的机器码 447-510 分区表：将磁盘分为若干个区 511-512 主引导记录签名 2.2 分区表考虑到每个区可以安装不同的操作系统，主引导记录必须知道将控制权交给哪个区。 分区表长度有64个字节，里面分为四项（所以一个硬盘最多有四个一级分区，又叫主分区），每一项16个字节 主分区16个字节组成： 范围/字节 作用 1-1 如果为0x80，就表示该分区是激活分区，控制权要交给这个分区。四个分区里面只能有一个是激活的 2-4 主分区第一个扇区的物理位置（柱面、磁头、扇区号） 5-5 主分区类型 6-8 主分区最后一个扇区的物理位置 9-12 该主分区第一个扇区的逻辑地址 13-16 主分区的扇区总数 第三阶段-硬盘启动这时，计算机的控制权就交给了硬盘的某个分区了 3.1 情况A：卷引导记录计算机会读取激活分区的第一个扇区，叫做卷引导记录（Volume boot record，VBR） 卷引导记录告诉计算机，操作系统在这个分区的位置。然后计算机就会加载操作系统了。 3.2 情况B：扩展分区和逻辑分区随着硬盘越来越大，四个分区已经不够了，需要更多分区。于是规定有一个分区可以定义为扩展分区（里面又分了好多个区，叫逻辑分区）。 计算机首先读取扩展分区的第一个扇区，叫扩展引导记录（EBR）。它里面包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区，包括它自身的分区表和下一个分区的分区表）。从里面找到第二个逻辑分区的位置，直到找到一个分区里面只包含它自己的分区表为止。 3.3 情况C：启动管理器在这种情况下，计算机读取主引导记录前446个字节的机器码之后，不把控制权交给某一个分区，而是运行启动管理器（boot loader），由用户选择启动哪一个操作系统。 Linux环境中，最流行的启动管理器是Grub。 第四阶段-操作系统控制权交给操作系统之后，操作系统的内核首先载入内存。 所有进程的祖先叫进程0，idle进程，或者由于历史的原因叫做swapper进程。 start_kernel()函数初始化内核需要的所有数据结构，激活终端，创建另一个叫做进程1的内核线程（一般叫做init进程），创建init进程之后，进程0执行cpu_idle()函数，该函数本质上是在开中断的情况下重复之星hlt汇编指令。当 没有其他进程处于TASK_RUNNING才选择执行进程0。 多处理器系统中每个CPU都有一个进程0，计算机启动之后首先启动一个CPU，禁用其他CPU，swapper进程进程初始化内核数据结构，通过copy_process()函数创建另外的swapper进程。 进程0创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init，结果init内核线程变成了一个普通进程。 以Linux系统为例，首先载入/boot目录下面的kernel。内核加载成功后（如上），第一个运行的程序是/sbin/init，它根据配置文件产生init进程，pid进程编号为1，其它进程都是它的后代。 然后init进程加载系统的各个模块，比如窗口和网络程序，直到/bin/login程序，跳出登录页面。 参考文献 计算机是如何启动的 深入理解Linux内核","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"Linux启动","slug":"Linux启动","permalink":"https://www.delta1037.cn/tags/Linux启动/"}]},{"title":"点石成金，挥刀琢玉——“双创老太”刘玉那些事儿","slug":"英雄会刘老师介绍","date":"2019-08-21T11:14:55.000Z","updated":"2019-08-21T14:01:27.314Z","comments":true,"path":"2019/08/21/英雄会刘老师介绍/","link":"","permalink":"https://www.delta1037.cn/2019/08/21/英雄会刘老师介绍/","excerpt":"","text":"点石成金，挥刀琢玉——“双创老太”刘玉那些事儿 高调、爱折腾、不走寻常路、犀利、“毒舌”、超级大忙人，她是被贴满标签的华中大教授——刘玉老师。而其中最响亮，最广为人知的标签，一定非“双创老太”莫属。今天，让我们走近这神秘的刘玉教授，说一说，她的那些事儿—— 她是谁—— 湖北省创业红娘众创空间 负责人 武汉创业红娘公益服务中心 理事长 华中科技大学 电信学院 教 授 华中科技大学 Dian团队 创始人 她都做过什么—— 扶弟子创新 曾指导本科生获全国挑战杯特等奖，Dian团队育人模式获国家教学成果二等奖，教育部大学生创新性实验计划的“源头”之一，央视小崔说事栏目曾以“点亮未来”专题报道，曾应邀到全国高校、中学、企事业等逾百家单位作创新创业报告，引起强烈反响。曾获评“全国师德先进个人”和湖北省“五一劳动奖章”、湖北省教育系统“三育人”奖、 宝钢优秀教师特等奖的提名奖、两次获华中科技大学教学质量优秀一等奖。 在她严格要求和精心培养下，Dian团队出站队员500多人在社会上总体表现优异，近7年涌现出50余家创业公司，其中贝贝网和贝店已成为独角兽，释码大华、ping++、悦然心动等创业公司业绩斐然，4人荣登福布斯中国30位“30岁以下创业者”榜单。 帮他人创业 2015年3月，刘玉创办“武汉市洪山区创业红娘公益服务中心”，义务为优秀创业项目与投资机构牵线搭桥，创业项目的甄选范围从华中科技大学在校生拓宽至全社会，不分地域、不分年龄、不分学校、不分学历。至今，经刘玉老师推荐的创业项目已超过500个，融资成交率13.2%，促成投资总额2.57亿元。 她的那些事儿—— 刘玉:创客点睛手——《长江日报》 创新潜能在实践中尽情释放——《中国教育报》网络版 人民网专访“创业红娘”刘玉：如何做到人靠谱、事落实、有情怀 刘玉：被“强推转身”的创业红娘——《中国青年报》 全国布撒“姻缘线”的“创业红娘” ——武汉首个创业服务公益机构实录——《长江日报》 武汉女教授入选“中国好人” 免费孵出50多家公司——荆楚网 华科Dian团队15年走出10余家“过亿”企业——人民网 崔永元“说事”设“圈套” 女教授均“化险为夷”——中国政协新闻网 “点”下种子——访谈华中科技大学“点团队”创始人刘玉教授——《大学生》 华科创客点睛手刘玉讲述：张小龙在武汉首提微信产品观——荆楚网 刘延东寄语Dian团队———在实践中释放创新潜能 华中科大教授刘玉：人才标准固化扼杀大学生创新热情——《中国青年报》 华中科技大学刘玉教授：未来工程师“点”亮江城","categories":[{"name":"团队","slug":"团队","permalink":"https://www.delta1037.cn/categories/团队/"}],"tags":[{"name":"test","slug":"test","permalink":"https://www.delta1037.cn/tags/test/"}]},{"title":"编译总结","slug":"compile","date":"2019-08-03T11:16:31.000Z","updated":"2019-09-04T00:48:03.826Z","comments":true,"path":"2019/08/03/compile/","link":"","permalink":"https://www.delta1037.cn/2019/08/03/compile/","excerpt":"","text":"编译 一、系统环境 CPU：Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz 操作系统：Ubuntu 18.04.2 LTS 内核版本：Linux version 4.18.0-25-generic GNU GCC版本：gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) C standard revision：C11 GNU Compiled BY GMP version： 6.1.2 MPFR version ：4.0.1 MPC version ： 1.1.0 isl version ： isl-0.19-GMP GNU 汇编器版本：2.30 (x86_64-linux-gnu) using BFD version (GNU Binutils for Ubuntu) 2.30 链接器版本： collect2 version：7.4.0 gcc一般是collect2,而不是ld，collect2 是ld链接器的一个封装，最终还是调用ld来完成链接工作 collect2通过第一次链接程序查看链接器输出文件来查找具有特定名称表明是构造函数的符号，如果找得到则会创建一个新的临时‘.c’文件包含这些符号，然后编译这个文件并第二次链接程序.The program collect2 works by linking the program once and looking through the linker output file for symbols with particular names indicating they are constructor functions. If it finds any, it creates a new temporary ‘.c’ file containing a table of them, compiles it, and links the program a second time including that file.） GNU ld (GNU Binutils for Ubuntu)：2.30 二、GCC编译过程2.1 GCC编译过程 预处理 删除所有的#define，展开所有的宏定义 处理所有的条件预编译指令&lt;#if,#endif,#ifdef,#ifndef,#elif,#else&gt; 处理#include预编译指令，将包含的文件插入到include的位置（递归进行） 删除所有的注释 添加行号和文件名标识（调试时使用） 保留所有的#pragma编译器指令（编译器需要使用这些指令） 1234567# 单独产生预处理后的文件（本模块假设hello.c是源代码程序,hello.i是hello.c预处理后的文件,hello.s是hello.c编译后的文件，hello.o是hello.c汇编后的文件，hello是hello.c最终的可执行程序）# 使用gcc命令产生预处理文件$ gcc -E hello.c -o hello.i# 使用cpp命令产生预处理文件$ cpp hello.c &gt; hello.i 编译：将预处理完的文件进行一系列的词法分析、语法分析、语义分析、中间代码生成、目标代码生成与优化之后产生相应的汇编代码文件 词法分析：扫描器运行类似于有限状态机的算法将代码的字符序列分割成一系列的记号 语法分析：语法分析器对扫描器产生的记号进行语法分析，从而产生语法树（以表达式为节点的树） 语义分析：语义分析器确定语句的意义（比如两个指针做乘法是没有意义的），编译器只能分析静态语义（在编译时能够确定的语义，通常包括声明和类型的匹配，类型的转换；与之相对的动态语义是在运行时才能确定的语义，例如将0作为除数是一个运行期语义错误） 12345678# 编译预处理后的文件产生汇编代码文件$ gcc -S hello.i -o hello.s# 编译源文件产生汇编代码文件$ gcc -S hello.c -o hello.s# 现在的gcc编译器将预处理和编译两个步骤合成了一个步骤，使用一个叫cc1的程序来完成这个过程$ /usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o hello.s 汇编：将汇编代码转变成机器可以执行的指令（根据汇编指令和机器指令的对照表一一翻译） 12345678# 使用as处理汇编文件产生目标文件$ as hello.s -o hello.o# 使用gcc处理汇编文件产生目标文件$ gcc -c hello.s -o hello.o# 使用gcc处理源文件产生目标文件$ gcc -c hello.c -o hello.o 链接：将目标文件链接到一起形成可执行文件,主要包括地址和空间分配，符号决议，和重定位等步骤 符号决议：也叫做符号绑定、名称绑定、名称决议等等。从细节上来讲，决议更倾向于静态链接，绑定更倾向与动态链接 重定位：编译一个文件时不知道一个要调用的函数或者需要操作的一个变量的地址，就会把这些调用函数或者操作变量的指令目标地址搁置，等到最后链接的时候由链接器去将这些指令的目标地址修正，这个地址修正的过程也被叫做重定位，每一个需要修正的地方叫做重定位入口。 2.2 实际编译过程 使用如下样例，包含hello.c和func.c两个源文件（之后也是用这两个文件进行分析） 123456789101112131415161718192021222324252627282930313233343536373839/* hello.c：主测试程序，包括全局静态变量，局部静态变量，全局变量，局部变量，基本的函数调用 */// export varextern int export_func_var;// global varint global_uninit_var;int global_init_var_0 = 0;int global_init_var_1 = 1;// const varconst char *const_string_var = \"const string\";// static global varstatic int static_global_uninit_var;static int static_global_init_var_0 = 0;static int static_global_init_var_1 = 1;// func headervoid func_call_test(int num);int main(void)&#123; // local var int local_uninit_var; int local_init_var_0 = 0; int local_init_var_1 = 1; // static local var static int static_local_uninit_var; static int static_local_init_var_0 = 0; static int static_local_init_var_1 = 1; // call func func_call_test(8); // export var op export_func_var = export_func_var * 2; return 0;&#125; 123456/* func.c：包含一个简单的被调用函数和一个全局变量 */int export_func_var = 666;void func_call_test(int num)&#123; int double_num = num * 2;&#125; 使用gcc -v hello.c func.c编译生成可执行文件a.out，产生如下输出（简化版本） 1234567891011121314[delta@delta: code ]$ gcc -v func.c hello.c# 对func.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 func.c -o /tmp/ccfC6J5E.s# 对func.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/ccF4Bar0.o /tmp/ccfC6J5E.s# 对hello.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o /tmp/ccfC6J5E.s# 对hello.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/cc7UmhQl.o /tmp/ccfC6J5E.s# 链接过程/usr/lib/gcc/x86_64-linux-gnu/7/collect2 -dynamic-linker ld-linux-x86-64.so.2 Scrt1.o crti.o crtbeginS.o /tmp/ccF4Bar0.o /tmp/cc7UmhQl.o crtendS.o crtn.o 三、链接过程解析Q: 目标文件的格式是怎样的？ 多个目标是如何链接到一起的？ 3.1 目标文件3.1.1目标文件类型 Window下的PE（Portable Executable） Linux下的ELF（Executable Linkable Format） 注： PE和ELF格式都是COFF（Common file format）格式的变种 目标文件与可执行文件的内容和结构类似，所以一般采用相同的格式存储。广义上来可以将目标文件和可执行文件看做是同一种类型的文件，在window下统称它们为PE-COFF文件格式，在Linux下统称它们为ELF文件。 不止是可执行文件按照可执行文件格式存储，动态链接库（DLL，Dynamic Linking Library）（Window的.dll和Linux的.so）以及静态链接库（Static Linking Library）（Window的.lib和Linux的.a）文件都按照可执行文件的格式存储。（静态链接库稍有不同，它是把很多的目标文件捆绑在一起形成一个文件，再加上一些索引。可以理解为一个包含很多目标文件的文件包） 3.1.2 ELF文件类型 ELF文件类型 说明 实例 可重定位文件（Relocatable File） 包含代码和数据，可以被用来链接成可执行文件或者共享目标文件，静态链接库可以归为这一类 Linux的.o，Window下的.obj 可执行文件（Executable File） 包含可以直接执行的程序，一般没有扩展名 Linux的/bin/bash文件，Window的.exe 共享目标文件（Shared Object File） 包含代码和数据，链接器可以上映这种文件与其他可重定位文件和共享目标文件进行链接产生新的目标文件；动态链接器可以将几个共享目标文件与可执行文件结合，作为进程映像的一部分来运行 Linux的.so，Window的.dll 核心转储文件（Core Dump File） 进程意外终止时，系统将该进程的地址空间的内容以及终止时的其它信息转储到核心转储文件 Linux下的core dump 3.1.3目标文件结构目标文件中包含编译后的指令代码、数据，还包括了链接时需要的一些信息（符号表，调试信息和字符串等），一般目标文件将这些信息按照不同的属性，以节（Section）的形式存储（有时也称为段（Segment)）。如下图所示 3.1.3.1常见的段 段名 说明 .text/.code 代码段，编译后的机器指令 .data 数据段，全局变量和局部静态变量 .bss 未初始化的全局变量和局部静态变量（.bss段只是为未初始化的全局变量和局部静态变量预留位置） .rodata 只读信息段 .rodata1 存放只读数据，字符串常量，全局const变量。与.rodata一样 .comment 编译器版本信息 .debug 调试信息 .dynamic 动态链接信息 .hash 符号哈希表 .line 调试时的行号表，即源代码行号与编译后的指令的对应表 .note 额外的编译器信息。程序的公司名，发布版本号 .strtab String Table，字符串表，用来存储ELF文件中用到的各种字符串 .symtab Symbol Table，符号表 .shstrtab Section String Table，段名表 .plt/.got 动态链接的跳转表和全局入口表 .init/.fini 程序初始化与终结代码段 3.1.3.2目标文件结构分析 ELF文件头： 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -h hello.o读取目标文件的ELF文件头，可以看出ELF文件头定义了ELF魔数、文件机器字节长度、数据存储方式、版本，运行平台、ABI版本、ELF重定位类型、硬件平台、硬件平台版本、入口地址、程序入口和长度、段表的位置和长度及段的数量等，如下图所示 1234567891011121314151617181920ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 1328 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 15 Section header string table index: 14 ELF文件头结构体定义在/usr/include/elf.h中，目标文件hello.o的文件头中机器字节长度为ELF64，找到64位版本文件头结构体Elf64_Ehdr定义，如下所示 1234567891011121314151617typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; 除结构体中的e_ident对应到readelf输出的从Magic到ABI Version部分，其它都是一一对应关系 e_shstrndx变量表示.shstrtab在段表中的下标 段表 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -S hello.o读取目标文件的段表部分 1234567891011121314151617181920212223242526272829303132333435363738Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000035 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000440 0000000000000048 0000000000000018 I 12 1 8 [ 3] .data PROGBITS 0000000000000000 00000078 000000000000000c 0000000000000000 WA 0 0 4 [ 4] .bss NOBITS 0000000000000000 00000084 0000000000000014 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 00000084 000000000000000d 0000000000000000 A 0 0 1 [ 6] .data.rel.local PROGBITS 0000000000000000 00000098 0000000000000008 0000000000000000 WA 0 0 8 [ 7] .rela.data.rel.lo RELA 0000000000000000 00000488 0000000000000018 0000000000000018 I 12 6 8 [ 8] .comment PROGBITS 0000000000000000 000000a0 000000000000002c 0000000000000001 MS 0 0 1 [ 9] .note.GNU-stack PROGBITS 0000000000000000 000000cc 0000000000000000 0000000000000000 0 0 1 [10] .eh_frame PROGBITS 0000000000000000 000000d0 0000000000000038 0000000000000000 A 0 0 8 [11] .rela.eh_frame RELA 0000000000000000 000004a0 0000000000000018 0000000000000018 I 12 10 8 [12] .symtab SYMTAB 0000000000000000 00000108 0000000000000240 0000000000000018 13 16 8 [13] .strtab STRTAB 0000000000000000 00000348 00000000000000f6 0000000000000000 0 0 1 [14] .shstrtab STRTAB 0000000000000000 000004b8 0000000000000076 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) 段表结构体定义在/usr/include/elf.h中，目标文件hello.o的文件头中机器字节长度为ELF64，找到64位版本段表结构体定义Elf64_Shdr（每个Elf64_Shdr对应一个段，Elf64_Shdr又称为段描述符），如下所示 12345678910111213typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; Elf64_Shdr部分成员解释 变量名 说明 sh_name 段名是一个字符串，位于一个叫.shstrtab的字符串表中，sh_name是段名字符串在.shstrtab中的偏移 sh_addr 段虚拟地址，如果该段可以加载，sh_addr为该段被加载后在进程地址空间的虚拟地址，否则为0 sh_offset 段偏移，如果该段存在于文件中则表示该段在文件中的偏移，否则无意义 sh_link、sh_info 段链接信息，如果该段的类型是与链接相关的，则该字段有意义 sh_addralign 段地址对齐，sh_addralign表示是地址对齐数量的指数，如果sh_addralign为0或者1则该段没有字节对齐要求 sh_entsize 对于一些段包含了一些固定大小的项，比如符号表，则sh_entsize表示每个项的大小 重定位表：hello.o中包含一个.rela.text的段，类型为RELA，它是一个重定位表。链接器在处理目标文件时必须对文件中的某些部位进行重定位，这些重定位信息都记录在重定位表中。对于每个需要重定位的代码段或者数据段，都会有一个相应的重定位表。 字符串表 .strtab：字符串表，保存普通的字符串，比如符号的名字 .shstrtab：段表字符串表，保存段表中用到的字符串，比如段名 结论：ELF文件头中的e_shstrndx变量表示.shstrtab在段表中的下标，e_shoff表示段表在文件中的偏移，只有解析ELF文件头，就可以得到段表和段表字符串表的位置，从而解析整个ELF文件 3.1.4 链接的接口——符号3.1.4.1 符号定义 定义：在链接中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量地址的引用。在链接中，将函数和变量统称为符号（Symbol），函数名或变量名称为符号名（Symbol Name）。 每个目标文件都有一个符号表记录了目标文件中用到的所有符号（每个定义的符号都有一个符号值，对于函数和变量来说，符号值就是它们的地址），常见分类如下 符号类型 说明 定义在本目标文件中的全局符号 可以被其它目标文件引用的符号 在本目标文件中引用的符号，却没有定义在本目标文件中 外部符号（External Symbol） 段名，由编译器产生 它的值就是该段的起始地址 局部符号 只在编译单元内部可见，链接器往往忽略它们 行号信息 目标文件指令与代码行的对应关系，可选 3.1.4.2 符号结构分析 符号表结构：符号表结构体定义在/usr/include/elf.h中，如下所示 123456789typedef struct&#123; Elf64_Word st_name; /* Symbol name (string tbl index) */ unsigned char st_info; /* Symbol type and binding */ unsigned char st_other; /* Symbol visibility */ Elf64_Section st_shndx; /* Section index */ Elf64_Addr st_value; /* Symbol value */ Elf64_Xword st_size; /* Symbol size */&#125; Elf64_Sym; Elf64_Sym成员解释 变量名 说明 st_name 符号名在字符串表中的下标 st_info 符号类型和绑定信息 st_other 符号可见性 st_shndx 符号所在的段 st_value 符号对应的值 st_size 符号大小 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -s hello.o读取目标文件的符号表部分 1234567891011121314151617181920212223242526Symbol table '.symtab' contains 24 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS hello.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000000 0 SECTION LOCAL DEFAULT 6 7: 0000000000000004 4 OBJECT LOCAL DEFAULT 4 static_global_uninit_var 8: 0000000000000008 4 OBJECT LOCAL DEFAULT 4 static_global_init_var_0 9: 0000000000000004 4 OBJECT LOCAL DEFAULT 3 static_global_init_var_1 10: 0000000000000008 4 OBJECT LOCAL DEFAULT 3 static_local_init_var_1.1 11: 000000000000000c 4 OBJECT LOCAL DEFAULT 4 static_local_init_var_0.1 12: 0000000000000010 4 OBJECT LOCAL DEFAULT 4 static_local_uninit_var.1 13: 0000000000000000 0 SECTION LOCAL DEFAULT 9 14: 0000000000000000 0 SECTION LOCAL DEFAULT 10 15: 0000000000000000 0 SECTION LOCAL DEFAULT 8 16: 0000000000000004 4 OBJECT GLOBAL DEFAULT COM global_uninit_var 17: 0000000000000000 4 OBJECT GLOBAL DEFAULT 4 global_init_var_0 18: 0000000000000000 4 OBJECT GLOBAL DEFAULT 3 global_init_var_1 19: 0000000000000000 8 OBJECT GLOBAL DEFAULT 6 const_string_var 20: 0000000000000000 53 FUNC GLOBAL DEFAULT 1 main 21: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 22: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND func_call_test 23: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND export_func_var 1234567注： 1. static_global_uninit_var、static_local_init_var_0和static_local_uninit_var、static_global_init_var_0和global_init_var_0在bss段（因为初始化为0和不初始化是一样的） 2. static_global_init_var_1、static_local_init_var_1和global_init_var_1在data段（初始化的全局变量） 3. static变量的类型均为LOCAL，表明该符号只为该目标文件内部可见；非Static全局变量的类型为GLOBAL，表明该符号外部可见 4. 在hello.c中引用了func_call_test和export_func_var符号，但是没有定义，所以它的Ndx是UND（注：export一个变量但是并未使用则符号表中不会出现这个边浪符号信息；export一个不存在的变量但是并未使用编译不会报错；export一个不存在的变量并使用会报错 &lt;**注意系统环境**&gt; ） 5. 未初始化的全局非静态变量global_uninit_var在COM块中 6. const_string_var在.data.rel.local段中 特殊符号：当使用链接器生成可执行文件时，会定义很多特殊的符号，这些符号并未在程序中定义，但是可以直接声明并引用它们 3.1.4.3 符号修饰与函数签名​ 符号修饰与函数签名：在符号名前或者后面加上_修饰符号，防止与库文件和其它目标文件冲突。现在的linux下的GCC编译器中，默认情况下去掉了加上_这种方式，可以通过参数选项打开 C++符号修饰：C++拥有类，继承，重载和命名空间等这些特性，导致符号管理更为复杂。例如重载的情况：函数名相同但是参数不一样。然后就有了符号修饰和符号改编的机制，使用函数签名（包括函数名，参数类型，所在的类和命名空间等信息）来识别不同的函数 C++符号修饰栗子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class C &#123; public: int func(int); class C2 &#123; public: int func(int); &#125;;&#125;;namespace N &#123; int func(int); class C &#123; public: int func(int); &#125;;&#125;int func(int num)&#123; return num;&#125;float func(float num)&#123; return num;&#125;int C::func(int num)&#123; return num;&#125;int C::C2::func(int num)&#123; return num;&#125;int N::func(int num)&#123; return num;&#125;int N::C::func(int num)&#123; return num;&#125;int main()&#123; int int_res = func(1); float float_var = 1.1; float float_res = func(float_var); C class_C; int_res = class_C.func(1); return 0;&#125; 使用g++ -c hello.cpp -o hello_cpp.o编译产生目标文件hello_cpp.o，使用readelf -a hello_cpp.o查看目标文件中的符号表，如下 1234567891011121314151617181920Symbol table '.symtab' contains 18 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS hello.cpp 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000000 0 SECTION LOCAL DEFAULT 7 7: 0000000000000000 0 SECTION LOCAL DEFAULT 8 8: 0000000000000000 0 SECTION LOCAL DEFAULT 6 9: 0000000000000000 12 FUNC GLOBAL DEFAULT 1 _Z4funci 10: 000000000000000c 16 FUNC GLOBAL DEFAULT 1 _Z4funcf 11: 000000000000001c 16 FUNC GLOBAL DEFAULT 1 _ZN1C4funcEi 12: 000000000000002c 16 FUNC GLOBAL DEFAULT 1 _ZN1C2C24funcEi 13: 000000000000003c 12 FUNC GLOBAL DEFAULT 1 _ZN1N4funcEi 14: 0000000000000048 16 FUNC GLOBAL DEFAULT 1 _ZN1N1C4funcEi 15: 0000000000000058 119 FUNC GLOBAL DEFAULT 1 main 16: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 17: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND __stack_chk_fail 可以看出函数签名与修饰后的名称的对应关系 函数签名 修饰后名称（符号名） int func(int) _Z4funci float func(float) _Z4funcf int C::func(int) _ZN1C4funcEi int C::C2::func(int) _ZN1C2C24funcEi int N::func(int) _ZN1N4funcEi int N::C::func(int) _ZN1N1C4funcEi extern “C”：C++编译器会将在extern C大括号内的内部代码当做C语言代码处理，也就是名称修饰机制将不会起作用。当需要兼容C和C++，例如在C++代码中调用C中的memset函数，可以使用C++的宏__cplusplus，C++在编译程序时会默认定义这个宏 123456789#ifdef __cplusplusextern “C” &#123;#endifvoid *memset(void *, int, size_t); #ifdef __cplusplus&#125;#endif 由于不同的编译器采用不同的名字修饰方法，必然会导致不同编译器产生的目标文件无法正常互相链接，这是导致不同编译器之间不能互操作的原因 3.1.4.4 弱符号与强符号​ 在编程中经常遇到符号重定义的问题，例如hello.c和func.c都定义了一个_global并将它们都初始化，在编译时就会报错。对于C/C++来说，编译器默认函数和初始化的全局变量为强符号，未初始化的全局变量为弱符号。 编译器处理符号规则 不允许强符号被多次定义 如果一个符号在一个文件中是强符号，在其它文件中是弱符号，则选择强符号 如果一个符号在所有的文件中都是弱符号，则选择其中占用空间最大的一个（int型和double型会选择double型） 弱引用与强引用：对外部目标文件中的符号引用在目标文件最终被链接成可执行文件时都哟啊被正确决议，如果没有找到该符号的定义，则会报未定义错误，这种被称为强引用；与之对应的弱引用，在处理弱引用时，如果该符号有定义，则链接器将该符号的引用决议；如果该符号未被定义，则链接器也不会报错。 弱符号与弱引用的作用（对库来说很有用） 库中定义的弱符号可以被用户定义的强符号所覆盖，从而使程序可以使用自定义版本的函数 程序可以对某些扩展功能模块的引用定义为弱引用，当扩展模块与程序链接到一起时，功能模块可以正常使用；如果去掉了某些功能模块，则程序也可以正常链接，只是缺少了相应的功能，这使得程序的功能更容易裁剪和组合 3.2 静态链接3.2.1 空间和地址分配链接器在合并多个目标文件的段时，采用相似段合并的方式，并分配地址和空间（虚拟地址空间的分配） 两步链接法： 空间和地址分配：扫描所有的目标文件，获得它们的各个段的长度、属性和位置，并且将输入目标文件中的符号表中所有的符号定义和符号引用收集起来，统一放到一个全局符号表，这一步中，链接器将能够获得所有输入目标文件的段长度，并将它们合并，计算输出文件中各个合并之后的段的长度，建立映射关系。 符号解析与重定位：使用空间和地址分配中收集到的所有信息，读取输入文件中段的数据、重定位信息，并且进行符号解析与重定位、调整代码中的地址等。 当进行了空间和地址分配之后，各个段的虚拟地址也就确定了，由于各个符号在段内的位置是相对的，所以各个符号的地址也就确定了。 3.2.2 符号解析与重定位 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用objdump -d hello.o读取目标文件的.text的反汇编结果，如下所示（简略部分内容）；同理使用gcc -c func.c -o func.o生成目标文件func.o。 12345678910111213141516[delta@rabbit: c_code ]$ objdump -d hello.oDisassembly of section .text:0000000000000000 &lt;main&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: c7 45 f8 00 00 00 00 movl $0x0,-0x8(%rbp) f: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) 16: bf 08 00 00 00 mov $0x8,%edi 1b: e8 00 00 00 00 callq 20 &lt;main+0x20&gt; 20: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 26 &lt;main+0x26&gt; 26: 01 c0 add %eax,%eax 28: 89 05 00 00 00 00 mov %eax,0x0(%rip) # 2e &lt;main+0x2e&gt; 2e: b8 00 00 00 00 mov $0x0,%eax 33: c9 leaveq 34: c3 retq 分析：由以上结果可以看出，在链接之前，main函数在调用func_call_test函数时，使用的地址是0x00000000，根据反汇编结果就是下一条指令（e8 00 00 00 00之中e8是callq的指令码，00 00 00 00是目的地址相对于下一条指令的偏移量）；在使用export_func_var变量时，编译器就将0x0看做是export_func_var的地址 使用ld hello.o func.o -e main链接两个目标文件，生成可执行文件a.out（并不能执行，因为缺少部分目标文件，但是符号已经被重新定位；-e main表示将main函数作为程序入口），使用objdump -d a.out查看a.out的.text段反汇编结果，如下图所示（简略部分内容） 123456789101112131415161718192021222324252627[delta@rabbit: c_code ]$ objdump -d a.out Disassembly of section .text:00000000004000e8 &lt;main&gt;: 4000e8: 55 push %rbp 4000e9: 48 89 e5 mov %rsp,%rbp 4000ec: 48 83 ec 10 sub $0x10,%rsp 4000f0: c7 45 f8 00 00 00 00 movl $0x0,-0x8(%rbp) 4000f7: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) 4000fe: bf 08 00 00 00 mov $0x8,%edi 400103: e8 15 00 00 00 callq 40011d &lt;func_call_test&gt; 400108: 8b 05 0a 0f 20 00 mov 0x200f0a(%rip),%eax # 601018 &lt;export_func_var&gt; 40010e: 01 c0 add %eax,%eax 400110: 89 05 02 0f 20 00 mov %eax,0x200f02(%rip) # 601018 &lt;export_func_var&gt; 400116: b8 00 00 00 00 mov $0x0,%eax 40011b: c9 leaveq 40011c: c3 retq 000000000040011d &lt;func_call_test&gt;: 40011d: 55 push %rbp 40011e: 48 89 e5 mov %rsp,%rbp 400121: 89 7d ec mov %edi,-0x14(%rbp) 400124: 8b 45 ec mov -0x14(%rbp),%eax 400127: 01 c0 add %eax,%eax 400129: 89 45 fc mov %eax,-0x4(%rbp) 40012c: 90 nop 40012d: 5d pop %rbp 40012e: c3 retq 使用nm a.out查看a.out中的符号信息（简略），可以看到export_func_var的地址为0000000000601018 12[delta@rabbit: c_code ]$ nm a.out 0000000000601018 D export_func_var 分析：在链接之后，可以从反汇编中看出main函数的调用func_call_test函数的地方地址已经被修正为func_call_test真正的地址000000000040011d，使用export_func_var变量的地方的地址也修正为export_func_var真正的地址0000000000601018（在nm a.out输出的符号表中）。所以链接器在完成地址空间分配之后就可以确定所有符号的虚拟地址了，链接器就可以根据符号的地址对每个需要重定位的地方进行地址修正。 链接器如何知道哪些地址需要修正呢？有一个重定位表的结构专门保存与重定位相关的信息（比如.text如果有需要重定位的地方，那么就会有一个叫.rela.text的段保存了代码段的重定位信息），使用objdump -r hello.o查看重定位信息如下（简略），可以看到所有需要重定位的地方 123456[delta@rabbit: c_code ]$ objdump -r hello.o RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE 000000000000001c R_X86_64_PLT32 func_call_test-0x00000000000000040000000000000022 R_X86_64_PC32 export_func_var-0x0000000000000004000000000000002a R_X86_64_PC32 export_func_var-0x0000000000000004 符号解析：使用nm hello.o可以查看hello.o 中所有的符号信息，如下所示，可以看到export_func_var和func_call_test符号都是未定义状态（U）。所以档链接器扫描完所有的输入目标文件之后，所有的这些未定义的符号都能够在全局符号表中找到，否则就会报符号未定义（undefined reference to）错误。 12345678910111213141516# 输出hello.o 中所有的符号信息[delta@rabbit: c_code ]$ nm hello.o 0000000000000000 D const_string_var U export_func_var U func_call_test0000000000000000 B global_init_var_00000000000000000 D global_init_var_1 U _GLOBAL_OFFSET_TABLE_0000000000000004 C global_uninit_var0000000000000000 T main0000000000000008 b static_global_init_var_00000000000000004 d static_global_init_var_10000000000000004 b static_global_uninit_var000000000000000c b static_local_init_var_0.18090000000000000008 d static_local_init_var_1.18100000000000000010 b static_local_uninit_var.1808 1234567# 符号未定义错误[delta@rabbit: c_code ]$ ld hello.o ld: warning: cannot find entry symbol _start; defaulting to 00000000004000e8hello.o: In function `main':hello.c:(.text+0x1c): undefined reference to `func_call_test'hello.c:(.text+0x22): undefined reference to `export_func_var'hello.c:(.text+0x2a): undefined reference to `export_func_var' 指令修正方式：（A：保存正在修正位置的值；P：被修正的位置&lt;相对于段开始的偏移量或者虚拟地址&gt;；S：符号的实际地址；L：表示其索引位于重定位条目中的符号的值）以下计算参考 12345678910111213# hello.o中的重定位信息（简略）[delta@rabbit: c_code ]$ objdump -r hello.o RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE 000000000000001c R_X86_64_PLT32 func_call_test-0x00000000000000040000000000000022 R_X86_64_PC32 export_func_var-0x0000000000000004000000000000002a R_X86_64_PC32 export_func_var-0x0000000000000004# 解析：# 根据输出符号的重定位类型有R_X86_64_PLT32和R_X86_64_PC32# R_X86_64_PLT32 ： L + A - P（绝对地址修正）# R_X86_64_PC32 ： S + A - P（相对寻址修正）# 其它方式参考：http://www.ucw.cz/~hubicka/papers/abi/node19.html 绝对地址修正：绝对地址修正后的地址为该符号的实际地址，例如调用func_call_test符号的地址被修正成为了绝对地址40011d 相对地址修正：相对地址修正后的地址为符号距离被修正位置的地址差，例如使用export_func_var符号的地址被修正成为了相对地址0x200f0a，mov指令（第一个mov指令）的下一条地址40010e加上这个偏移量0x200f0a就是export_func_var的绝对地址0x601018 COMMON块：根据nm hello.o的输出，如下所示（简略），可以看到global_uninit_var符号的类型为COMMON类型，编译器将未初始化的全局变量作为弱符号处理 12[delta@rabbit: c_code ]$ nm hello.o 0000000000000004 C global_uninit_var 多个符号定义类型情况分析 两个或以上强符号类型不一致：报重定义错误 有一个强符号和多个弱符号：取强符号，若是有弱符号比强符号空间大的情况则编译时会出现warning 两个或者以上弱符号类型不一致：取占用空间最大的弱符号 注：当编译器将一个编译单元编译成目标文件时，如果该编译单元包含弱符号（未初始化或者初始化为0的全局变量是典型），那么该符号所占用的最终空间就是不确定的，所以编译器无法在该阶段为该符号在BSS段分配空间。但是经过链接之后，任何一个符号的大小都确定了，所以它可以在最终输出文件的BSS段为其分配空间。总体来看，未初始化的全局变量是放在BSS段的 3.2.3 静态库链接 定义：静态库可以简单地看做是一组目标文件的集合，即很多目标文件经过压缩打包后形成的一个文件（Linux上常用的C语言静态库libc位于/usr/lib/x86_64-linux-gnu/libc.a） 静态链接过程：在链接过程中ld链接器会自动寻找所有需要的符号以及它们所在的目标文件，将这些目标文件从libc.a中“解压”出来，最终将它们链接到一起形成一个可执行文件。使用gcc -v hello.c func.c编译生成可执行文件a.out，可以看到详细的链接过程，产生如下输出（简化版本） 123456789101112131415161718192021222324[delta@delta: code ]$ gcc -v func.c hello.c# 对func.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 func.c -o /tmp/ccfC6J5E.s# 对func.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/ccF4Bar0.o /tmp/ccfC6J5E.s# 对hello.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o /tmp/ccfC6J5E.s# 对hello.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/cc7UmhQl.o /tmp/ccfC6J5E.s# 链接过程/usr/lib/gcc/x86_64-linux-gnu/7/collect2 -dynamic-linker ld-linux-x86-64.so.2 Scrt1.o crti.o crtbeginS.o /tmp/ccF4Bar0.o /tmp/cc7UmhQl.o crtendS.o crtn.o############################################# 实际各个目标文件的位置/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o/usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o/tmp/ccF4Bar0.o/tmp/cc7UmhQl.o/usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o 可以看到Scrt1.o crti.o crtbeginS.o /tmp/ccF4Bar0.o /tmp/cc7UmhQl.o crtendS.o crtn.o被链接入了最终可执行文件 各个文件的解释（来源） 目标文件 说明 crt0.o Older style of the initial runtime code ? Usually not generated anymore with Linux toolchains, but often found in bare metal toolchains. Serves same purpose as crt1.o (see below). crt1.o Newer style of the initial runtime code. Contains the _start symbol which sets up the env with argc/argv/libc _init/libc _fini before jumping to the libc main. glibc calls this file ‘start.S’. crti.o Defines the function prolog; _init in the .init section and _fini in the .fini section. glibc calls this ‘initfini.c’. crtn.o Defines the function epilog. glibc calls this ‘initfini.c’. scrt1.o Used in place of crt1.o when generating PIEs. gcrt1.o Used in place of crt1.o when generating code with profiling information. Compile with -pg. Produces output suitable for the gprof util. Mcrt1.o Like gcrt1.o, but is used with the prof utility. glibc installs this as a dummy file as it’s useless on linux systems. crtbegin.o GCC uses this to find the start of the constructors. crtbeginS.o Used in place of crtbegin.o when generating shared objects/PIEs. crtbeginT.o Used in place of crtbegin.o when generating static executables. crtend.o GCC uses this to find the start of the destructors. crtendS.o Used in place of crtend.o when generating shared objects/PIEs. 通常链接顺序： 1crt1.o crti.o crtbegin.o [-L paths] [user objects] [gcc libs] [C libs] [gcc libs] crtend.o crtn.o 链接过程控制：链接过程需要考虑很多内容：使用哪些目标文件？使用哪些库文件？是否保留调试信息、输出文件格式等等。 链接器控制链接过程方法： 使用命令行来给链接器指定参数 将链接器指令存放在目标文件里面，编译器通常会使用这种方式向链接器传递指令。 使用链接控制脚本 3.2.4 BFD库简介 定义：由于现代的硬件和软件平台种类繁多，每个平台都有不同的目标文件格式，导致编译器和链接器很难处理不同平台的目标文件。BFD库（Binary File Descriptor library）希望通过统一的接口来处理不同的目标文件格式。 现代GCC（具体来讲是GNU 汇编器GAS）、链接器、调试器和GDB及binutils的其他工具都是通过BFD库来处理目标文件，而不是直接操作目标文件。 3.3 装载与动态链接3.3.1可执行文件的装载 进程的虚拟地址空间：每个程序运行起来之后，它将拥有自己独立的虚拟地址空间，这个虚拟地址空间的大小由计算机的硬件平台决定，具体来说是CPU的位数决定（32位平台下的虚拟空间为4G&lt;2^32&gt;，通过cat /proc/cpuinfo可以看到虚拟地址的位数，如本机为address sizes : 39 bits physical, 48 bits virtual，虚拟地址位数为48位，则虚拟空间为2^48）。 进程只能使用操作系统分配给进程的地址，否则系统会捕获到这些访问并将其关闭（Window：进程因非法操作需要关闭；Linux：Segment Fault段错误） 装载的方式：程序运行时是有局部性原理的，所以可以将程序最常用的部分驻留在内存中，将不常用的数据存放在磁盘里（动态装入的基本原理） 覆盖装入（几乎被淘汰）：覆盖装入的方法吧挖掘内存潜力的任务交给了程序员，程序员在编写程序时将程序分为若干块，然后编写一个辅助代码来管理这些这些模块何时应该驻留内存，何时应该被替换掉（在多个模块的情况下，程序员需要手工将它们之间的依赖关系组织成树状结构） 页映射：页映射不是一下子将指令和数据一下子装入内存，而是将内存和磁盘中的所有数据和指令按照页（Page）为单位划分，之后所有的装载和操作的单位就是页。 操作系统角度来看可执行文件的加载： 创建一个独立的虚拟地址空间：创建映射函数所需要的对应的数据结构 读取可执行文件头，建立虚拟空间和可执行文件的映射关系：程序在发生页错误时，操作系统从物理空间分配出来一个物理页，然后将“缺页”从磁盘读取到内存中，并设置缺页的虚拟页与物理页的映射关系，很明显，操作系统捕获到缺页错误时，它应该知道当前所需要的页在可执行文件的哪一个位置。这就是虚拟空间与可执行文件之间的映射关系（这种映射关系只是保存在操作系统内部的一个数据结构，Linux中将进程虚拟空间中的一个段叫做虚拟内存区域（VMA））。 将CPU的指令寄存器设置成可执行文件的入口地址，启动运行 注：页错误处理： CPU将控制权交给操作系统 操作系统查询装载过程 第二部建立起来的数据结构，找到空白页所在的VMA，计算出相应页面在可执行文件中的便宜，然后在物理内存中分配一个物理页面，将进程中该虚拟地页与分配的物理页之间建立映射关系 把控制权还给进程 3.3.2 动态链接 为什么需要动态链接：1、静态链接方式对于计算机内存和磁盘空间的浪费非常严重；2、静态链接库对程序的更新部署会带来很多麻烦（如果其中一个依赖进行了更新，那么该程序就要重新链接发布） 动态链接：将链接的过程推迟到了运行的时候再进行，通过动态链接器（第二部分GCC编译过程中最后的链接设置了动态链接器参数-dynamic-linker ld-linux-x86-64.so.2 ）完成链接工作，通过延迟绑定等来将动态链接损失的性能尽可能的小。 动态地选择加载各种程序模块 加强程序的兼容性：一个程序在不同的平台运行时可以动态地链接到由操作系统提供的动态链接库，这些动态链接库相当于在程序和操作系统之间添加了一个中间层，从而消除程序对不同平台之间依赖的差异性 地址无关代码：共享对象在编译时不能假设自己在进程虚拟空间中的位置。把指令中那些需要修改的部分分离出来与数据部分放在一起，这样指令部分就可以保持不变，而数据部分可以在每个进程中有一个副本，这种方案就是地址无关代码（PIC，Position-Independent Code） 装载时重定位：一旦模块装载地址确定，即目标地址确定，那么系统就对程序中所有的绝对地址进行重定位（静态链接时的重定位叫做链接时重定位；动态链接的重定位叫做装载时重定位 ） 模块中国各种类型地址类型引用方式： 模块内部的函数调用、跳转：采用相对地址调用，不需要重定位 模块内部的数据访问，比如模块中定义的全局变量，静态变量：采用相对地址访问，获取当前的PC值，加上偏移量就能访问变量了 模块外部的数据访问，比如其它模块定义的全局变量：ELF的做法是子啊数据段里面建立一个指向这些变量的指针数组，称为全局偏移表（GOT，Global Offset Table）。GOT是放在数据段的，可以在模块装载时被修改，并且每个进程都可以有独立的副本，互相不影响。 模块外部的函数调用、跳转等：通过GOT中的项进行间接跳转 延迟绑定：当函数第一次被用到才进行绑定（符号查找、重定位等），如果没有用到则不绑定。ELF使用PLT（Procedure Linkage Table）的方式来事先延迟绑定（PLT使解析只会在符号未解析时进行一次）。 动态链接的步骤 动态链接器自举：动态链接器不依赖其它任何共享对象；动态链接器本身所需的全局和静态变量的重定位工作由它本身完成 装载共享对象：将可执行文件和链接器本身的符号都合并到一个全局符号表中（图的遍历过程），当一个符号需要加入到全局符号表时，如果相同的符号已经存在，则忽略后加入的符号 重定位与初始化：重新遍历可执行文件和每个共享对象的重定位表，将它们的GOT/PLT中的每个需要重定位的地方进行修正。 四、参考文献[0] 程序员的自我修养 ：链接、装载与库 / 俞甲子，石凡，潘爱民著.—北京：电子工业出版社 [1] GNU ONLINE DOC - collect2 https://gcc.gnu.org/onlinedocs/gccint/Collect2.html","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"编译","slug":"编译","permalink":"https://www.delta1037.cn/tags/编译/"}]},{"title":"基于NS3的无线链路物理层仿真实验","slug":"基于ns3的无线链路物理层仿真实验","date":"2019-02-11T11:21:59.000Z","updated":"2019-10-15T06:49:56.028Z","comments":true,"path":"2019/02/11/基于ns3的无线链路物理层仿真实验/","link":"","permalink":"https://www.delta1037.cn/2019/02/11/基于ns3的无线链路物理层仿真实验/","excerpt":"","text":"一、实验目的 掌握NS3的基本仿真方法 熟悉NS3的无线链路模型 改进NS3的无线链路模型 二、实验背景在原有的NS3的无线模型中,很难去控制链路的速率，延迟和错误等属性，例如在原有的模型中，错误率是不随距离变化的，即只要在可以传输的范围之内，错误率都是一样的，但是在实际中，随着距离的增加，错误率应该逐渐上升，而不是保持不变，因此我们在现有的模型中做出了一些改进，引入随着距离增加错误率逐渐增加的错误模型，并且引入丢头队列和丢尾队列来模拟不同队列的场景下传输速率的变化，同时加入定向网络的模型，实现定向传输的功能并且支持固定争用模型，即在冲突范围内，随着用户数量的增加，收包率逐渐下降。 三、实验原理1.错误模型 图一:节点分布图 上图是基于NS3的错误模型节点分布图，如图所示，节点0分布在半径为100的圆的中心，其余100个节点以节点0为中心半径为100的圆内随机分布，同时节点0向周围节点发送数据，传输距离为100. ​ 在NS3原有的错误模型中，节点0向各个节点发送数据的丢包率是一样的，但是实际场景中随着距离的增加，丢包率会逐渐上升，经过研究和调查，我们所构建的丢包率曲线如下图 图二:丢包率曲线 2.队列模型​ 在NS3的原有队列模型中使用的是丢尾队列，当发送数据包的队列已满时，丢尾队列会丢弃队列的最后的数据包，以控制数据包的发送率，我们引入了丢头队列，即当队列已满时，主动丢弃队列的头部的数据包，因为当队列已满时，表明队列的头部数据包非常的大，导致发送时间过长，使得后面的数据包处于等待过程中。因此丢头队列机制也会使得数据包的发送速率提升。 3.定向网络​ 在NS3现有的模型中,无线网络采用的时广播的方式，中心节点发送数据之后，其余的节点都会收到数据包，我们引入了定向网路的模型，即在显示场景中，通过摆放天线的朝向，可以定向的向部分节点发送数据，两者对比如图： 图三：定向网络和非定向网络对比 ​ 在NS3中构造如上图所示的场景，在定向网络中只有定向的节点才会收到数据包，其余节点则不回收到数据包，而在非定向网络中，则是全部节点都会收到数据包，因此在两种场景下统计各个节点收到的数据包的数量就可以对比两者的特性。 4.固定争用​ 实际场景中，在可传输的范围内，随着用户数量的增多，用户之间发生冲突的几率会逐渐增加，网络的性能将会逐渐下降，吞吐量逐渐下降，丢包率逐渐上升。 图四：固定争用 ​ 如图所示，仍然采用错误模型中的节点分布，中心节点向周围节点发送数据，同时不断扩大冲突范围，随着冲突范围的不断扩大，覆盖的用户数量就会不断的增加，吞吐量应该会逐渐下降，因此统计各个节点的丢包率应该会观察到随着冲突范围的增加，丢包率在逐渐上升。 四、实验过程1.错误模型测试 图五：节点分布图 ​ 采用如图五中的节点分布，一共有101个节点，节点0在中心，另外一百个节点随机分布在半径为100的圆内，令中心节点向周围节点发送数据，统计各个节点收到的数据包。 图六:测试所得丢包率曲线 ​ 采用所构造的错误模型曲线，统计丢包率，测试结果如图六所示，测试结果显示随着距离的增加，丢包率在逐渐的上升，因此符合预期要求。 图七:测试所得丢包率曲线 ​ 另一方面，减少节点数量为21个，统计统计节点的收包特性图，如图七所示，图中绿色的部分表明节点正在收到数据包，其余表示因发生错误导致节点处于空闲状态，结果表明由于节点所处的距离不同，任何两个节点的收包特性是不一样的，因此也从另一方面验证了所构造的模型的合理性和正确性。 2.数据包队列测试 ​ 图八:丢头队列和丢为队列 ​ 采用两种类型的队列机制:丢头队列和丢为队列，测试的机制如图八所示，一共有两个节点，节点0向节点1发送数据包，并分别采用两种队列机制，然后统计节点1的收包特性。 ​ 图九:测试所得丢包率曲线 ​ 如图所示为测试结果，测试结果表明，丢头队列和丢尾队列都可以改变丢包率，并且可以看出丢头队列的延迟比丢尾队列的延迟更小。 ​ 图十:队列优先级测试曲线 ​ 如图所示曲线为队列有限级的测试曲线，所发送的数据包分为数据包和控制包 3.定向传输测试 图十一:定向传输测试模型 ​ 上图为测试定向网络时的节点分布图，其中节点1，3，4，7，10，11为定向网络节点，当使用定向网络传输模式时，中心节点0向这些节点定向传输数据，其余节点则应不能收到数据包，而当使用非定向网络传输模式时，所有节点都应该可以收到数据包。 图十二:定向传输测试结果 ​ 测试结果如上图，蓝色为非定向网络，黄色为定向网络，结果表明，当使用非定向网络时，全部节点都可以收到数据包，当使用定向网络时，只有定向网络节点才可以收到数据包，非定向网络节点无法收到数据包。 4.固定争用测试 图十三：固定争用测试结果 ​ 如图所示，横轴为冲突范围所覆盖的用户数量，测试结果表明：随着冲突范围的不断扩大，覆盖的用户数量逐渐增多，因此导致的冲突逐渐增多，丢包率逐渐上升，收包率逐渐下降。 五、实验小结​ 实验过程中，我们遇到了很多的问题，首先在实验环境的搭建过程中，刚开始搭建的是基于NS3-dev的环境，在代码测试的过程中遇到了很多的问题，之后又搭建了NS3-dce的环境进行测试。同时，在测试代码的时候也有很多的问题，由于机器的处理速度有限，仿真测试结果往往需要很长时间才会出来，也花费了我们很多的精力。 ​ 在之后的过程中，我们将继续改进这个模型，构建宏基站和微基站的体系架构，并在此架构上面探索单小区模型和大规模网络场景模型下的基站调度策略。","categories":[{"name":"未分类","slug":"未分类","permalink":"https://www.delta1037.cn/categories/未分类/"}],"tags":[]},{"title":"chrome起始页修改","slug":"chrome起始页","date":"2018-12-31T14:11:02.000Z","updated":"2019-08-03T13:37:24.316Z","comments":true,"path":"2018/12/31/chrome起始页/","link":"","permalink":"https://www.delta1037.cn/2018/12/31/chrome起始页/","excerpt":"","text":"修改chrome起始页面window上的chrome一进去就是2345什么鬼的乱七八糟的，看着贼难看 改名字修改C:\\Program Files (x86)\\Google\\Chrome\\Application下的chrome.exe为其它名字，比如geniusrabbit.exe ，重新建立快捷方式到桌面就行了，同时也可以固定到底部 效果","categories":[{"name":"问题","slug":"问题","permalink":"https://www.delta1037.cn/categories/问题/"}],"tags":[{"name":"2345","slug":"2345","permalink":"https://www.delta1037.cn/tags/2345/"},{"name":"chrome","slug":"chrome","permalink":"https://www.delta1037.cn/tags/chrome/"}]},{"title":"敏捷开发小记","slug":"敏捷开发小记","date":"2018-11-12T14:48:33.000Z","updated":"2019-08-03T13:37:26.876Z","comments":true,"path":"2018/11/12/敏捷开发小记/","link":"","permalink":"https://www.delta1037.cn/2018/11/12/敏捷开发小记/","excerpt":"","text":"敏捷知识基础 迭代计划会议、迭代验收会议、每日站立会议、迭代回顾会议 聚焦客户价值，激发团队潜能、适应变化 自动化、变化的需求 story 故事描述了对于系统或软件的客户或用户有价值的一个功能点 组成 简短描述 针对故事描述交流，澄清细节 记录和传递故事细节的测试信息，用来确定故事是否开发完成 格式： 作为X（什么用户角色 为了Y（目的 希望得到什么（系统提供什么功能 3-3-4 三个角色：PO、master、开发人员 三个工件： 产品清单 迭代清单 燃尽图 四个会议 收集story 价值分析 识别用户角色 编写story 确定优先级 估计 分解Story 分解原则：每个格式提供相对完整的功能 好的story 独立 便于沟通 有价值 易于估计 可测试 持续集成 持续集成工作产品，一天集成多次，每次集成有自动化的测试环境（包含测试） 测试驱动开发 快速新增测试 运行所有测试 做改动 所有测试通过 重构，消除重复设计，设计优化结构 测试用例 快速：测试运行够快 独立用例之间互相独立 可重复：任何环境、可重复 自足验证：足够的自动化测试验证逻辑 及时：及时写测试用例","categories":[{"name":"测试","slug":"测试","permalink":"https://www.delta1037.cn/categories/测试/"},{"name":"软件工程","slug":"测试/软件工程","permalink":"https://www.delta1037.cn/categories/测试/软件工程/"}],"tags":[{"name":"小记","slug":"小记","permalink":"https://www.delta1037.cn/tags/小记/"},{"name":"敏捷开发","slug":"敏捷开发","permalink":"https://www.delta1037.cn/tags/敏捷开发/"}]},{"title":"自动化测试与shell总结","slug":"自动化测试与shell总结","date":"2018-11-12T14:17:09.000Z","updated":"2019-10-18T08:20:59.625Z","comments":true,"path":"2018/11/12/自动化测试与shell总结/","link":"","permalink":"https://www.delta1037.cn/2018/11/12/自动化测试与shell总结/","excerpt":"","text":"自动化测试&amp;&amp;shell总结学习软件工程,小有所成 自动化测试自动化测试,使用自动化工具(脚本等&lt;应该可以这么理解?&gt;),自动测试工程 关于测试测试即为测试代码,但是测试代码的方式又有很多,在没有学习软件工程之前,我自己以为的测试就是写一个函数,调用所写的函数,传入参数,然后根据传出的参数来判断函数的功能是否正确;学习软件工程之后,测试是传入测试的指令,预制工程的状态,然后由原工程进行代码的运行之后,最后导出运行之后的状态,与正确的状态对比,判断工程运行是否正确 1.单元测试单元测试就是学习软件工程之前的测试方法,即:写测试函数,调用工程中的某一个功能函数,根据调用该函数之后的返回值,来判断该功能函数实现的是否正确. 这就是单元测试(测试诸多功能中的一个) 2.集成测试集成测试就是学习软件工程之后的测试方法,即:在工程中留有接口,准备接收预置工程状态的命令,和导出工程状态的指令,根据导出的状态,来与正确的状态进行比较,来判断整个工程是否正确. 这就是集成测试(测试整个工程) 关于自动化测试测试实现自动化, 就是将导入工程状态和比较程序状态的过程由工具实现,比如可以写一个脚本,自动导入要预置的工程的状态,然后对比导出的状态与正确的状态是否一致 心得: 1. 将预置的状态的命令写入表格中,便于管理测试用例 2. 将正确的状态写入表格,便于管理 3. 将表格内容生成文件 Shell这次软件工程实践,在自动化测试这一块采用的shell脚本来实现测试的自动化 关于文件的对比: 对比肯定是需要两个文件的,但是两个文件又在不同的文件夹中, 若采用for循环遍历文件夹,则只能遍历其中一个文件夹 ,并且shell中没有同时遍历两个文件夹的for循环&lt;解决思路: 先用一个for循环遍历其中一个文件夹,将遍历到的文件路径存于数组中, 然后再去遍历另外一个文件夹,并且依次读取数组中的内容,便实现了同时遍历的效果&gt; 关于操作对象的确定性: 本来使用的for循环遍历文件夹是使用的for m in $(ls someFilePath)的形式,然后m就是其中的一个文件,但是使用这种形式操作下,我们并不清楚m是什么,(ls的顺序虽然是按照一定的顺序排列的,但是对于m的未知性,这种操作也有一定的危险性&lt;解决思路,对文件命名采用数字标识,加前缀表明文件类型,例如:dump1,dump2….right1,right2…. for循环的时候就可以循环坐标&gt; 脚本风格:在微机原理课上学到,所有的变量及其赋值应该放置在一处以便于管理的思想, 所以所有的可见的字符都应该用变量名字标识,然后在后边的脚本中只对变量名字操作,这样,如果想修改变量的值,只在统一的地方修改就可以,不用修改使用变量的诸多地方(类似于c语言中的宏) 精确浮点数计算:”scale=2;算术表达式” | bc","categories":[{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/categories/Shell/"},{"name":"测试","slug":"Shell/测试","permalink":"https://www.delta1037.cn/categories/Shell/测试/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"},{"name":"测试","slug":"测试","permalink":"https://www.delta1037.cn/tags/测试/"}]},{"title":"Linux小系统（一）-小系统制作","slug":"linux小系统-小系统制作","date":"2018-10-06T15:05:57.000Z","updated":"2019-08-03T13:37:25.496Z","comments":true,"path":"2018/10/06/linux小系统-小系统制作/","link":"","permalink":"https://www.delta1037.cn/2018/10/06/linux小系统-小系统制作/","excerpt":"","text":"制作Linux小系统-外围文件系统定制 环境： - window10 - vmvare pro 14 - centos6.10-mini 一、Linux启动过程分析 BIOS MBR/GPT Master Boot Record and Disk partitions Globally Unique Identifier Parttion Table Format OS Loader Window:NTLDR/BootMgr Linux:GRUB/GRUB2 OS Kernel DOS:IO.SYS MSDOS.SYS Window:ntoskrnl.exe Linux:vmlinuz Application Manager DOS:command.com Window:explorer.exe Linux:init Applications… 二、启动bash/boot中的init*.img文件 一个由OS loader载入的镜像文件 临时“根文件系统” /boot/grub/grub.conf文件title Linux 2.4 root (hd0,1) kernel /boot/vmlinuz ramdisk_size=8192 root=LABEL=/ initrd /boot/initrd.img 制作根文件系统 使用原来的kernel，initd自己的init*.img 如何生成img文件 . 表示当前目录$ find . | cpio -H newc -o | gzip &gt; /boot/initrd.img 解压生成的img(不小心删掉了自己的系统文件夹，可以用这个方法恢复) $ mv initramfs.img initramfs.img.gz # 添加gz后缀$ gunzip initramfs.img.gz # 解压$ mkdir temp # 创建目录并将解压后的文件丢进去$ cpio -i -F ../initramfs.img # 解压刚刚丢进temp的文件 制作init Application Manager init是开机后grub引导进入系统后执行的，所以想要开机进去之后得到一个bash，就得在这个里面定制过程 bash是一个命令，所以只要执行这个命令，就可以得到一个bash， # 查找命令find，可使用通配符* $ find / -name &quot;bash&quot; 可执行文件&amp;动态库 随意创建一个目录作为我们小系统的根目录，创建必要的文件夹（拷入小系统的路径与大系统路径一致，例如bash在bin目录中，就要在小系统根目录下创建bin目录然后将bash拷入） bash执行还需要有其依赖的动态库，我们的小系统启动起来是独立于大系统的，所以我们要将其依赖的动态库也拷进我们的小系统 # 查新指令依赖的动态库 $ ldd /可执行文件路径 $ ldd /bin/bash 拷贝可执行文件依赖动态库脚本 #!/bin/bash use : ./script.sh /可执行文件 /动态库目录dependList=$( ldd $1 | awk ‘{if (match($3,”/“)){ print $3}}’ )echo $dependListcp $dependList $2 拷贝目录下的所有可执行文件依赖的动态库脚本 #!/bin/bash use : ./script.sh /可执行文件目录 /动态库目录for m in $(ls $1)do dependList=$( ldd $1/$m | awk &apos;{if (match($3,&quot;/&quot;)){ print $3}}&apos; ) cp $dependList $2 done 三、管理设备 udev : 管理、监控主机设备的服务程序 依赖与sysfs文件系统（挂载于/sys） 规则文件/lib/udev 配置文件/etc/udev 自动在/dev目录下创建设备节点 /proc目录：通过 /proc 文件系统，在运行时访问内核内部数据结构、改变内核设置的机制 /sys目录：硬件设备的驱动程序信息 通过执行/sbin/start_udev，就可以检测到所有的设备 # 查看当前机器所有设备 $ ls /dev 四、挂载磁盘 磁盘也是一种设备 在linux上挂载磁盘，磁盘一般是在dev目录里的，但是在上面的管理设备部分，当列出当前机器设备时，并没有看到有关sd*之类的，这是因为缺少驱动程序 Linux的驱动在/lib/modules目录，可以看到有不同的版本号 $ lsmod # 列出当前机器所使用的所有驱动 $ modinfo # 查看驱动具体介绍，包括驱动依赖关系 $ insmod # 加载指定的驱动 $ modprobe # 载入制定模块或者载入一组相依的模块，需要有依赖关系moudules.dep 磁盘所需驱动 scsi_transport_spi.ko mptbase.ko mptscsih.ko mptspi.ko crc-t10dif.ko sd_mod.ko etx4文件系统驱动 mbcache.ko jbd2.ko ext4.ko 当加载完磁盘和文件系统驱动，就可以挂载和读写原来的文件系统了 五、登录login login认证体系（PAM） /etc/pam.d /lib/security 六、使用/sbin/init启动系统/sbin/init的工作： /etc/rc.sysinit probe devices:udevd fsck remount /etc/rc service /sbin/mingetty login prompt = mingetty+/bin/login 七、联网 网卡驱动： e1000.ko ping：查看网络是否连通 ethtool：查看网卡信息 ifup、ifdown：启动，关闭网卡 mentohust：连接校园网的工具 ssh：连接到远程主机，或者被远程主机连接 scp：基于ssh在两台主机之间拷贝文件","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.delta1037.cn/tags/linux/"}]},{"title":"Linux小系统（二）-内核编译","slug":"linux内核编译","date":"2018-10-04T11:16:31.000Z","updated":"2019-08-03T13:37:25.308Z","comments":true,"path":"2018/10/04/linux内核编译/","link":"","permalink":"https://www.delta1037.cn/2018/10/04/linux内核编译/","excerpt":"","text":"Linux内核编译内核下载与解压内核下载内核下载地址 解压$ tar -xvf linux-*.tar.xz 编译安装开发环境$ yum groupinstall &apos;Development Tools&apos; $ yum install ncurses-devel $ yum install elfutils-libelf-devel $ yum install bc 参考文档Linux-4.4-x86_64 内核配置选项简介-作者：金步国 Linux 核心编译与管理-鸟哥 TIPS小系统需要实现的功能、 CPU 硬盘控制器 网络控制器 USB控制器 HID、Mass Storage 声卡控制器(可选) 个人总结 网络控制器：联网需要网卡驱动，在设备管理器里可以看到自己网卡是什么型号的，然后在设备驱动-&gt;网络设备支持-&gt;以太网设备支持里将自己网卡那一类勾上，其它可以不要（因为没有这类网卡） 能编译成模块的尽量编译成模块，这样内核会变小很多 编译过程$ make mrproper # 删除之前的核心功能配置文件,配置文件！！！ $ make clean # 清理编译过程中的中间文件，不删除配置文件 $ make menuconfig #选择模块 $ make clean #清除 $ make -j 4 #多线程编译 $ make modules_install #安葬模块 $ make install #一键安装","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"小系图","slug":"小系图","permalink":"https://www.delta1037.cn/tags/小系图/"}]},{"title":"Linux小系统（三）-U盘启动","slug":"linux小系统-u盘启动","date":"2018-10-04T11:05:01.000Z","updated":"2019-08-03T13:37:25.404Z","comments":true,"path":"2018/10/04/linux小系统-u盘启动/","link":"","permalink":"https://www.delta1037.cn/2018/10/04/linux小系统-u盘启动/","excerpt":"","text":"U盘启动小系统 环境： Window10 CentOs虚拟机 制作启动盘 找一个不常用的U盘，分出来一小部分作为启动分区，剩余的作为日常使用（最好在window上分盘。。。） 在虚拟机上挂载U盘，启动分区格式化 $ mkfs.ext4 /dev/uBootPart 将分出来的启动分区添加上启动标志 $ fdisk /dev/uBootPart -a 再次fdisk -l 之后看到U盘的启动分区的boot下有个* 4.向启动分区中安装grub,/mnt是挂载位置 $ grub-install --root-directory=/mnt /dev/uBootPart 必要文件拷贝 /boot/grub/grub.conf (内容做适当修改) boot/vmlinuz* boot/initramfs.img","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.delta1037.cn/tags/linux/"}]},{"title":"计网笔记","slug":"计网笔记","date":"2018-09-11T11:25:10.000Z","updated":"2019-08-03T13:37:27.536Z","comments":true,"path":"2018/09/11/计网笔记/","link":"","permalink":"https://www.delta1037.cn/2018/09/11/计网笔记/","excerpt":"","text":"计网笔记基本概念 路由：根据目的节点地址确定如何将消息转发到目的节点的过程 常用的两种交换方式：电路交换、分组交换 电路交换：建立一条专用电路，允许源节点通过这条链路将比特流发送到目的节点 电路交换存在原因：对网络容量需求的不断增加 分组交换：使用存储转发机制，每个节点先通过某条链路接收一个完整的分组，将分组存储到内存中，然后将整个分组发送到下一个节点，节点彼此之间发送离散的数据块 分组交换特点：分组交换效率高 分层和协议 分层优点：1.将建造网络这个问题分解为多个可处理的部分；2.提供模块化的设计 协议：协议为另一台机器上的对等实体定义一个对等接口 中间节点：（由处理的层分类） repeater/中继：直接在物理层处理，转发数据包 bridge/网桥：在数据链路层处理，将网络中的多个网段在数据链路层中转发 router/路由：在网络层处理，根据目的节点地址确定如何将消息转发到目的节点的过程 gateway/网关：在传输层及以上处理，按照网段转发数据 时延 = 光速传播延迟+发送数据单元时间+排队延迟 带宽：在一段特定的时间内网络所能传输的比特数 延迟带宽积：相当于第一个比特到达接收者之前，发送者必须发送的比特数","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.delta1037.cn/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.delta1037.cn/tags/计算机网络/"}]},{"title":"visdom&tensorBoardX可视化","slug":"visdomtensorboard可视化","date":"2018-08-16T09:50:31.000Z","updated":"2019-08-03T13:37:26.584Z","comments":true,"path":"2018/08/16/visdomtensorboard可视化/","link":"","permalink":"https://www.delta1037.cn/2018/08/16/visdomtensorboard可视化/","excerpt":"","text":"acc,loss曲线的可视化 visdom 安装 $ pip install visdom 启用 $ python -m visdom.server 使用 import visdomvis = visdom.Visdom(env=’model_env’) 多曲线可视化(loss,acc)vis.line(Y=np.column_stack(np.array([train_loss, train_acc,test_acc])), X=np.column_stack(np.array([epoch + 1, epoch + 1, epoch + 1])), win=&apos;main&apos;, update=&apos;append&apos;) tensorboardX 安装 $ pip install tensorboardX 使用 from tensorboardX import SummaryWriterwriter = SummaryWriter(‘/path/to/log’) 多曲线可视化(loss, acc)writer.add_scalars(&apos;data/group&apos;, {&apos;test_loss&apos;:loss_vue, &apos;test_acc&apos;:acc_vue}, train_step)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://www.delta1037.cn/categories/机器学习/"}],"tags":[{"name":"tensorboard","slug":"tensorboard","permalink":"https://www.delta1037.cn/tags/tensorboard/"},{"name":"visdom","slug":"visdom","permalink":"https://www.delta1037.cn/tags/visdom/"},{"name":"可视化","slug":"可视化","permalink":"https://www.delta1037.cn/tags/可视化/"}]},{"title":"CodeStyle","slug":"codestyle","date":"2018-07-31T15:09:46.000Z","updated":"2019-08-03T13:37:24.488Z","comments":true,"path":"2018/07/31/codestyle/","link":"","permalink":"https://www.delta1037.cn/2018/07/31/codestyle/","excerpt":"","text":"CodeStyle(待续…)!我最讨厌不写注释的人和让我写注释的人… 写好代码,人人有责 共勉~ 一.CODE COMPLETE NOTE1.变量 变量定义尽量靠近使用该变量的地方 使用同一变量的代码尽量集中到一起,减轻大脑负担 尽量减小变量的作用域,更有利于debug,又不会对远处的变量误操作 二.Leetcode踩坑指南1.要考虑所有的情况 传入为空的情况:例如传入了一个数组但是里面有0个值,传入了一个链表但是头结点就为NULL 传入二维数组:在判断列数是否为0的时候,提前判断行数是否是0,否则无法得到列数 2.返回二维数组操作格式int** function(int* array, int arraySize, int** columnSizes, int* returnSize) { //some operation } Explanation the array is what you have to operate returnSize is the rowSize that you have to return columnSizes is the col size of every row，malloc format is int col=(int)malloc(rowSize*sizeof(int)); *columnSizes=col; 计算中间值(防止溢出) 给定first和last，计算mid： mid=first+(last-first)/2; //若直接相加除二可能会溢出 Run time error问题 Run time error :数组越界（maybe…） 存在死循环:数组的index更新或者链表的循环有问题 三.个人总结 1 函数注释 /** function: 函数功能 @param: 函数参数,简介 @return: 返回值简介","categories":[{"name":"CodeStyle","slug":"CodeStyle","permalink":"https://www.delta1037.cn/categories/CodeStyle/"}],"tags":[{"name":"codestyle","slug":"codestyle","permalink":"https://www.delta1037.cn/tags/codestyle/"}]},{"title":"Apache配置ssl","slug":"apache配置ssl","date":"2018-07-31T11:55:45.000Z","updated":"2019-08-03T13:37:24.232Z","comments":true,"path":"2018/07/31/apache配置ssl/","link":"","permalink":"https://www.delta1037.cn/2018/07/31/apache配置ssl/","excerpt":"","text":"阿里云申请的ssl证书配置(Apache)下载证书 下载证书 上传到服务器 解压到 /etc/apache2/ssl (不存在则创建) 配置Apache 打开SSL模块 $ a2enmod ssl 配置conf 编辑apache2配置文件 $ vim /etc/apache2/apache2.conf apache2配置文件 &lt;Directory /var/www/&gt; Options Indexes FollowSymLinks #把none改为all AllowOverride all Require all granted &lt;/Directory&gt; 编辑port.conf文件 $ vim ports.conf port.conf配置 #添加监听443端口 &lt;IfModule ssl_module&gt; Listen 443 &lt;/IfModule&gt; 配置default-ssl.conf #添加servername ServerName example.com #修改sslengine SSLEngine on #添加证书文件，按照阿里云给出的示例添加即可 #证书的文件位置就是刚刚上传的位置 SSLCertificateFile /etc/apache2/ssl/public.pem SSLCertificateKeyFile /etc/apache2/ssl/2146003231320408.key SSLCertificateChainFile /etc/apache2/ssl/chain.pem 启用启用刚刚的ssl配置 $ a2ensite default-ssl 重启apache服务器 $ service apache2 restart OK~","categories":[{"name":"网站","slug":"网站","permalink":"https://www.delta1037.cn/categories/网站/"}],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://www.delta1037.cn/tags/ssl/"}]},{"title":"神经网络Note","slug":"神经网络note","date":"2018-07-30T09:56:33.000Z","updated":"2019-08-03T13:37:27.096Z","comments":true,"path":"2018/07/30/神经网络note/","link":"","permalink":"https://www.delta1037.cn/2018/07/30/神经网络note/","excerpt":"","text":"神经网络笔记 代码链接github :wink: Note数据处理train_data = torchvision.datasets.CIFAR10( root=&apos;Datadir&apos;, train=True, transform=transforms.ToTensor(),download=True ) torchvision.datasets.CIFAR10:代表这是cifar10数据集,若为torchvision.datasets.MNIST则为mnist数据集 root:数据集的存放位置 train=True:代表这是训练集 download=True:如果数据不存在就会自行下载 train_loader = Data.DataLoader(dataset=train_data, batch_size=4, shuffle=True, num_workers=2) dataset=train_data:代表从train_data加载数据 batch_size: 批训练的数据个数 shuffle: 是否要打乱数据(打乱比较好) num_workers: 多线程读取数据 训练模型optimizer = optim.SGD(net.parameters(), lr=0.03) 定义优化器 lr=0.03: 学习率为0.03 SGD: 使用SGD优化器 loss_func = nn.CrossEntropyLoss() 定义损失函数 CrossEntropyLoss:交叉熵损失 循环使用数据训练50次for epoch in range(50): # 训练 # 每次训练之前的初始化loss&amp;acc train_loss = 0 train_acc = 0 for i, data in enumerate(train_loader, 0): # 得到数据 inputs, lables = data # 包装数据 inputs, lables = Variable(inputs), Variable(lables) # 梯度清零 optimizer.zero_grad() # 将输入输进网络&amp;forward out = net(inputs) # 计算损失 loss = loss_func(out, lables) train_loss += loss.item() # 计算正确率 pred = torch.max(out, 1)[1] train_acc += (pred == lables).sum().item() # backward&amp;optimize loss.backward() optimizer.step() train_loss += loss.data.item() if i % 2000 == 1999: # 格式化输出loss&amp;acc print(&apos;[%d,%5d] loss:%.6f&apos; % (epoch+1, i+1, train_loss/2000)) print(&apos;[%d,%5d] acc: %.6f&apos; % (epoch + 1, i + 1, train_acc / (2000 * lables.size(0)))) # 训练2000组数据打印数据之后的初始化 train_acc = 0 train_loss = 0 torch.save(net, &apos;Alex0.03.pkl&apos;) # 测试 # 正确率初始化 train_acc1 = 0 for i, data in enumerate(test_loader, 0): # 得到数据并包装数据 inputs, lables = data inputs, lables = Variable(inputs), Variable(lables) # 计算正确率 out = net(inputs) pred = torch.max(out, 1)[1] train_acc1 += (pred == lables).sum().item() # 阶段性输出 if i % 1000 == 999: print(&apos;testDataAcc:[%d,%5d] acc: %.6f&apos; % (epoch + 1, i + 1, train_acc1 / (1000 * lables.size(0)))) train_acc1 = 0 全连接神经网络note 每层的节点数和层数可自己随意定义 参考代码 mnist全连接参考代码 cifar10全连接参考代码 卷积神经网络参数计算 输入矩阵的格式:四个维度(样本数,图像高度,图像宽度,图像通道数) 卷积核(权重矩阵):四个维度(卷积核高,卷积核宽,输入通道数,输出通道数) 卷积核输入的通道数由输入矩阵的通道数决定 输出矩阵的通道数由卷积核的输出通道数决定 输出矩阵的高和宽由输入矩阵,卷积核,扫描方式(padding,stride)所决定 卷积之后的图像大小计算:outputSize = (inputSize + 2*padding - kernelSize)/stride + 1 LeNet AlexNet VGG ResNet GoogLeNetleNet cifar10数据集参考代码 输入是32x32的图像 C1是一个卷积层,卷积核为5x5,步长为1,没有填充,由(32-2*0-5)/1+1=28,得输出图像为28x28 S2是一个降采样层,kernelSize等于2,步长为2,没有填充,得到输出为14x14 C3是一个卷积层,卷积核大小为5x5,步长为1,没有填充,得输出图像为10x10 S4是一个降采样层,kernelSize等于2,步长为2,没有填充,得到输出为5x5 C5是一个卷积层,卷积核大小为5x5,步长为1,没有填充,得输出图像为1x1 F6是一个全连接层 输出有十个参数 AlexNet-cifar10数据集参考代码 代码做了简化,使用单个运算核心运行的 note未跟随代码 - 卷积部分分为上下两块,卷积使用数据要看连接的虚线 - LRN层:对当前层的输出结果做平滑处理 VGG cifar10数据集参考代码 连续conv较多,计算量巨大 ResNet cifar10数据集参考代码 深度网络的退化问题网络深度增加时,网络准确度出现饱和甚至开始下降 使用残差学习解决退化问题残差学习相比原始特征直接学习更容易,当残差为0时,此时堆积层仅仅做了恒等映射.至少网络性能不会下降,实际上残差不会为0,也会使得堆积层在输入特征基础上学习到新的特征,从而有更好的性能 - 残差学习相当于一种短路机制 残差学习单元 不同深度的ResNet网络 googLeNet 论文翻译中文版 cifar10数据集参考代码 GoogLeNet 与传统神经网络相比提出了Inception结构,用于增加神经网络的宽度和深度,Inception模型主要考虑多个不同的卷积核能够增强网络的适应能力,4个分支在最后通过一个聚合操作合并 Inception参考博客 v1 版本1: 随后文章指出这种 naive 结构存在着问题：每一层 Inception module 的 filters 参数量为所有分支上的总数和，多层 Inception 最终将导致 model 的参数数量庞大，对计算资源有更大的依赖 版本2: 改进:Inception module with dimension reduction,在不损失模型特征表示能力的前提下，尽量减少 filters 的数量，达到降低模型复杂度的目的 v2 使用两个3*3的卷积核代替一个5*5的卷积核,在降低参数的同时,增加了更多的非线性变换 v3 将一个3*3的卷积核拆解成3*1和1*3的卷积核 引入了 Factorization into small convolutions 的思想,将一个较大的二维卷积拆解为两个较小的一维卷积,加速了运算并减轻了过拟合 v4 V4 相比 V3 主要是结合了微软的 ResNet","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://www.delta1037.cn/categories/机器学习/"}],"tags":[{"name":"naturalNet","slug":"naturalNet","permalink":"https://www.delta1037.cn/tags/naturalNet/"}]},{"title":"owncloud 搭建","slug":"owncloud-搭建","date":"2018-07-10T02:03:27.000Z","updated":"2019-08-03T13:37:25.936Z","comments":true,"path":"2018/07/10/owncloud-搭建/","link":"","permalink":"https://www.delta1037.cn/2018/07/10/owncloud-搭建/","excerpt":"","text":"搭建 ownCloudLAMP环境参见wordpress搭建 安装ownCloud官网参考 add keywget -nv https://download.owncloud.org/download/repositories/production/Ubuntu_16.04/Release.key -O Release.key apt-key add - &lt; Release.key installecho &apos;deb http://download.owncloud.org/download/repositories/production/Ubuntu_16.04/ /&apos; &gt; /etc/apt/sources.list.d/owncloud.list apt-get update apt-get install owncloud-files 安装完成之后即可在http://yourip/owncloud 打开页面 note若打不开出现乱码, cd /var/www mv owncloud html/ 配置数据库创建数据库和用户mysql -uroot -p //登录 &gt; create database owncloud; //创建数据库owncloud &gt; GRANT ALL ON owncloud.* TO user@localhost IDENTIFIED BY &apos;password&apos;; //**用户名为user**可自己更改 &gt; flush privileges; &gt; exit note登录时localhost后加上数据库访问端口3306(mysql) 若出现Can’t create or write into the data directory,需要修改owncloud文件夹的权限 $ chown -hR www-data owncloud","categories":[{"name":"ownCloud","slug":"ownCloud","permalink":"https://www.delta1037.cn/categories/ownCloud/"}],"tags":[{"name":"ownCloud","slug":"ownCloud","permalink":"https://www.delta1037.cn/tags/ownCloud/"}]},{"title":"Kubernetes","slug":"kubernetes","date":"2018-05-04T11:39:53.000Z","updated":"2019-08-03T13:37:25.120Z","comments":true,"path":"2018/05/04/kubernetes/","link":"","permalink":"https://www.delta1037.cn/2018/05/04/kubernetes/","excerpt":"","text":"kubernetesMy Study of kuberneteskubernetes结构图-来源 基本概念和术语master功能:集群控制节点,负责整个集群的管理和控制,属于首脑 master节点上运行的关键进程 - Kubernetes API Server(kube-apiserver):提供HTTP Rest接口的关键服务进程,kubernetes里所有资源的增删查改操作的唯一入口,也是集群控制的入口进程 - Kubernetes Controller Manager(kube-controller-manager):kubernetes里资源对象的自动化控制中心 - Kubernetes Scheduler(kube-scheduler):负责资源调度(Pod调度)的进程 Node除了Master,kubernetes中的其它机器被称为node节点,node节点是kubernetes集群中的负载节点,每个node都会被分配工作负载(docker容器),当某个node出错时,该节点的任务会被master自动转移到其它节点上.node上的关键进程 - kubelet:负责pod对应的容器的创建,启动停止等任务,同时与master密切协作,实现集群管理 - kube-proxy:实现kubernetes Service的通信与负载均衡 - Docker engine(docker):Docker引擎,负责本机的容器创建和管理 Pod每个pod有一个根容器Pause,还有一个或者多个用户业务容器Why kubernetes have Pod? - 在一组容器作为一个单元时,很难对整体进行操作,引入业务无关并且不易死亡的Pause容器作为Pod的根容器,以它的状态代表整个容器组的状态 - Pod里的多个业务共享Pause里的IP,共享Pause容器挂接的Volume,既简化了业务之间的通信问题,也解决了文件共享问题 Label功能:Label可以附加到各种资源对象上,例如node,pod,service,rc等,一个资源对象可以定义任意数量的Label,同一个Label也可以添加到任意数量的资源对象上去,以提供Label Selector来选择对象 标签选择方式: - 等式:name=redis-slave,name!=redis-slave - 集合:name in (redis-master,redis-slave),name not in (redis-master,redis-slave) Label和Label Selector 共同构成了kubernetes系统中最核心的应用模型,使得被管理对象能够被精细的分组管理,实现整个集群的高可用性 Replication Controller(RC)管理 Pods 的生命周期。它们确保指定数量的 Pods 会一直运行，还有实现资源伸缩。 - 定义RC实现Pod的创建与副本数量的自动控制 - RC 通过Lable Selector机制实现对副本的自动控制 - 通过改变RC的Pod副本数量，实现Pod的扩容或缩容 - 通过改变RC里Pod模板中的镜像版本，实现Pod的滚动更新 DeploymentDeployment可以认为是RC的升级版，最大的区别是我们可以随时知道POD容器的部署进度 使用场景: 创建一个Deployment对象来生成RC并完成Pod副本的创建过程 检查Deployment的状态看部署动作是否完成 更新deployment以创建新的Pod(升级) 如果当前Deployment不稳定则回滚到早先版本 暂停Deployment以便于一次修改多个PodTemplateSpec的配置项，之后再进行发布 扩展Deployment以应对高负载 查看Deployment的状态，以此作为发布是否成功的指标 清理不在需要的旧版本RC Horizontal Pod Autoscaler(HPA)HPA也是一种资源对象，通过追踪分析RC控制的pod的负载变化情况来确定是否需要针对性地调整目标pod的副本数（增加或者减少） Pod负载的度量指标: - CpuUtilizationPercentage（CPU利用率）,取所有副本自身CPU利用率的平均值（需要定义Pod Request值） - 应用程序自定义的度量指标，比如TPS或者QPS StatefulSet用于实现有状态的集群管理，可以将它看做Deployment/RC的一个变种 特性: - StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群的其他成员 - StatefulSet控制的Pod副本的启停顺序是受控的，如StatefulSet名叫zk,则第一个叫做zk-0，第二个叫做zk-2，依次类推 - Stateful里的Pod采用稳定的持久化存储卷，通过PV/PVC实现 Service service定义了一个服务的访问入库地址，前端应用（Pod）通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端Pod副本集群之间则是通过Label Selector来实现无缝对接的。RC的作用实际上是保证service服务能力和服务质量始终处于预期的标准。 一组Pod组成的服，客户端如何访问？每个Node上的kube-proxy进程负责把对service的请求转发的后端某个Pod的实例上，并在内部实现了服务的负载均衡与会话保持机制。但需要注意的是：service不是共用一个IP，而是每个Service分配了一个全局唯一的虚拟IP地址（ClusterIP），服务调用就变成一个TCP网络通信。 kubernetes的服务发现机制，Service对象都有一个唯一的ClusterIP以及唯一的名字，在老版本中通过自动注入环境变量将service的name与ClusterIP绑定，新版本中采用插件的方式引入了DNS系统，把service的name作为DNS域名，然后程序就可以通过service的name来建立通信连接了 外部系统访问service的关键在于3种IP，即： 1.Node IP node节点的IP地址，集群之外的节点访问集群内的服务时，必须要通过NodeIP进行访问 2.Pod IP pod的IP地址，Docker Engine根据dicker0网桥的IP地址段进行分类的一个虚拟的二层网络的IP地址 3.Cluster IP service的IP地址，虚拟的IP，它的特点：仅作用域service对象，由k8s管理和分配IP地址;无法被ping;只能结合service port组成一个具体的通信端口，单独的Cluster IP不具备通信基础;集群之内 Node/pod/cluster之间的通信与通常的IP路由与很大的不同 service的cluster IP无法供外部直接使用，但通过指定服务的port绑定在节点的port上，即可进行访问；当pod位于多个node时，通过nodeip:port访问到的是nodeip所在node上的pod,如需负载可以考虑使用硬件负载均衡器或者Nginx Volumevolume是pod中能够别多个容器访问的共享目录；k8s中volume定义在pod上，然后被pod中的多个容器挂载到具体的目录下；volume与pod的生命周期相同 类型: - emptyDir：Pod分配到node时创建的，它的初始内容为空，并且无需指定宿主机上对应的目录文件，pod从node上移除时，则emptyDir中的数据永久删除；emptyDir的用途有： - 临时空间 - 长时间任务的checkpoint点 - 一个容器需要从另一个容器获取数据的目录 hostPath，在pod上挂载宿主机的文件或目录， 主要用途： 容器应用生成的文件（如日志）需要永久保存时 需要访问宿主机的文件时 注意事项: 不同的node上具有相同配置的pod可能因为宿主机上的目录和文件不同而导致对Volume上目录和文件的访问结果不一致 hostPath无法纳入资源配额管理 NFS，使用NFS网络文件系统共享存储数据 其他类型：ceph、glusterfs等 Persistent Volume(PV) PV是k8s集群中某个网络存储中对应的一块存储，它和Volume的区别： PV只能是网络存储，不属于任何Node，但可以在每个Node上访问 PV独立于Pod定义 PV目前支持的类型涵盖了很多公有云平台存储（gce、aws）以及一些网络文件系统（NFS） Pod想申请PV时，需要先定义一个PVC（Persistent Volume Claim），然后在Pod的Volume中引用定义好的PVC Namespace Namespace通过将集群中的资源对象分配（逻辑上的）到不同的Namespace中，形成逻辑上的分组不同的项目、用户组等，便于实现多租户资源管理。 默认的namespace是default 声明资源对象时，在metadata一项中可以指定，如namespace: dev Annotation注解与Label类似，但具有严格的命名规则","categories":[{"name":"集群","slug":"集群","permalink":"https://www.delta1037.cn/categories/集群/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://www.delta1037.cn/tags/kubernetes/"}]},{"title":"Docker","slug":"docker","date":"2018-05-04T05:28:31.000Z","updated":"2019-08-03T13:37:24.780Z","comments":true,"path":"2018/05/04/docker/","link":"","permalink":"https://www.delta1037.cn/2018/05/04/docker/","excerpt":"","text":"参考1 安装安装docker 卸载旧版本 $ apt-get remove docker docker-engine docker.io 添加源并更新 $ add-apt-repository “deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable” $ apt-get update 安装最新的稳定版 $ apt-get install -y docker-ce 安装制定版本 #获取版本列表$ apt-cache madison docker-ce#指定版本安装$ apt-get install -y docker-ce=17.09.1~ce-0~ubuntu 设置并启动docker服务接受所有ip包转发$ vi /lib/systemd/system/docker.service #找到ExecStart=xxx，在这行上面加入一行，内容如下：(k8s的网络需要) ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT 启动服务$ systemctl daemon-reload $ service docker start 系统设置关闭防火墙$ ufw disable #查看状态 $ ufw status 设置系统参数#写入配置文件 $ cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF #生效配置文件 $ sysctl -p /etc/sysctl.d/k8s.conf 配置host#配置host，使每个Node都可以通过名字解析到ip地址 $ vi /etc/hosts #加入如下片段(ip地址和servername替换成自己的) 192.168.1.101 server01 192.168.1.102 server02 192.168.1.103 server03","categories":[{"name":"集群","slug":"集群","permalink":"https://www.delta1037.cn/categories/集群/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.delta1037.cn/tags/docker/"}]},{"title":"C++工程目录结构","slug":"c工程目录结构","date":"2018-02-26T15:06:20.000Z","updated":"2019-08-03T13:37:24.700Z","comments":true,"path":"2018/02/26/c工程目录结构/","link":"","permalink":"https://www.delta1037.cn/2018/02/26/c工程目录结构/","excerpt":"","text":"C++各种工程参考目录结构参考文章 开发工程结构例如，我们创建一个C++/C程序工程TestProj，其文件可以参照图10-1所示的结构来组织。 - TestProj ——Include ——Source ——Shared ——Resource ——Debug ——Release ——Bin ——IDE生成的文件 ——Readme ——其他临时文件 ——数据文件 ——配置文件 ——DLL 目录的用途如下: （1）Include目录存放应用程序的头文件（.h），还可以再细分子目录 （2）Source目录存放应用程序的源文件（.c或 .cpp），还可以再细分子目录 （3）Shared目录存放一些共享的文件 （4）Resource目录存放应用程序所用的各种资源文件，包括图片、视频、音频、图标、光标、对话框等，还可以再细分子目录 （5）Debug目录存放应用程序调试版本生成的中间文件 （6）Release目录存放应用程序发行版本生成的中间文件 （7）Bin目录存放程序员自己创建的lib文件和dll文件 【提示】：分清楚编译时相对路径和运行时相对路径的不同，这在编写操作DLL文件、INI文件及数据文件等外部文件的代码时很重要，因为它们的“参照物”不同。 例如下面的代码行： #include “..\\include\\abc.h” 是相对于当前工程所在目录的路径，或者是相对于当前文件所在目录的路径，在编译选项的设置中也有这样的路径。 而下面一行代码： OpenFile(“..\\abc.ini”); 则是相对于运行时可执行文件所在目录的路径，或者是相对于你为当前程序设置的工作目录的路径。 实践总结：信息管理系统1、不同类型项目的目录结构不尽相同，linux下c语言信息管理系统的一个典型的目录结构如下（不使用IDE开发）： - testDir ——include（头文件目录） ——res（资源文件） ——src（源代码文件） ——lib（库文件） ——bin（编译结果的可执行程序文件） ——config（配置文件） 注：文件名小写简称为好，方便输入 Linux内核源代码2、Linux内核源代码的组成如下（假设相对于linux目录）： - kernelDir include—— 这个目录包括了核心的大多数include文件。另外对于每种支持的体系结构分别有一个子目录 lib—— 此目录包含了核心的库代码。与处理器结构相关库代码被放在arch//lib/目录下 arch—— 这个子目录包含了此核心源代码所支持的硬件体系结构相关的核心代码。如对于X86平台就是i386 init—— 此目录包含核心启动代码 mm—— 此目录包含了所有的内存管理代码。与具体硬件体系结构相关的内存管理代码位于arch//mm目录下，如对应于X86的就是arch/i386/mm/fault.c drivers—— 系统中所有的设备驱动都位于此目录中。它又进一步划分成几类设备驱动，每一种也有对应的子目录，如声卡的驱动对应于drivers/sound ipc—— 此目录包含了核心的进程间通讯代码 modules—— 此目录包含已建好可动态加载的模块 fs—— Linux支持的文件系统代码。不同的文件系统有不同的子目录对应，如ext2文件系统对应的就是ext2子目录 kernel—— 主要核心代码。同时与处理器结构相关代码都放在arch/*/kernel目录下 net—— 核心的网络部分代码。里面的每个子目录对应于网络的一个方面 scripts—— 此目录包含用于配置核心的脚本文件 Documentation—— 此目录是一些文档，起参考作用","categories":[{"name":"未分类","slug":"未分类","permalink":"https://www.delta1037.cn/categories/未分类/"}],"tags":[]},{"title":"Mysql error2002","slug":"mysql-error2002","date":"2018-01-31T04:08:08.000Z","updated":"2019-10-18T08:19:37.336Z","comments":true,"path":"2018/01/31/mysql-error2002/","link":"","permalink":"https://www.delta1037.cn/2018/01/31/mysql-error2002/","excerpt":"","text":"Mysql error2002配置 DigtalOcean Ubuntu17.04 Mysql5.7* Wordpress 问题 查看网站时显示连接数据库错误 后台登录Mysql显示 ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’ (2) 解决 内存不足。。。 参考链接-增加交换区 生成交换空间 $ sudo fallocate -l 4G /swapfile 查看生成的文件 $ sudo ls -lh /swapfile 输出的内容 $ -rw-r--r-- 1 root root 4.0G Apr 28 17:19 /swapfile 更改文件的权限 $ sudo sudo chmod 600 /swapfile 设置交换空间并使交换空间可用 $ sudo mkswap /swapfile$ sudo swapon /swapfile 查看设置结果 $ free -m","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"},{"name":"Bug","slug":"Linux/Bug","permalink":"https://www.delta1037.cn/categories/Linux/Bug/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.delta1037.cn/tags/mysql/"}]},{"title":"Protocol","slug":"protocol","date":"2018-01-29T13:33:54.000Z","updated":"2019-08-03T13:37:26.188Z","comments":true,"path":"2018/01/29/protocol/","link":"","permalink":"https://www.delta1037.cn/2018/01/29/protocol/","excerpt":"","text":"读协议森林协议森林 分两部分两台计算机上的通信所使用的协议：物理层：传输物理信号 链路层：信息以帧为单位传输，帧中包括收信地址和送信地址以及校验序列和数据（记录起点地址和终点地址） 网络层：理解两种帧格式，让不同网络上的计算机进行通信（记录计算机one，WiFi接口，以太网接口，计算机two） - 路由器：一个路由器有多块网卡，每个网卡接入到一个网络，并理解相应的连接层的协议，在帧经过路由到达另一个网络的时候，路由器就会读取帧的信息并改写发送到另一个网络 同一台计算机上的应用与外界通信协议：传输层：每个进程有自己的通信需求，传输层协议使用端口号来识别通信的进程 表示层：把数据转换为能与接收者的系统格式兼容并适合传输的格式 会话层：负责在数据传输中设定和维护电脑网络中两台电脑之间的通讯连接 应用层：规范某个进程通信的格式，提供为应用软件而设的接口，以设定与另一应用软件之间的通讯。例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3等 各层协议全部协议参见wiki 链路层以太网以太网的帧格式 头部：最初的七个字节被成为序言。序言是为了让接受设备调整好接受频率（时钟复原）。随后是目的地和出发地。最后是Type，说明数据部分的数据类型 数据：一般包含更高层协议的数据，例如IP包。数据尾部可能填充０，因为一个帧需要超过最小长度 尾部：校验序列，检验数据的传输是否发生了错误 集线器（Hub） Vs 交换器（Switch）集线器向所有的端口转发数据，这样连接在同一个集线器的设备都能知道别人在传输什么，并且不允许集线器上的两台设备同事进行通信 交换器记录各个设备的ＭＡＣ地址，只将帧转发到对应的端口 WIFIWIFI与集线器连接下的以太网类似，一个WIFI设备会向所有的WIFI设备转发帧 网络层IP协议ARP地址解析协议ARP协议介于链路层和网络层之间，每台主机上都有ARP chache，用来存储局域网IP与MAC地址如何对应。 ARP包包裹在一个帧中，以广播的形式询问局域网上所有的主机和路由，发送自己的IP与MAC地址，最终ARP chache达到稳定。 ICMP协议 功能：传输网络诊断信息 分类：错误信息／咨询类信息 ICMP包结构：１．Type：ICMP包大的类型；２．Code：Code是Type内可以细分的小的类型；３．Checksum：校验整个ICMP包 传输层TCP协议UDP协议","categories":[{"name":"协议","slug":"协议","permalink":"https://www.delta1037.cn/categories/协议/"},{"name":"计算机网络","slug":"协议/计算机网络","permalink":"https://www.delta1037.cn/categories/协议/计算机网络/"}],"tags":[{"name":"protocol","slug":"protocol","permalink":"https://www.delta1037.cn/tags/protocol/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.delta1037.cn/tags/计算机网络/"}]},{"title":"短信收发功能分析","slug":"短信收发功能分析","date":"2018-01-01T15:21:28.000Z","updated":"2019-08-03T13:37:27.020Z","comments":true,"path":"2018/01/01/短信收发功能分析/","link":"","permalink":"https://www.delta1037.cn/2018/01/01/短信收发功能分析/","excerpt":"","text":"转载请联系作者 短信接收与发送功能分析*华中科技大学 摘要本文主要介绍了短信的发送与接收功能，其中包含发信端向短信中心发送短信的过程、短信中心相互转发短信的过程，短信中心向收件人发送短信的过程，具体介绍了这三者之间的连接过程和网关在这三者之间的作用；此外介绍了短信中心的存储转发模式、网关、寄存器、移动交换中心、如何确认收件人的位置和不同的传输模式，具体介绍了网关在安全性方面的作用和短信发送所采用的协议；然后，简单介绍了短信的几种加密算法，并分析了算法的原理和不安全性体现；最后介绍了短信的发展过程，及其在发送内容方面的进步，和各种短信业务的分类及其简单介绍了在发送过程中路线的不同。 关键词：短信 发送 接收 短信协议 加密算法 短信发展 1.短信的发送与接收1.1手机编辑短信发送到短信中心1.1.1从手机编辑短信到发送到短信中心的大体流程首先发送端编辑短信，并且填写收件人的号码，然后手机内的芯片对文字信息进行编码，向串口写相应的AT指令，然后将信息传递到基带，由调制解调器调制成电磁波，最后该电磁波发送到短信中心。 1.1.2客户端与短信中心验证流程a．首先MS向MSC发起接入请求，其中包含MS的IMSI或TMSI号码；b，MSC向VLR发起接入请求，VLR在接入处理过程中可进行鉴权和加密；c，VLR向MSC回送接入证实消息；d，MSC向MS回送接入证实消息，允许MS进入GSM网络通讯；e，MS向MSC发送一条短消息，其中包含短消息的内容、目的SC地址；f，MSC向VLR查询MS是否可以发送短消息；g，VLR在确认MS具有短消息业务且没有被禁止后，通知MSC当前MS可以发送短消息，并提供MSISDN号码；h，MSC向IWMSC转发短消息，其中包含该条短消息的内容、源MS的MSISDN号码、目的SC地址；i，IWMSC向SC转发短消息，其中包含该条短消息的内容、源MS的MSISDN号码、目的SC地址；j，SC通知IWMSC已接受短消息；k，IWMSC通知MSC已接收短消息；l，MSC通知MS短消息发送成功。 1.1.3短信编码的规则对短信参数进行ＰＤＵ（ｐｒｏｔｏｃｏｌ ｄａｔａ ｕｎｉｔ）格式的编码，短信经过十六进制的编码后进行传送，其中不仅包含了消息字符，还包含了许多元数据，比如短信中心地址、字符编码格式、时间戳等 1.1.4关于短信字符的限制无论何时使用SS7协议的移动应用部分（MAP），SMSC和手机之间都会发送短消息。消息与MAP MO-和MT-ForwardSM操作，其有效载荷长度由信令协议的约束所限制发送以精确地140 个字节（140个字节×8比特/字节= 1120个比特），单条短信采用７位编码时最长可达１６０个字符，对于中文字符需要１６位编码，因此实际能发送的文本只有７０个字符，过长的短信会进行分割发送 1.2从短信中心到短信中心的转发1.2.1从短信中心到短信中心转发的大体过程首先短信中心对收到的信息进行初次解码，来确定收件人的号码和其他关键信息，然后以此来查找收件人的位置，然后将该短信发送到收件人所在位置的短信中心 1.2.2 短信中心的存储转发模式短信发出后先存储在ＳＭＳＣ（短信服务中心，ｓｈｏｒｔ ｍｅｓｓａｇｅ ｓｅｒｖｉｃｅ ｃｅｎｔｅｒ），然后由短信中心将短信信息发送给接收方，如果接收方不在服务区，ＳＭＳＣ就会自动保存该信息，等到接收方出现在服务区时再发送 1.2.3 网关（SMCGMSC）的作用获取来自SMSC传递的短消息，通过HLR读取路由信息，符合传送条件后，将SMS消息发送给收件人所处的基站 1.2.4归属地位置寄存器（HLR）归属地位置寄存器，用于存放和管理移动用户的相关信息，移动设备所在位置信息同样保存在HLR，HLR每隔一段时间就会记录位置信息，采用这样的机制，当进行服务时可以迅速查到收件人 1.2.5移动交换中心（MSC）移动交换中心，管控数据的连接与传送，当用户从一个服务区转至另一个服务区时，可以对区域进行切换 1.2.6 关于收件人位置的确定尽管您没有使用手机打电话，您的手机也在不停地发送和接收着信息。它通过被称为控制通道的通路与手机发射塔进行通信。这种通讯的目的是让手机系统了解自己所在的信号区域，以便在您移动时，手机可以切换到其他信号区域。每隔一段时间，手机和发射塔将交换数据包以确定一切工作正常。 1.2.7 跨网传输与同网传输跨网传输：不同运营商的短信中心之间相互发送，首先发信人先将信息发送到收信人运营商的短信中心，发送人运营商的短信中心将信息发送给收信人运营商的短信中心，收信人的短信中心再将该信息发送给收信人。 同网传输：相同运营商的短信中心之间互相发送，首先发信人将信息发送到短信中心，短信中心再将该信息发送给收信人。 1.3从短信中心到发送到收件人的手机中1.3.1从短信中心到发送到收件人手机的大体过程用户手机定时器触发开始读串口数据进行判断，当串口没有数据时，等待下一次定时器触发；当短信中心向收件人发送电磁波即串口有数据时，将串口的数据读入，然后收件人对收到的数据进行解码，最后对PDU编码的数据解析成文本，在手机端以UI界面显示 1.3.1接收端与短信中心的相互验证流程a, SC向GMSC发送短消息，其中包含短消息的内容、源SC地址、目的MS的MSISDN号码，另外还有SC存在短消息等待发送标识；b. GMSC向目的MS所属的HLR查询路由信息；c, HLR向GMSC返回查询结果，有两种情况：成功，返回路由信息其中包含目的MS所在的MSC号码，以及目的用户的IMSI、LMSI号码;;失败，返回错误原因，可能同时返回Alert_MSISDN号码。d. GMSC根据获得的路由信息向目的MSC发送短消息，其中包含短消息内容、源SC地址、目的MS的IMSI或LMSI号码；e. MSC向VLR查询目的MS的相关信息，包括MS是否可及等标志位；f. VLR向MSC发送寻呼请求消息，要求建立无线连接；g. MSC收到VLR的寻呼请求后，向MS发送寻呼请求；h. MS寻呼成功，进行接入过程；i. MSC发送接入请求消息通知VLR寻呼成功；j. VLR完成对MS的鉴权、数据的更新以及加密等操作后，通知MSC接入成功；k. MSC向MS发送接入证实消息；l. MSC向MS转发短消息，其中包括短消息内容和源SC地址；m. MS向MSC返回短消息成功接收消息；n. MSC通知GMSC，MS已成功接收短消息；o. GMSC通知SC，MS已成功接收短消息。行判断；当数据中有新短信的提示符时，按照ＰＤＵ短信的解码格式对该短信进行解码，并调用ＵＩ界面提示新短信到达 1.4短信的双向传输模式ＳＭＳ对发送的消息进行可靠的双向传输，即ＳＭＳ发送消息后会受到确认信息，获得发送的结果，对于不同的结果即发送成功或者发送失败会显示不同的信息给发送方 1.5短信的传输同步功能ＳＭＳ传输的同步性，即ＳＭＳ可以与数据、语音等业务一起进行同步传输，即便在业务信道数据量处于高峰时也能保证信息的顺利发送 1.6短信的PTP模式Ｐｅｅｒ ｔｏ ｐｅｅｒ的通信方式，发送方只需要知道对方的手机号码，就可以给对方发送信息，就先计算机的ｉｐ地址一样，一旦绑定，就可以通过该地址与其他地址建立连接 1.7 无状态通信SMS是一种无状态通信协议，其中每个SMS消息被认为完全独立于其他消息。使用SMS作为有状态对话（其中MO应答消息与特定MT消息配对）的通信信道的企业应用要求会话管理在协议外部维护 1.8 短信所采用的协议1.8.1 协议名称ＳＭＰＰ（ｓｈｏｒｔ ｍｅｓｓａｇｅ ｐｅｅｒ ｔｏ ｐｅｅｒ ｐｒｏｔｏｃｏｌ），对等短信信息协议 1.8.2 协议的功能1）定义了外部短信信息实体ＥＳＭＥ与短信息中心ＳＭＳＣ的数据通信接口 2）在ＥＳＭＥ和ＳＭＳＣ之间定义一系列的短信息交换操作 3）在ＥＳＭＥ和ＳＭＳＣ之间定义ＥＳＭＥ和ＳＭＳＣ交换的数据格式 1.8.3 各个运营商对协议的拓展各运营商基于ＳＭＰＰ协议开发了适合自己的协议标准：中国移动的ＣＭＰＰ协议，中国联通的ＳＧＩＰ协议，中国电信的ＳＭＧＰ协议 1.9 短信的发送与接收手机的信号频率很高，一般在900Mhz左右，靠电离层反射传播，打电话的手机信号传到最近的基站，也就是移动或者连通的信号塔，再由基站把高频信号频率降低，由基站和基站之间通信，这个信号是直线传播，遇到高的建筑物会被挡住，所以那些塔都竖的很高，传到接电话的手机附近的基站，再转成高频信号发给手机。 1.10 短信网关1.10.1 短信网关简介短信网关ISMG全称Internet Short Message Gateway，主要是为了解决各网络、各运营商之间的短信互通和SP的接入问题。它为使用单位收发短信而提供的一个动态数据交换平台系统。通过该系统的接口软件，可以将短信平台与各种系统和软件进行无缝高效相连，将应用单位的系统随时产生的动态信息转变成手机短信，通过梦网平台连接移动和联通的短信中心以端口特服号码进行实时中发送和接受，为各种系统（或软件）建立一个快速的短信双向（或单向）通道，以便手机用户采用短信方式与SP双向通信，接收SP提供的信息服务。 1.10.2 短信网关的组成及其功能短信网关各组成部分的功能为： （1）SMPP代理系统遵循SMPP 3.3版本协议与GSM网中短消息中心连接，实现高效、可靠的数据传输。该系统支持流量控制功能，能够根据SMSC的业务量进行发送流量控制。 （2）通信代理系统实现与SP等内容供应商的连接和协议互通。它基于TCP/IP协议基础之上，利用CMPP协议与SP之间建立一条安全、高效的传输通道。该系统支持流量控制功能，能够根据本身的业务量进行接收流量控制。 （3）防火墙作为短信网关的重要功能组成部分，其功能是对短信网关内部其它相关模块进行保护，实现针对内外访问的包过滤和代理。 （4）短消息网关处理系统完成网关的业务处理，包括：向汇接网关进行路由查询，在本地建立短信网关ID、用户手机号码、SP ID及其IP地址对应表的缓存，建立用户手机号码段与SMSC（短信中心）地址的对应表，完成对数据分发功能的支持、计费原始话单的提供及处理等。 （5）短信网关计费系统提供短信网关的原始话单记录（CDR）。 （6）业务管理系统包括业务管理和网关监控功能。 1.10.3 短信网关与短信中心的连接短信网关与短信中心之间应采用专线方式互联 1.10.4 短信网关的安全性短信网关在硬件和软件结构设计上应采用分布式、模块化的设备，其中硬件设备可考虑采用多台主机，在网络上利用四层交换机实现负载分担工作，避免单点故障，实现设备的安全。 同时短信网关采用防火墙技术，可以支持IP包过滤和应用代理方式，防止外界的攻击，实现信息的安全。 短信网关与SP在进行CMPP协议的连接建立时，采用MD5对互相的身份进行认证，实现业务的安全。 短信网关与短信中心、计费中心之间的连接都采用专线方式，而且与计费中心的连接还要求计费中心侧加入防火墙，保障了现网设备的安全性不会由于与短信网关的连接而降低。 2.短信的安全性2.1 GSM标准的加密算法对于ＧＳＭ标准所使用的加密算法，短信的安全性已经被证实是不堪一击的，通过暴力破解可在２的３２次方时间内解出短信的具体内容， 2.2 GSM算法的改进可以使用强加密的ＣＤＭＡ标准，用于保密信息的传输 2.3 A5/1算法2.3.1 算法简介A5 / 1是用来产生为每个脉冲串的114位序列的密钥流被进行异或之前调制与114位。A5 / 1使用一个64位的密钥和一个公认的22位帧号进行初始化。使用Comp128v1进行密钥生成的老式GSM实现有10个密钥位固定为零，从而产生有效的密钥长度的54位。这个弱点通过Comp128v2的引入得到纠正，该Comp128v2产生适当的64位密钥。 2.3.2 算法的破解利用了GSM通信加密中的两个安全漏洞，并且在普通商用硬件的帮助下，花费了55天的时间计算出了一个彩虹表。这个彩虹表的大小为984GB。得到了彩虹表之后，安全专家就可以在短短的九秒内确定用于加密通信数据的密钥了。 2.4 A5/2算法密码基于四个带有不规则时钟的线性反馈移位寄存器和一个非线性组合器的组合 2.5 A5/3算法（KASUMI）KASUMI算法在3GPP技术规范中规定。KASUMI是128位密钥和64位输入和输出的分组密码。KASUMI的核心是一个八轮Feistel网络。主要Feistel网络中的轮函数是不可逆的类Feistel网络变换。在每一轮中，循环函数都使用一个循环密钥，该循环密钥由使用固定密钥调度从原始128位密钥导出的八个16位子密钥组成。 2.6 短信不安全方面a.通过固定网络传输的通信数据没有受到加密保护；b.无法抵御某些主动攻击；c.只有连接至安全的固定网络才可以保证GSM的通信安全；d.GSM中的合法拦截只是一种事后补救措施；e.终端识别码不可信任。 3.短信的发展及其分类3.１．SMS短信仅支持发送文本，根据发送对象和客户是否处理漫游状态，基础短信业务可分为网内点对点短信、网间点对点短信、国际短信、短信国际漫游。 3.2. 移动梦网短信业务移动梦网短信业务是移动梦网服务的重要组成部分，是中国移动向客户提供的基于移动梦网短信平台的数据应用服务总称。移动梦网短信业务由与中国移动签约的合作伙伴提供，目前已接入数百家内容提供商（简称SP），提供了数万种业务。 3.3．ＥＭＳ短信可以支持发送格式文本、音效、小型图片、以及照片。其中音效是语音短信业务，语音短信业务是指把你想说的话语通过固定电话、小灵通或者手机进行录音，发给一个或多个用户进行收听你的留言，同时，你还可以根据电话的提示音，进行语音短信的接收、转发、查询、回复和语音短信点播等操作。它弥补了传统的文字短信难以传递声音和信息输入不便的缺憾，解决了那些因为不熟悉拼音使用，长时间徘徊在短信之外的人们发送短信的难题，也有效地解决了电话、小灵通或手机与之间发送短信的互联互通问题。 3.4．ＭＭＳ彩信可以支持文本短信息、动画、音频、视频文件。彩信的英文名是MMS，它是Multimedia Messaging Service的缩写，意为多媒体信息服务，通常又称为彩信。它最大的特色就是支持多媒体功能，能够传递功能全面的内容和信息，这些信息包括文字、图像、声音、数据等各种多媒体格式的信息。 彩信在技术上实际并不是一种短信，而是在GPRS网络的支持下，以WAP无线应用协议为载体传送图片、声音和文字等信息。彩信业务可实现即时的手机端到端、手机终端到互联网或互联网到手机终端的多媒体信息传送。 4.短信业务的分类１．网内点对点通信用户在手机上编辑信息内容，输入对方手机号码，选择发送将一条短信发送到接收方手机的短信业务，单条最大长度为140个字节，或者70个中文字符 ２．网间短信业务中国移动和中国联通实现短信的互联互通，移动用户和联通用户可通过手机发送短信 ３．国际短信中国移动和全球89个国家和地区的134个移动运营商实现了短信互通，即移动用户可以和港澳台、东南亚、北美、南美等国家和地区的主要移动运营商的用户收发短信 ４．短信国际漫游中国移动用户漫游与中国移动签署了GSM漫游协议的国家和地区后，可以使用当地移动网络和国内移动用户收发短信 5.参考文献 [1] 维基百科SMS https://en.wikipedia.org/wiki/SMS [2] 互动百科 短信http://www.baike.com/wiki/%E7%9F%AD%E4%BF%A1 [3] 维基百科 KASUMI算法 https://en.wikipedia.org/wiki/KASUMI [4] 智能手机电话短信实验模块设计http://rf.eefocus.com/article/id-257105 [5] 短信平台在移动办公中的设计与实现https://wenku.baidu.com/view/91d83d987f1922791788e800.html [6] 多媒体短信https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%AA%92%E9%AB%94%E7%9F%AD%E8%A8%8A [7] 移动CMPP通信原理及短信协议解析https://wenku.baidu.com/view/53dba4ee9b89680203d82549.html?re=view [8] 移动网络名词理解http://m.blog.csdn.net/karen_wang/article/details/7650433","categories":[{"name":"SMS","slug":"SMS","permalink":"https://www.delta1037.cn/categories/SMS/"}],"tags":[{"name":"SMS","slug":"SMS","permalink":"https://www.delta1037.cn/tags/SMS/"},{"name":"短信","slug":"短信","permalink":"https://www.delta1037.cn/tags/短信/"}]},{"title":"2018","slug":"2018-2","date":"2018-01-01T15:05:12.000Z","updated":"2019-08-03T13:37:24.056Z","comments":true,"path":"2018/01/01/2018-2/","link":"","permalink":"https://www.delta1037.cn/2018/01/01/2018-2/","excerpt":"","text":"To 2018 不要老是宅在学校，老是看书看漫画动漫。。。武汉的那些奇奇怪怪的街，或许很有趣呢，，，倒是出去过几次，走在繁华的街上，人来人往，有几丝惊恐，算了编不下去了。。。下次勇敢点! 是这座城接纳不了自己，还是自己接纳不了这座城。 哦～ 下学期要好好听课……这学期废了，听课率估计不到1%，期末预习真的是鸭梨大，，， 不要老是去想一些乱七八糟的事情，好好规划自己，虽然不想被灌输一些奇怪的知识，但还是要收拾好自己，知道自己要做什么 怎么感觉和别人老是沟不通呢……难道是API有问题么，，， 找找心在哪咯，，， 就酱，就这些。。。 最近好像能看懂诗集了，，语文老师看到这儿…肯定会大吃一鲸的吧…… 等会儿复制下再圈个重点//期末预习过度后遗症 谢谢大佬送的肯德基日历～","categories":[{"name":"未分类","slug":"未分类","permalink":"https://www.delta1037.cn/categories/未分类/"}],"tags":[]},{"title":"解决phpstorm在浏览器打开预览遇到502","slug":"解决phpstorm在浏览器打开预览遇到502","date":"2017-12-12T04:46:07.000Z","updated":"2019-08-03T13:37:27.448Z","comments":true,"path":"2017/12/12/解决phpstorm在浏览器打开预览遇到502/","link":"","permalink":"https://www.delta1037.cn/2017/12/12/解决phpstorm在浏览器打开预览遇到502/","excerpt":"","text":"解决phpstorm在浏览器打开预览遇到502FIRST STEP:若看到phpstorm右下角有提示php-cgi未安装，则运行 $ sudo apt-get install php-cgi 安装这个插件 SECOND STEP:打开setting-&gt;Language &amp; Frameworks -&gt;PHP 配置CLI Interpreter点击右侧选择目录，PHP executable 路径填 /usr/bin/php7.0 配置Include Path下面的Include Path 填 /etc/php/7.0/cli/conf.d 以上两条路径或者按照你的安装路径来填 我的php安装的目录有权限不能访问，如果你们同样遇到权限问题可用chmod和chown来修改该目录的权限","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.delta1037.cn/categories/Ubuntu/"}],"tags":[{"name":"502","slug":"502","permalink":"https://www.delta1037.cn/tags/502/"},{"name":"phpstorm","slug":"phpstorm","permalink":"https://www.delta1037.cn/tags/phpstorm/"}]},{"title":"Permission denied (publickey)","slug":"解决permission-denied-publickey-问题","date":"2017-12-06T14:34:54.000Z","updated":"2019-10-18T08:19:50.136Z","comments":true,"path":"2017/12/06/解决permission-denied-publickey-问题/","link":"","permalink":"https://www.delta1037.cn/2017/12/06/解决permission-denied-publickey-问题/","excerpt":"","text":"Permission denied (publickey)问题描述在用Linux终端使用ssh root@server_ip来连接到远程服务器时，出现Permission denied (publickey).提示 问题原因首先ssh连接服务器是需要一对秘钥的，包括私钥和公钥，私钥（~/.ssh/id_rsa）保存在本地服务器上，而公钥（~/.ssh/id_rsa.pub）保存在远程服务器上（~/.ssh/authorized_keys文件内）。当使用ssh进行连接时，本地向远程服务器发起连接，服务器会随机生成一个字符串发送给登陆的用户（发起登陆的客户端），用户对该字符串使用私钥加密之后发送给服务器，服务器使用公钥对加密后的字符串解密，如果解密后的字符串与之前发送给客户端的字符串一致，则判断为登陆成功。 综上，Permission denied(publickey)的问题可能如下1、远程服务器没有添加公钥2、远程服务器公钥文件夹权限错误 一、公钥没有添加如果服务器端根本就没有添加公钥是断然不可能通过认证的 Solution客户端已经有秘钥对：通过其它方式登录到远程服务器，查看~./ssh/authorized_keys文件中是否添加了公钥，若没有可直接将公钥内容拷贝到该文件末尾客户端没有秘钥对：通过ssh-keygen命令生成秘钥对，默认文件夹是~/.ssh文件夹，将.ssh文件夹内id_rsa.pub的内容拷贝到服务器上的~./ssh/authorized_keys文件末尾（若服务器上~./ssh/authorized_keys不存在则也可以使用ssh-keygen来生成文件结构） 二、远程服务器.ssh权限问题远程服务器~/.ssh文件夹及其文件权限不对，包括1、authorized_keys文件权限2、.ssh文件夹权限3、.ssh文件夹所有权 Solution通过其它方式登录到远程服务器，如果是阿里云则可以在网页中通过验证之后打开一个终端，然后进行如下操作 更改文件所有权 12$ chown -R your_user:your_user ~/.ssh //我用root登录，your_user是root 更改文件夹权限 1$ chmod 700 ～/.ssh 更改authorized_keys文件权限 1$ chmod 600 ~/.ssh/authorized_keys 参考文献 https://askubuntu.com/questions/311558/ssh-permission-denied-publickey","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/categories/Linux/"},{"name":"Bug","slug":"Linux/Bug","permalink":"https://www.delta1037.cn/categories/Linux/Bug/"}],"tags":[{"name":"Permission denied","slug":"Permission-denied","permalink":"https://www.delta1037.cn/tags/Permission-denied/"},{"name":"ssh","slug":"ssh","permalink":"https://www.delta1037.cn/tags/ssh/"}]},{"title":"美化Ubuntu","slug":"美化ubuntu","date":"2017-12-05T11:59:32.000Z","updated":"2019-08-03T13:37:27.172Z","comments":true,"path":"2017/12/05/美化ubuntu/","link":"","permalink":"https://www.delta1037.cn/2017/12/05/美化ubuntu/","excerpt":"","text":"Ubuntu美化（安装macUbuntu主题）推荐一个装双系统的博客：最近刚装了双系统，重新布置了下Ubuntu的界面，这个博客不错，装双系统可以看一下http://blog.csdn.net/fesdgasdgasdg/article/details/54183577 下载壁纸略。。。（壁纸好看就行了17 张程序员壁纸推荐） 下载主题图标等tip:使用install安装时可能会出现找不到这个安装包的问题，可以使用‘星’符（正则表达式匹配） $ sudo apt-get install macbuntu* 来看本地有哪些包可以安装 $ sudo add-apt-repository ppa:noobslab/macbuntu $ sudo apt-get update $ sudo apt-get install macbuntu-os-icons-lts-v7 $ sudo apt-get install macbuntu-os-ithemes-lts-v7 安装Plank Dock$ sudo apt-get install plank 将plank添加到开机启动-&gt;使用gnome-session(启动器中搜索,打开并将启动命令填入) unity-tweak-tool 安装并打开unity-tweak-tool，修改安装的主题 个人认为可以添加热区使鼠标移到此位置时可以平铺打开的所有界面，及其方便界面之间的切换 另附想要继续美化可以参考第一个链接，可能需要科学上网，鄙人认为只要有plank方便操作就可以了 终端配置简书：五分钟入门Terminator 安装新字体 将新字体拷入/usr/share/fonts中 运行以下命令更新字体缓存 $ sudo fc-cache -f -v 参考链接 http://www.noobslab.com/2016/04/macbuntu-1604-transformation-pack-for.html -http://www.linuxidc.com/Linux/2016-06/131947.htm","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.delta1037.cn/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.delta1037.cn/tags/Ubuntu/"},{"name":"美化","slug":"美化","permalink":"https://www.delta1037.cn/tags/美化/"}]},{"title":"MPI笔记","slug":"mpi笔记","date":"2017-11-10T11:56:08.000Z","updated":"2019-08-03T13:37:25.676Z","comments":true,"path":"2017/11/10/mpi笔记/","link":"","permalink":"https://www.delta1037.cn/2017/11/10/mpi笔记/","excerpt":"","text":"OpenMP和OpenMP区别 OpenMP：支持内存共享的单机多核 OpenMPI：集群计算 多个线程同时工作 降低解决问题的运行时间 增大要解决问题的尺度 把要解决的问题分解到一些子任务 -理想状态是各个子任务之间可以互不影响工作 把任务映射到不同的进程 参考链接： MPI 分布式编程 MPI 学习笔记","categories":[{"name":"未分类","slug":"未分类","permalink":"https://www.delta1037.cn/categories/未分类/"}],"tags":[]},{"title":"9.27~10.28计划","slug":"9-2710-28计划","date":"2017-09-27T05:54:59.000Z","updated":"2019-08-03T13:37:24.140Z","comments":true,"path":"2017/09/27/9-2710-28计划/","link":"","permalink":"https://www.delta1037.cn/2017/09/27/9-2710-28计划/","excerpt":"","text":"本月计划：9.27-10.1：1）学习机器学习算法–贝叶斯，向量机；学习对数据的处理 2）学习Python的基本语法结构，能够理解Python写的机器学习程序 3）算法导论学习29章线性规划 10.1-10.7：1）完善多线程的知识结构，参考深入理解计算机系统的网络编程和并发编程，将socket服务端改写出一个多线程程序 2）算法导论30-31章多项式与快速傅里叶变换和数论算法，解决15-16章动态规划和贪心算法题目，理解红黑树删除部分 3）深入理解计算机系统复习第三章程序的程序级表示，学习第四章处理器体系结构，了解汇编语言内部原理 4）CTK+，改写计算器程序，有图形页面 5）解决ping解包错误问题 6）编译时自己写makefile和CMakeList.txt 10.8-10.14：1）学习Linux系统管理 2）算法导论第32章字符串匹配，写23-24关于树的题目 3）深入理解计算机系统第五章-优化程序性能，写3-4章课后习题 10.15-10.21：1）学习TCP/IP 2）算法导论34章-NP完全性，写二叉树和红黑树题目 3）深入理解计算机系统第六章-存储器的层次结构，第五章课后习题 10.22-10.28：1）继续学习shell脚本，完善知识体系的不足 2）算法导论35章-近似算法，写数论算法的题目 3）深入理解计算机系统第七章-链接，第六章课后习题 总计划：每日一道leetcode，若easy则两道，以理解为主 吾志所向,一往无前 愈挫愈勇,再接再厉","categories":[{"name":"计划","slug":"计划","permalink":"https://www.delta1037.cn/categories/计划/"}],"tags":[]},{"title":"状态机","slug":"状态机","date":"2017-09-13T09:24:11.000Z","updated":"2019-08-03T13:37:26.944Z","comments":true,"path":"2017/09/13/状态机/","link":"","permalink":"https://www.delta1037.cn/2017/09/13/状态机/","excerpt":"","text":"参考文献 有限状态机状态机：表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型 有限状态机的下一个状态和输出，是由输入和当前状态决定的。 分类：接收器和识别器：接收器和识别器（序列检测器）产生一个二元输出，是或者否回答输入是否被机器接受，所有有限状态机的状态是称为接受或者不接受。 在所有处理都被处理，若当前状态是接受状态，输入被接受，否则被拒绝。 开始状态：一个没有起点的箭头 接受（最终）状态：接受状态（最终状态）是机器回报到目前为止，输入的字符串属于它所接收的内容之状态，状态图中通常将其标注为双圆圈 开始状态也可以是接受状态，此情况下自动机会接受空字符串，。如果开始状态不是接受状态，且没有可以连到任何接受状态的箭头，那么此自动机就不会“接受”任何输入 变换器：两种变换器： 1.Moore机，摩尔型有限状态机。 只使用进入动作的有限状态机，也就是输出只依赖于状态 2.Mealy机，米莉型有限状态机。 只使用输入动作的有限状态机，也就是输出依赖于输入和状态","categories":[{"name":"状态机","slug":"状态机","permalink":"https://www.delta1037.cn/categories/状态机/"}],"tags":[{"name":"状态机","slug":"状态机","permalink":"https://www.delta1037.cn/tags/状态机/"}]},{"title":"关于Ubuntu右上角无线有线图标消失","slug":"关于ubuntu右上角无线有线图标消失","date":"2017-09-02T14:01:58.000Z","updated":"2019-08-03T13:37:26.656Z","comments":true,"path":"2017/09/02/关于ubuntu右上角无线有线图标消失/","link":"","permalink":"https://www.delta1037.cn/2017/09/02/关于ubuntu右上角无线有线图标消失/","excerpt":"","text":"打开配置文件 sudo gedit /etc/NetworkManager/nm-system-settings.conf 把false改成true 重启该服务： sudo service network-manager restart","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.delta1037.cn/categories/Ubuntu/"}],"tags":[{"name":"图标","slug":"图标","permalink":"https://www.delta1037.cn/tags/图标/"}]},{"title":"Posix笔记","slug":"posix笔记","date":"2017-08-28T10:54:52.000Z","updated":"2019-08-03T13:37:26.104Z","comments":true,"path":"2017/08/28/posix笔记/","link":"","permalink":"https://www.delta1037.cn/2017/08/28/posix笔记/","excerpt":"","text":"由于硬件提供商会实现线程的硬件专用版本，为了使线程程序可移植，需要标准的线程编程接口：POSIX threads或者Pthreads Pthreads库被定义为一系列的c语言程序类型和过程调用，是用pthreads的include头文件和一个线程库来实现的 使用Pthreads的目的 使获得潜在的程序执行性能变成现实 当与创建和管理进程的代价相比较时，线程创建时只需要更小的系统开支，管理线程比管理进程需要更少的系统资源 进程内的所有线程共享相同的地址空间 线程的创建与取消： 创建线程： int pthread_create(pthread_t thread, pthread_attr_t attr, void (\\start_routine)(void *), void * arg) pthread_create()创建的线程不具备与主线程(调用pthread_create()的线程)同样的执行序列，而是使其运行start_routine(arg)函数 thread返回创建线程的ID，attr是创建线程时设置的线程属性 pthread_create()的返回值表示线程是否创建成功。 arg是void_类型变量，但是可以作为任意类型的参数传给start_routine()函数；start_routine()返回一个void_类型的返回值，这个值可以是其它类型，由pthread_join()获取 attr参数是一个结构指针","categories":[{"name":"多线程","slug":"多线程","permalink":"https://www.delta1037.cn/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://www.delta1037.cn/tags/多线程/"},{"name":"posix","slug":"posix","permalink":"https://www.delta1037.cn/tags/posix/"}]},{"title":"OpenMP","slug":"openmp","date":"2017-08-28T02:42:58.000Z","updated":"2019-08-03T13:37:25.848Z","comments":true,"path":"2017/08/28/openmp/","link":"","permalink":"https://www.delta1037.cn/2017/08/28/openmp/","excerpt":"","text":"进程与线程 进程：进程是正在运行的程序实例 线程：线程是进程中实际运作单位，一个进程可以并行多个线程 进程包含如下程序资源和程序执行状态信息： 进程ID/环境/工作目录/程序指令/寄存器/栈/堆/文件描述符/信号动作/共享库/进程间通信工具（消息队列，管道，信号量，共享内存） 线程使用和在进程中生存，仍有操作系统来安排并且独立的实体来运行，很大程度上是因为他们为可执行代码的存在复制了刚刚好的基本资源 这个独立的控制流之所以实现，是因为线程维护着： 栈指针/寄存器/调度属性(规则和优先级)/等待序列和阻塞信号/线程拥有的数据 Unix环境中线程的特点： 生存在进程中，并使用进程资源 拥有独立的控制流，前提是它的父进程还存在，并且操作系统支持它 它仅仅复制可以使他调度的必要的资源 他可能会同其它与之同等独立的线程分享进程资源 如果父进程死掉那么它也会死掉 它是轻量级的，因为大部分的开支已经在它的进程创建时完成了 由于在同一个进程内的线程分享资源： 一个线程对共享的系统资源做出改变会被其它线程看到 指向同一个地址的两个指针的数据是相同的 对同一块内存进行读写操作是可行的，但是需要程序员明确的同步处理操作 OpenMP是MultiProcessing的缩写 作为框架或者说协议： OpenMP并不是一个简单的函数库，而是一个诸多编译器支持的框架，或者是协议，不需要任何配置 在编译程序时在末尾加上-fopenmp 循环的并行化： OpenMP提供一种简单的方式让人们不需要懂得创建和销毁线程就能写出来多线程的程序，为此设计了一些pragma，指令和函数让编译器在合适的地方插入线程太多的循环只要在for之前插入一个pragma就可以了 #pragma omp parallel for 每个循环被分配都被分配到了不同的线程，并且保证只执行一次，OpenMP决定了多少线程要打开，销毁和创建，需要做的就是告诉OpenMP哪里需要被线程化 OpenMP对多线程化的循环的要求： 循环的变量值必须是有符号整形 循环的比较条件必须是&lt; &lt;= &gt; &gt;=中的一种 循环的增量部分必须是增减一个不变的值 如果比较的符号是&lt; &lt;=，那么每次循环变量应该增加，反之减小 循环必须没有奇奇怪怪的东西，不能从内部循环跳到外部循环，goto和break只能在循环内部跳转，异常必须在循环内部被捕获 检测是否支持OpenMP： #ifndef _OPENMP fprintf(stderr,”OpenMP not supported”); #endif 避免数据依赖和竞争： 两个不同的迭代之间不能有依赖关系 当每次迭代都依赖于另一个不同的迭代，这被称为竞态条件 竞态条件很难被检测到 管理公有和私有数据： 当数据被设置为私有的时候，每个线程都有自己的一份拷贝 当数据被设置为公有的时候，所有的线程访问的都是相同的内存地址 默认情况下：除了循环变量以外，所有的数据都被设置为公有的 把变量设置为私有的方法： 在循环内部声明变量，注意不要是static的 通过OpenMP指令声明私有变量：#pragma cmp parallel for private（temp） Reductions： 一种常见的循环就是累加变量，循环内部有sum+=arry[i]; 为此OpenMP提供了reductions语句：#pragma cmp parallel for reductions是（+：sum） 在内部实现中，OpenMP为每个线程提供了私有的sum变量，当线程退出时，OpenMP再把每个线程的和加在一起得到最终结果 OpenMP不只能做累加，凡是累计计算都是可以的： 操作 私有临时变量初值 +，- 0 × 1 &amp; ~0 | 0 ^ 0 &amp;&amp; 1（true） || 0（false） 循环调度： 负载均衡是多线程程序中对性能影响最大的因素，只有实现负载均衡才能保证所有的核心都是忙的，而不会出现空闲时间，若没有达到负载均衡，一些线程早于其它线程结束，导致处理器空闲浪费优化的性能 在循环中由于每次迭代的时间差太大破坏负载均衡 默认情况下，OpenMP认为所有的循环迭代的运行时间都是一样的，导致了OpenMP会把不同的迭代等分到不同的核心上，并且让他们的分布尽可能地减少内存冲突，这样做是因为循环一般会线性的访问内存，所以把循环按照前一半后一半的方法分配可以最大程度来减少冲突，这最内存访问来说是最好的方法，但是对于负载均衡可能不是最好的方法，反过来最好的负载均衡可能也会破坏内存的访问，需要折中考虑 OpenMP负载均衡语法： #pragma omp parallel for schedule（kind[,chunk size]) kind 的类型，chunk size必须是循环不变的正整数","categories":[{"name":"多线程","slug":"多线程","permalink":"https://www.delta1037.cn/categories/多线程/"}],"tags":[{"name":"OpenMP","slug":"OpenMP","permalink":"https://www.delta1037.cn/tags/OpenMP/"},{"name":"多线程","slug":"多线程","permalink":"https://www.delta1037.cn/tags/多线程/"}]},{"title":"Ping笔记(二)","slug":"ping笔记二","date":"2017-08-24T10:57:13.000Z","updated":"2019-08-03T13:37:26.024Z","comments":true,"path":"2017/08/24/ping笔记二/","link":"","permalink":"https://www.delta1037.cn/2017/08/24/ping笔记二/","excerpt":"","text":"函数介绍(续)重要的函数: socketint socket(int family, int type, int protocol); 返回值:成功时返回文件描述符 / 失败时返回-1 头文件: #include &lt;sys/socket.h&gt; 函数作用:创建一个套接字 一般为了执行网络I/O，一个进程必须做的第一件事就是调用socket函数 函数参数第一个参数family：指明套接字中使用的协议族信息。 常见值有: 第二个参数type：指明套接口类型，也即套接字的数据传输方式。 常见值有: 在常见的使用socket进行网络编程中，经常使用SOCK_STREAM和SOCK_DGRAM，也就是TCP和UDP编程。在本项目中，我们将使用SOCK_RAW（原始套接字）。 原始套接字的主要作用在三个方面： 1.通过原始套接字发送/接收 ICMP 协议包。 2.接收发向本级的，但 TCP/IP 协议栈不能处理的IP包。 3.用来发送一些自己制定源地址特殊作用的IP包（自己写IP头）。 ping 命令使用的就是 ICMP 协议，因此我们不能直接通过建立一个 SOCK_STREAM或SOCK_DGRAM 来发送协议包，只能自己构建 ICMP 包通过 SOCK_RAW 来发送。 第三个参数 protocol：指明协议类型。 常见值有： 图片描述信息 参数 protocol 指明了所要接收的协议包。 如果指定了 IPPROTO_ICMP，则内核碰到ip头中 protocol 域和创建 socket 所使用参数 protocol 相同的 IP 包，就会交给我们创建的原始套接字来处理。 因此，一般来说，要想接收什么样的数据包，就应该在参数protocol里来指定相应的协议。当内核向我们创建的原始套接字交付数据包的时候，是包括整个IP头的，并且是已经重组好的IP包。如下所示： 图片描述信息 这里的数据也就是前面所说的时间戳。 但是，当我们发送IP包的时候，却不用自己处理IP首部，IP首部由内核自己维护，首部中的协议字段被设置成调用 socket 函数时传递给它的第三个参数。 我们发送 IP 包时，发送数据时从 IP 首部的第一个字节开始的，所以只需要构造一个如下所示的数据缓冲区就可以了。 图片描述信息 如果想自己处理 IP 首部，则需要设置 IP_HDRINCL 的 socket 选项，如下所示： int flag = 1; setsocketopt(sockfd, IPPROTO_TO, IP_HDRINCL, &amp;flag, sizeof(int)); 此时，我们需要构造如下所示的数据缓冲区。 注意，我们自己填充 IP 首部时，也不是填充 IP 首部的所有字段，而是应该将 IP 首部的 id 字段设置为0，表示让内核来处理这个字段。同时，内核还会自动完成 IP 首部的校验和的计算并填充。 最后介绍发送和接收 IP 包的两个函数：recvfrom 和 sendto。 #include &lt;sys/socket.h&gt; ssize_t recvfrom(int sockfd, void * buff, size_t nbytes, int flags, struct sockaddr * from, socklen_t * addrlen); ssize_t sendto(int sockfd, const void * buff, size_t nbytes, int flags,const struct sockaddr * to, socklen_t addrlen); 成功时返回读写的字节数，失败时返回-1。 sockfd参数：套接字描述符。 buff参数：指向读入或写出缓冲区的指针。 nbytes参数：读写字节数。 flags参数：本项目中设置为0。 recvfrom 的 from 参数指向一个将由该函数在返回时填写数据发送者的地址信息的结构体，而该结构体中填写的字节数则放在 addrlen 参数所指的整数中。 sendto 的 to 参数指向一个含有数据报接收者的地址信息的结构体，其大小由addrlen参数指定。 校验和算法检验和算法在 TCP/IP 协议族中是比较常见的算法。 IP、ICMP、UDP和TCP报文头部都有校验和字段，不过IP、TCP、UDP只针对首部计算校验和， 而 ICMP 对首部和报文数据一起计算校验和。 检验和算法可以分成两步来实现。 首先在发送端，有以下三步： 1.把校验和字段置为0。 2.对需要校验的数据看成以16bit为单位的数字组成，依次进行二进制求和。 3.将上一步的求和结果取反，存入校验和字段。 其次在接收端，也有相应的三步： 1. 对需要校验的数据看成以16bit为单位的数字组成，依次进行二进制求和，包括校验和字段。 2. 将上一步的求和结果取反。 3. 判断最终结果是否为0。如果为0，说明校验和正确。如果不为0，则协议栈会丢掉接收到的数据。 从上可以看出，归根到底，校验和算法就是二进制反码求和。由于先取反后相加与先相加后取反，得到的结果是一样的，所以上面的步骤都是先求和后取反。 下面用C语言来实现校验和算法，代码如下： /** * addr 指向需校验数据缓冲区的指针 * len 需校验数据的总长度（字节单位） */ unsigned short checkSum(unsigned short *addr, int len){ unsigned int sum = 0; while(len &gt; 1){ sum += *addr++; len -= 2; } // 处理剩下的一个字节 if(len == 1){ sum += *(unsigned char *)addr; } // 将32位的高16位与低16位相加 sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum += (sum &gt;&gt; 16); return (unsigned short) ~sum; } 上面的代码首先定义了一个32位无符号整型的变量sum，用来保存16bit二进制数字相加的结果，由于16bit相加可能会产生进位，所以这里使用32位变量来保存结果，其中高16bit保存的是相加产生的进位。 然后下面的 while 循环，对数据按16bit累加求和。 接下来的if语句判断是否还剩下8bit（一字节）。如果校验的数据为奇数个字节，会剩下最后一字节。把最后一个字节视为一个2字节数据的高字节，这个2字节数据的低字节为0，继续累加。 之后的两行代码作用是将 sum 高16bit的值加到低16bit上，即把累加中最高位的进位加到最低位上。（sum &gt;&gt; 16）将高16bit右移到低16bit，（sum &amp; 0xffff）将高16bit全部置为0。注意，这两步都不会改变sum原来的值。 进行了两次相加可以保证 sum 高16bit都为0，没有进位了。 最后取反，并返回。 扩展： 为什么使用二进制反码求和，而不是原码或补码呢？ 这是因为，使用反码计算校验和比较简单和快速。对于网络通信来说，最重要的就是效率和速度。 编码实现整个程序的流程图如下所示： 图片描述信息 第一步，首先创建原始套接字。 第二步，封装 ICMP 报文，向目的IP地址发送 ICMP 报文，1秒后接收 ICM P响应报文，并打印 TTL，RTT。 第三步：循环第二步N次，本项目设置为5。 第四步:输出统计信息。 栗子:#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/time.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netdb.h&gt; #define ICMP_SIZE (sizeof(struct icmp)) #define ICMP_ECHO 8 #define ICMP_ECHOREPLY 0 #define BUF_SIZE 1024 #define NUM 5 // 发送报文次数 #define UCHAR unsigned char #define USHORT unsigned short #define UINT unsigned int // ICMP报文数据结构 struct icmp{ UCHAR type; // 类型 UCHAR code; // 代码 USHORT checksum; // 校验和 USHORT id; // 标识符 USHORT sequence; // 序号 struct timeval timestamp; // 时间戳 }; // IP首部数据结构 struct ip{ // 主机字节序判断 #if __BYTE_ORDER == __LITTLE_ENDIAN UCHAR hlen:4; // 首部长度 UCHAR version:4; // 版本 #endif #if __BYTE_ORDER == __BIG_ENDIAN UCHAR version:4; UCHAR hlen:4; #endif UCHAR tos; // 服务类型 USHORT len; // 总长度 USHORT id; // 标识符 USHORT offset; // 标志和片偏移 UCHAR ttl; // 生存时间 UCHAR protocol; // 协议 USHORT checksum; // 校验和 struct in_addr ipsrc; // 32位源ip地址 struct in_addr ipdst; // 32位目的ip地址 }; char buf[BUF_SIZE] = {0}; USHORT checkSum(USHORT *, int); // 计算校验和 float timediff(struct timeval *, struct timeval *); // 计算时间差 void pack(struct icmp *, int); // 封装一个ICMP报文 int unpack(char *, int, char *); // 对接收到的IP报文进行解包 int main(int argc, char * argv[]){ struct hostent *host; struct icmp sendicmp; struct sockaddr_in from; struct sockaddr_in to; int fromlen = 0; int sockfd; int nsend = 0; int nreceived = 0; int i, n; in_addr_t inaddr; memset(&amp;from, 0, sizeof(struct sockaddr_in)); memset(&amp;to, 0, sizeof(struct sockaddr_in)); if(argc &lt; 2){ printf(&quot;use : %s hostname/IP address \\n&quot;, argv[0]); exit(1); } // 生成原始套接字 if((sockfd = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP)) == -1){ printf(&quot;socket() error \\n&quot;); exit(1); } // 设置目的地址信息 to.sin_family = AF_INET; // 判断是域名还是ip地址 if(inaddr = inet_addr(argv[1]) == INADDR_NONE){ // 是域名 if((host = gethostbyname(argv[1])) == NULL){ printf(&quot;gethostbyname() error \\n&quot;); exit(1); } to.sin_addr = *(struct in_addr *)host-&gt;h_addr_list[0]; }else{ // 是ip地址 to.sin_addr.s_addr = inaddr; } // 输出域名ip地址信息 printf(&quot;ping %s (%s) : %d bytes of data.\\n&quot;, argv[1], inet_ntoa(to.sin_addr), (int)ICMP_SIZE); //循环发送报文、接收报文 for(i = 0; i &lt; NUM; i++){ nsend++; // 发送次数加1 memset(&amp;sendicmp, 0, ICMP_SIZE); pack(&amp;sendicmp, nsend); // 发送报文 if(sendto(sockfd, &amp;sendicmp, ICMP_SIZE, 0, (struct sockaddr *)&amp;to, sizeof(to)) == -1){ printf(&quot;sendto() error \\n&quot;); continue; } // 接收报文 if((n = recvfrom(sockfd, buf, BUF_SIZE, 0, (struct sockaddr *)&amp;from, &amp;fromlen)) &lt; 0){ printf(&quot;recvform() error \\n&quot;); continue; } nreceived++; // 接收次数加1 if(unpack(buf, n, inet_ntoa(from.sin_addr)) == -1){ printf(&quot;unpack() error \\n&quot;); } sleep(1); } // 输出统计信息 printf(&quot;--- %s ping statistics ---\\n&quot;, argv[1]); printf(&quot;%d packets transmitted, %d received, %%%d packet loss\\n&quot;, nsend, nreceived, (nsend - nreceived) / nsend * 100); return 0; } /** * addr 指向需校验数据缓冲区的指针 * len 需校验数据的总长度（字节单位） */ USHORT checkSum(USHORT *addr, int len){ UINT sum = 0; while(len &gt; 1){ sum += *addr++; len -= 2; } // 处理剩下的一个字节 if(len == 1){ sum += *(UCHAR *)addr; } // 将32位的高16位与低16位相加 sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum += (sum &gt;&gt; 16); return (USHORT) ~sum; } /** * 返回值单位：ms * begin 开始时间戳 * end 结束时间戳 */ float timediff(struct timeval *begin, struct timeval *end){ int n; // 先计算两个时间点相差多少微秒 n = ( end-&gt;tv_sec - begin-&gt;tv_sec ) * 1000000 + ( end-&gt;tv_usec - begin-&gt;tv_usec ); // 转化为毫秒返回 return (float) (n / 1000); } /** * icmp 指向需要封装的ICMP报文结构体的指针 * sequence 该报文的序号 */ void pack(struct icmp * icmp, int sequence){ icmp-&gt;type = ICMP_ECHO; icmp-&gt;code = 0; icmp-&gt;checksum = 0; icmp-&gt;id = getpid(); icmp-&gt;sequence = sequence; gettimeofday(&amp;icmp-&gt;timestamp, 0); icmp-&gt;checksum = checkSum((USHORT *)icmp, ICMP_SIZE); } /** * buf 指向接收到的IP报文缓冲区的指针 * len 接收到的IP报文长度 * addr 发送ICMP报文响应的主机IP地址 */ int unpack(char * buf, int len, char * addr){ int i, ipheadlen; struct ip * ip; struct icmp * icmp; float rtt; // 记录往返时间 struct timeval end; // 记录接收报文的时间戳 ip = (struct ip *)buf; // 计算ip首部长度，即ip首部的长度标识乘4 ipheadlen = ip-&gt;hlen &lt;&lt; 2; // 越过ip首部，指向ICMP报文 icmp = (struct icmp *)(buf + ipheadlen); // ICMP报文的总长度 len -= ipheadlen; // 如果小于ICMP报文首部长度8 if(len &lt; 8){ printf(&quot;ICMP packets\\&apos;s length is less than 8 \\n&quot;); return -1; } // 确保是我们所发的ICMP ECHO回应 if(icmp-&gt;type != ICMP_ECHOREPLY || icmp-&gt;id != getpid()){ printf(&quot;ICMP packets are not send by us \\n&quot;); return -1; } // 计算往返时间 gettimeofday(&amp;end, 0); rtt = timediff(&amp;icmp-&gt;timestamp, &amp;end); // 打印ttl，rtt，seq printf(&quot;%d bytes from %s : icmp_seq=%u ttl=%d rtt=%fms \\n&quot;, len, addr, icmp-&gt;sequence, ip-&gt;ttl, rtt); return 0; 执行提示 socket() error 错误，也就是调用 socket 函数的时候出现了错误。这是因为我们创建的是原始套接字，原始套接字必须有 root 权限才能创建，所以我们可以加 sudo 执行 Ping笔记(一) 参考文献参考文献一","categories":[{"name":"Ping","slug":"Ping","permalink":"https://www.delta1037.cn/categories/Ping/"}],"tags":[{"name":"c语言","slug":"c语言","permalink":"https://www.delta1037.cn/tags/c语言/"},{"name":"ping","slug":"ping","permalink":"https://www.delta1037.cn/tags/ping/"}]},{"title":"Ping笔记(一)","slug":"ping笔记","date":"2017-08-24T10:51:39.000Z","updated":"2019-08-03T13:37:23.968Z","comments":true,"path":"2017/08/24/ping笔记/","link":"","permalink":"https://www.delta1037.cn/2017/08/24/ping笔记/","excerpt":"","text":"Ping的c语言实现Ping和ICMPPing简介:ping 命令是用来查看网络上另一个主机系统的网络连接是否正常的一个工具 ping类似于声呐系统: ping 命令使用回显请求和回显应答消息。具体表现是向网络上的另一个主机系统发送 ICMP 报文，如果指定系统得到了报文，它将把报文一模一样地传回给发送者 ping 命令所使用到的 TCP/IP 协议：ICMP 协议 ping执行后的返回内容 : 1.显示出被测试系统主机名和相应 IP 地址 111.13.101.208 (111.13.101.208) 2.返回给当前主机的 ICMP 报文顺序号 icmp_seq=3 3.ttl 生存时间和往返时间 rtt（单位是毫秒，即千分之一秒) ttl=51 time=16.6 ms 以ping baidu.com为例: 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq=1 ttl=51 time=16.4 ms 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq=2 ttl=51 time=17.3 ms 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq=3 ttl=51 time=16.6 ms ICMP介绍ICMP 是（Internet Control Message Protocol）Internet 控制报文协议。它是 TCP/IP 协议族的一个子协议，用于在 IP 主机、路由器之间传递控制消息。 - 控制消息有：目的不可达消息，超时信息，重定向消息，时间戳请求和时间戳响应消息，回显请求和回显应答消息 注意ICMP协议是-IP层-的一个协议，。这是因为ICMP报文在发送给报文接收方时可能要经过若干子网，会牵涉到路由选择等问题，所以ICMP报文需通过IP协议来发送，是IP层的 ICMP报文格式:1.回显 请求 报文其中类型为 0，代码为 0。 2.回显 应答 报文其中类型为 8，代码为 0。 3.校验和字段：包括数据在内的整个 ICMP 协议数据包的校验和，具体实现方法会在下面详细介绍。 4.标识符字段：用于唯一标识 ICMP 报文，本项目使用程序的进程 id。因为如果同时在两个命令行终端执行 ping 命令的话， 每个 ping 命令都会接收到所有的回显应答，所以需要根据标识符来判断回显应答是否应该接收。 5.序号字段：ICMP 报文的序号。 6.数据字段：也就是报文，本项目中我们将发送报文的时间戳放入数据字段，这样当接收到该报文应答的时候可以取出发送时间戳， 将接收应答的时间戳减去发送时间戳就是报文往返时间（rtt）。提前预告一下，这里使用gettimeofday()API函数获取时间戳，详细介绍会在函数介绍部分说明。 - c语言数据结构表示: ICMP 报文 C 语言实现可以用下面的数据结构表示： struct icmp{ unsigned char type; // 类型 unsigned char code; // 代码 unsigned short checksum; // 校验和 unsigned short id; // 标识符 unsigned short sequence; // 序号 struct timeval timestamp; // 时间戳 }; unsigned char 正好一字节，也就是 8bit，unsigned short 二字节，也就是 16bit，unsigned int4 字节（32bit）， 不过上面没用到。其中 struct timeval 类型可能有人不清楚，不过没关系，函数部分说明。 IP报文首部C语言实现的数据结构表示 &gt; struct ip{ unsigned char version:4; // 版本 unsigned char hlen:4; // 首部长度 unsigned char tos; // 服务类型 unsigned short len; // 总长度 unsigned short id; // 标识符 unsigned short offset; // 标志和片偏移 unsigned char ttl; // 生存时间 unsigned char protocol; // 协议 unsigned short checksum; // 校验和 struct in_addr ipsrc; // 32位源ip地址 struct in_addr ipdst; // 32位目的ip地址 }; 地址信息表示编写网络应用程序时,要使用地址信息指定数据传输给哪个主机 地址信息内容 1.地址族，基于IPv4的地址族还是IPv6的地址族。 2.IP地址。 3.端口号。 地址信息的结构体(一) struct sockaddr_in{ sa_family_t sin_family; // 地址族 uint16_t sin_port; // 端口号 struct in_addr sin_addr; // 32位IP地址 char sin_zero[8]; // 不使用 }; 其中struct in_addr结构体定义如下： struct in_addr{ in_addr_t s_addr; // 32位IP地址 }; in_addr_t使用如下宏指令定义，也就是无符号整型32位。 #define in_addr_t uint32_t 地址信息的结构体(二) struct sockaddr{ sa_family_t sin_family; // 地址族 char sa_data[14]; // IP地址和端口 }; 成员sa_data保存的信息包含 IP 地址和端口号，剩余部分填充0。 网络编程中常用struct sockaddr_in,因为填充数据更方便 网络编程接口函数定义使用的是struct sockaddr,因为它是最先开始使用的 两个结构体之间的转换: 定义地址信息时使用 struct sockaddr_in 结构体，然后将该结构体类型转为 struct sockaddr 结构体类型传递给网络编程接口函数 字节顺序的转换主机字节序与网络字节序在不同 CPU 中，4字节整型数值1在内存空间的保存方式是不同的。 4字节整型数值1可用二进制表示如下： 00000000 00000000 00000000 00000001 而有些CPU则以倒序保存 00000001 00000000 00000000 00000000 所以，如果发送主机与接收主机CPU字节序不一样则就会出现问题。 引申上面的问题，这就涉及到CPU解析数据的方式，其方式有2种： - 大端序（Big Endian）：高位字节存放到低位地址。 - 小端序（Little Endian）：高位字节存放到高位地址。由于不同CPU字节序不一样，因此，在通过网络传输数据时约定统一方式，这种约定称为网络字节序（Network Byte Order），非常简单——统一为大端序。 所以，进行网络传输数据前，需要先把数据数组转化为 大端序 格式再进行网络传输。接收到网络数据后，需要转换本机字节序格式然后进行后续处理。不过，幸运地是这些工作不需要我们自己完成，系统会自动转换的。 用到字节序转换的地方我们唯一需要转换的是向struct sockaddr_in结构体变量填充IP地址和端口号数据的时候。当然，系统已经提供了一些函数，只需调用相应函数即可。 转换字节序的函数有： unsigned short htons(unsigned short); unsigned short ntohs(unsigned short); unsigned long htonl(unsigned long); unsigned long ntohl(unsigned long); 上面的函数非常简单，通过函数名就能知道它们的功能， htonl/htons 中的h代表主机（host）字节序，n代表网络（network）字节序，s指的是 short，l指的是 long （需要注意一下，linux 中 long 类型只占4个字节，跟int类型一样）。 示例: #include &lt;stdio.h&gt; #include &lt;arpa/inet.h&gt; int main(void){ unsigned short hosts = 0x1234; unsigned short nets; unsigned long hostl = 0x12345678; unsigned long netl; nets = htons(hosts); netl = htonl(hostl); printf(&quot;Host ordered short: %#x \\n&quot;, hosts); printf(&quot;Network ordered short: %#x \\n&quot;, nets); printf(&quot;Host ordered long: %#lx \\n&quot;, hostl); printf(&quot;Network ordered long: %#lx \\n&quot;, netl); return 0; } 大家通过上面的程序也可以判断自己主机是大端序的还是小端序的,Intel 系列 CPU 采用的都是小端序标准 函数介绍函数gettimeofday()#include &lt;sys/time.h&gt; int gettimeofday(struct timeval *tv, struct timezone *tz); 该函数的作用是把当前的时间放入 struct timeval 结构体中返回。 注意： 1.精确级别,微秒级别 2.受系统时间修改影响 3.返回的秒数是从1970年1月1日0时0分0秒开始 其参数 tv 是保存获取时间结果的结构体，参数 tz 用于保存时区结果。 结构体 timeval 的定义为： struct timeval { long int tv_sec; // 秒数 long int tv_usec; // 微秒数 } 结构体timezone的定义为： struct timezone { int tz_minuteswest;/格林威治时间往西方的时差/ int tz_dsttime; /DST 时间的修正方式/ } timezone 参数若不使用则传入0即可，本项目传入0。 /** * 本程序实现计算程序运行时间 */ #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/time.h&gt; // 计算时间差，单位：ms float timediff(struct timeval *begin, struct timeval *end){ int n; // 先计算两个时间点相差多少微秒 n = ( end-&gt;tv_sec - begin-&gt;tv_sec ) * 1000000 + ( end-&gt;tv_usec - begin-&gt;tv_usec ); // 转化为毫秒返回 return (float) (n / 1000); } int main(void){ struct timeval begin, end; gettimeofday(&amp;begin, 0); // 这里让程序挂起一秒 printf(&quot;do something here...&quot;); sleep(1); gettimeofday(&amp;end, 0); printf(&quot;running time : %fms\\n&quot;, timediff(&amp;begin, &amp;end)); return 0; } 大约都运行了1秒钟时间。但有时候多1毫秒，有时候又恰好1秒。这是因为系统中运行的程序不只本程序一个，有时候恰好遇到内核进行进程切换需要时间 inet_addr 函数#include &lt;arpa/inet.h&gt; in_addr_t inet_addr(const char *string); 该函数的作用是将用点分十进制字符串格式表示的IP地址转换成32位大端序整型。 成功时返回32位大端序整型数值，失败时返回 INADDR_NONE 。 简单的示例: #include &lt;stdio.h&gt; #include &lt;arpa/inet.h&gt; int main(void){ char *addr1 = &quot;1.2.3.4&quot;; char *addr2 = &quot;192.168.1.1&quot;; in_addr_t data; data = inet_addr(addr1); printf(&quot; %s -&gt; %#lx \\n&quot;, addr1, (long)data ); data = inet_addr(addr2); printf(&quot; %s -&gt; %#lx \\n&quot;, addr2, (long)data ); return 0; } inet_ntoa 函数char * inet_ntoa(struct in_addr addr); 该函数的作用与 inet_addr 正好相反。将32位大端序整型格式IP地址转换为点分十进制格式。 成功时返回转换的字符串地址值，失败时返回-1。 简单的示例 #include &lt;stdio.h&gt; #include &lt;arpa/inet.h&gt; int main(void){ struct in_addr addr1, addr2; char * str1, * str2; addr1.s_addr = htonl(0x1020304); addr2.s_addr = htonl(0xc0a80101); str1 = inet_ntoa(addr1); str2 = inet_ntoa(addr2); printf(&quot;%#lx -&gt; %s \\n&quot;, (long)addr1.s_addr, str1); printf(&quot;%#lx -&gt; %s \\n&quot;, (long)addr2.s_addr, str2); return 0; } 函数两次执行的结果怎么是一样的，其实这是 C 语言编程中常会出现的陷阱。 我们可以再看下上面函数的定义，注意该函数返回值类型为 char 指针类型，大家看出端倪了吗？ inet_addr函数在执行过程中，在内部会申请内存并保存结果字符串，然后返回内存地址。所以调用完该函数应该将字符串复制到其他内存空间。 因为再次调用该函数时，之前保存的字符串很有可能被覆盖。知道了原因，大家可以动手修改上面的代码了。 首先定义一个接收缓冲区 char buf[20]; ，然后使用 memcpy(buf, str1, sizeof(str)) 将 inet_ntoa 函数生成的字符串保存缓冲区。 记住，memcpy 函数在头文件 #include &lt;string.h&gt; 中声明的，需要加上这个头文件。 函数 gethostbyname –根据域名获取IP地址#include &lt;netdb.h&gt; struct hostent gethostbyname(const char hostname); 成功时返回hostent结构体地址，失败时返回NULL指针。 struct hosten结构体定义如下： struct hostent{ char * h_name; char h_aliases; char h_addrtype; char h_length; char h_addr_list; }; 我们最关心的是h_addr_list成员，它保存的就是域名对应IP地址。由于一个域名对应的IP地址不止一个，所以h_addr_list成员是char **类型，相当于二维字符数组。 下面通过一张图来表示h_addr_list成员的参数，希望大家可以加深对hostent结构体的理解。 图片描述信息 简单的示例 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netdb.h&gt; int main(int argc, char *argv[]){ int i; struct hostent *host; if(argc &lt; 2){ printf(&quot;Use : %s &lt;hostname&gt; \\n&quot;, argv[0]); exit(1); } host = gethostbyname(argv[1]); for(i = 0; host-&gt;h_addr_list[i]; i++){ printf(&quot;IP addr %d : %s \\n&quot;, i+1, inet_ntoa(*(struct in_addr *)host-&gt;h_addr_list[i])); } return 0; } 上面代码中，打印IP地址是出现了令人困惑的类型转换。 host-&gt;h_addr_list[i]得到的是字符串指针，但该字符串指针实际指向的是struct in_addr结构体变量地址值。 (struct in_addr _)host-&gt;h_addr_list[i]将字符串指针转换为struct in_addr结构体指针。 由于inet_ntoa参数类型是struct in_addr而不是struct in_addr *，所以用_运算符取出struct in_addr结构体的值。 Ping笔记(二) 参考文献参考文献一","categories":[{"name":"Ping","slug":"Ping","permalink":"https://www.delta1037.cn/categories/Ping/"}],"tags":[{"name":"c语言","slug":"c语言","permalink":"https://www.delta1037.cn/tags/c语言/"},{"name":"ping","slug":"ping","permalink":"https://www.delta1037.cn/tags/ping/"}]},{"title":"CMake笔记","slug":"cmake","date":"2017-08-24T03:19:44.000Z","updated":"2019-08-03T13:37:24.404Z","comments":true,"path":"2017/08/24/cmake/","link":"","permalink":"https://www.delta1037.cn/2017/08/24/cmake/","excerpt":"","text":"CMake它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件 linux平台使用cmake流程 编写 CMake 配置文件 CMakeLists.txt 。 执行命令 cmake CMakeListPath 生成 Makefile 使用 make 命令进行编译。make使用 编写CMakeList.txt文件基本版#CMake 最低版本号要求 cmake_minimum_required (VERSION 2.8) #项目信息 project (project_name) #指定生成目标 add_executable(target_name main.c) #CMake 最低版本号要求 cmake_minimum_required (VERSION 2.8) #项目信息 project (project_name) # 使用变量 set(SOURCE_FILES file1.c file2.c main.c) set（SOURCE_FILES file1.c file2.c main.c [apend ...]) # 追加方式添加 #指定生成目标 add_executable(target_name ${SOURCE_FILES}) 添加源文件目录# 添加源文件目录 aux_source_directory(srcPath DIR_SRCS) # 指定生成目标 add_executable(target_name ${DIR_SRCS}) 添加头文件目录# 包含头文件目录 include_directories(includeFilePath) 添加子目录子目录中也有有一个CMakeList.txt，子目录下生成一个链接库 # 查找当前目录源文件，将名称 aux_source_directory(srcPath DIR_SRCS) # 生成链接库 add_library(library_name ${DIR_SRCS}) 在主函数中添加链接库 add_excutable(target_name ${SRCS}) # 在指定生成目标之后添加链接库 target_link_library(target_name ${library_name}) 添加链接库link_libraries(library_name1 library_name2) # 所有编译目标都链接的库 link_directories(DLLPath) # 指定动态链接库的搜索路径 target_link_libraries(target_name ${BOOST_LIBRARIES}) # 添加链接库 # 在指定目录中搜索一个库，并且包含在变量中 find_library(MY_LIB library_name1 libraryPath) # 查找并添加动态库(添加一部分) 其它设置编译参数add_definitions(&quot;-Wall -g&quot;) 添加编译依赖add_dependencies() 设置目标属性set_target_properties() # eg： set_target_properties(${project_name} PROPERTIES SOVERSION 0.0.1 PUBLIC_HEADER &quot;include/gtstack.h;include/gttypes.h&quot; ) 设置版本号set(VERSION_MAJOR 1) # 最大的版本编号 set(VERSION_MINOR 0) # 其次于major的版本号 set(VERSION_PATCH 0) # 其次于minor的版本号 set(VERSION_TWEAK 0) # 其次于patch的版本号 # 版本号：MAJOR.MINOR.PATCH.TWEAK （semver语义化版本号的规则） 输出信息message([SEND_ERROR | STATUS | FATAL_ERROR] “message to display”) 语法LESS,GREATER,EQUAL # 数字比较 STRLESS、STRGREATER、STREQUAL # 字符串比较 if(CONDITION1) ... elseif(CONDITION2) ... else(CONDITION3) ... endif # 1 foreach(loop_var arg1 arg2...) ... endforeach(loop_var) # 2 foreach(loop_var RANGE total) ... endforeach(loop_var) # 3 foreach(loop_var RANGE start stop [step]) ... endforeach(loop_var) # 4 foreach(loop_var IN [LISTS [list1 [...]]] [ITEMS [item1 [...]]]) ... endforeach(loop_var) while(CONDITION) ... endwhile(CONDITION) # Logic operation if(FALSE AND (FALSE OR TRUE)) ... endif()","categories":[{"name":"CMake","slug":"CMake","permalink":"https://www.delta1037.cn/categories/CMake/"}],"tags":[{"name":"CMke","slug":"CMke","permalink":"https://www.delta1037.cn/tags/CMke/"}]},{"title":"Makefile笔记","slug":"makefile","date":"2017-08-23T14:45:16.000Z","updated":"2019-08-03T13:37:25.592Z","comments":true,"path":"2017/08/23/makefile/","link":"","permalink":"https://www.delta1037.cn/2017/08/23/makefile/","excerpt":"","text":"Makefile 简介makefile用来制定编译的规则及其其它更复杂的操作.并且能实现整个工程的自动化编译,提高编译效率 Makefile 格式:target : prerequisites &lt;tab&gt; command 目标：target 文件名 : *.o … (可以是多个，即使是最终目标文件） 操作的名字(伪目标) ： clean … 通过 .PHONY 来声明clean是一个伪目标，而不是一个目标文件,例： .PHONY: cleanclean: rm *.o temp 前置条件 prerequisites一组文件名 ： 用空格分开 只要有一个前置条件的文件有过更新，目标就要重新构建 命令 command由一行或者多行的shell命令组成，命令之前必须有tab键 1. 每行命令在一个单独的shell中执行，这些shell之间没有继承关系 2. 多行命令依赖解决： 1、加上.ONESHELL: 2、 用逗号分隔 3、添加换行转义 Makefile 语法注释# 这是注释 target : prerequisites &lt;tab&gt; command 回声 echoing在执行每一条命令时都会在终端打印这条命令，在命令之前加上@可以关闭 通配符Makefile通配符与bash一致，主要有 1. * : 可以匹配任何字符 2. ？: 匹配任意单个字符 3. […] : 匹配一个单字符范围, 模式匹配对文件名进行类似正则运算的匹配,适应于大量同类型的文件 %.o : %.c 变量变量可以用等号赋值，访问时可以使用$(Variable)来访问 所以在使用美元符号的时候可以使用$$来转义 赋值： VARIABLE = value # 在执行时扩展，允许递归扩展。 VARIABLE := value # 在定义时扩展。 VARIABLE ?= value # 只有在该变量为空时才设置值。 VARIABLE += value # 将值追加到变量的尾端。 内置变量 $(CC) ： 指向当前使用的编译器 $(MAKE) ：指向当前使用的Make工具 自动变量 $@ : 指代当前需要生成的目标 $&lt; ： 指代第一个前置条件 $? ： 指代比目标更新的所有前置条件 $^ ： 指代所有前置条件 判断和循环判断 ifeq ($(CC),gcc) libs=$(libs_for_gcc) else libs=$(normal_libs) endif 循环 LIST = one two three all: for i in $(LIST); do \\ echo $$i; \\ done 函数格式 $(function arguments) # 或者 ${function arguments} shell函数srcfiles := $(shell echo src/{00..99}.txt) wildcard函数srcfiles := $(wildcard src/*.txt) subst 函数$(subst from,to,text) patsubst函数$(patsubst pattern,replacement,text) 替换后缀名min: $(OUTPUT:.js=.min.js) Makefile 执行通过make命令工具来解释makefile中的指令,makefile告诉make需要怎么去编译和链接目标程序,make还能根据当前文件情况确定哪些文件需要重新编译 $ make # 自动寻找Makefile $ make -f Makefile $ make --file=Makefile 附：编译和链接基本流程 源文件–编译–&gt;中间文件 中间文件–链接–&gt;可执行文件 编译链接细节 编译时，编译器需要的是语法，函数与变量的声明是否正确，只要正确就能生成中间文件 链接时，主要是链接函数和全局变量，连接时只管中间目标文件 在中间文件过多时，可以给中间文件打包 注中间文件： 1. Windows：.obj 2. UNIX ： .o 文件 打包文件： 1. Window ： 库文件（Library File) .lib 2. Unix ： Archive File， .a 参考文献参考博客","categories":[{"name":"Makefile","slug":"Makefile","permalink":"https://www.delta1037.cn/categories/Makefile/"}],"tags":[{"name":"make","slug":"make","permalink":"https://www.delta1037.cn/tags/make/"},{"name":"makefile","slug":"makefile","permalink":"https://www.delta1037.cn/tags/makefile/"}]},{"title":"Shell脚本","slug":"shell脚本","date":"2017-08-22T13:51:38.000Z","updated":"2019-10-18T08:26:48.776Z","comments":true,"path":"2017/08/22/shell脚本/","link":"","permalink":"https://www.delta1037.cn/2017/08/22/shell脚本/","excerpt":"","text":"Shell脚本一、文件夹排序脚本1.1对当前目录对当前目录所有的文件夹名称及其文件名称进行排序的操作1234567891011121314#/bin/bash#对文件路径的本目录的所有文件的文件名进行排序path=$1files=$(ls $path)for filename in $files #循环遍历当前文件夹内的所有文件名及其文件夹名do echo $filename&gt;&gt;sort.txt #将输出的文件名重定向到test.txtdoneecho \"排序之后:\"sort test.txt #对文件排序并输出rm test.txt #删除文件 1.2对当前目录及其子目录对当前目录及其子目录所有的文件夹名称及其文件名称进行排序的操作123456789101112131415161718#!/bin/bash#对文件路径本目录及其所有子目录文件名排序function ergodic()&#123; for filename in $(ls $1) #循环遍历当前文件夹内的所有文件名及其文件夹名 do if [ -d $1\"/\"$filename ] #判断是否存在子目录 then ergodic $1\"/\"$filename #对函数ergodic进行递归调用 else echo $filename&gt;&gt;test.txt #将输出的文件名重定向到test.txt fi done&#125;ergodic $1 #函数开始执行的位置,$1为输入的第一个参数echo \"排序之后:\"sort test.txt #对文件排序并输出rm test.txt #删除文件 二、非递归阶乘1234567891011121314151617181920212223242526#!/bin/bash# 计算阶乘# 由于$?无法返回大数字,使用全局变量存储返回的值let result=0let localreturn=0funFactorial()&#123; let num1=1 if [ $1 -gt $num1 ]; then let numSub=$1-1 funFactorial $numSub let result=$localreturn*$1 let localreturn=$result else let result=1 let localreturn=1; fi&#125;if [ -n \"$1\" ]; then funFactorial $1 echo result:$resultelse echo \"usage: factorial.sh [n]\" echo \"calculates a number's factorial\"fi 三、文件解压123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/bin/bash# usage: self_compression.sh [--list] or [source compressd file] [destination path]# self compression accroding to file name suffix# 不存在参数if [ \"\" = \"$1\" ]; then echo \"usage: self_compression.sh [--list] or [source compressd file] [destination path]\" echo \"self compression accroding to file name suffix\"else # 有参数 --list if [ \"--list\" = \"$1\" ]; then echo \"Support file types:zip tar tar.gz tar.bz2\" # 选择文件类型&amp;解压缩文件 else # get type file=$1 type=$&#123;file##*.&#125; # Choose type &amp; unzip if [ \"$type\" = \"zip\" ]; then unzip $1 -d $2 elif [ \"$type\" = \"tar\" ]; then tar -xf $1 -C $2 elif [ \"$type\" = \"gz\" ]; then tar -xzvf $1 -C $2 elif [ \"$type\" = \"bz2\" ]; then tar -xjvf $1 -C $2 else echo \"$type Not Suport!!\" fi fifi``` ## 四、获得某个目录下前N个最大的文件```bash#!/bin/bash# echo \"usage:file_size_get.sh [-n N] [-d DIR]\"# echo \"show top N largest files/directories\"# 获得指定或默认目录下的前N个文件或者所有文件# 存在参数if [ -n \"$1\" -o -n \"$3\" ];then # 有两个参数 if [ -n \"$1\" -a -n \"$3\" ];then du -ak $4 | sort -nr | head -$2 &gt; test.txt # 只有参数-n elif [ \"-n\" = \"$1\" ];then du -ak | sort -nr | head -$2 &gt; test.txt # 只有参数-d else du -ak $2 | sort -nr &gt; test.txt fi# 不存在参数else du -ah | sort -nr &gt; test.txtficat -n test.txtrm test.txt 源码github链接","categories":[{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"}]},{"title":"Socket网络编程笔记","slug":"socket网络编程笔记","date":"2017-08-22T09:29:08.000Z","updated":"2019-08-03T13:37:26.432Z","comments":true,"path":"2017/08/22/socket网络编程笔记/","link":"","permalink":"https://www.delta1037.cn/2017/08/22/socket网络编程笔记/","excerpt":"","text":"源代码客户端代码#include &lt;stdio.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/in.h&gt; #include &lt;string.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;zconf.h&gt; int main() { //创建套接字 int sock=socket(AF_INET,SOCK_STREAM,0); //向特定的服务器发起请求 struct sockaddr_in serv_addr; memset(&amp;serv_addr,0,sizeof(serv_addr));//用0填充每个字节 serv_addr.sin_family=AF_INET; //使用ipv4 serv_addr.sin_addr.s_addr=inet_addr(&quot;127.0.0.1&quot;); serv_addr.sin_port=htons(1234); //端口 connect(sock,(struct sockaddr*)&amp;serv_addr,sizeof(serv_addr)); //读取服务器传回的数据 char buffer[40]; read(sock,buffer,sizeof(buffer)-1); printf(&quot;Message from server:%s\\n&quot;,buffer); //关闭套接字 close(sock); return 0; } 服务端代码#include &lt;stdio.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/in.h&gt; #include &lt;string.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;zconf.h&gt; int main() { //创建 int serv_sock =socket(AF_INET,SOCK_STREAM,IPPROTO_TCP); //将套接字绑定ip,端口 struct sockaddr_in serv_addr; memset(&amp;serv_addr,0,sizeof(serv_addr)); //填充每个字节用0 serv_addr.sin_family=AF_INET; //使用ipv4 serv_addr.sin_addr.s_addr=inet_addr(&quot;127.0.0.1&quot;); //本机(即服务器)IP地址 serv_addr.sin_port=htons(1234); //使用的端口 bind(serv_sock,(struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)); //开始监听 listen(serv_sock,20); //接收客户端请求 struct sockaddr_in clnt_addr; socklen_t clnt_addr_size =sizeof(clnt_addr); int clnt_sock=accept(serv_sock,(struct sockaddr*)&amp;clnt_addr,&amp;clnt_addr_size); //向客户端发送数据 char str[]=&quot;hello world&quot;; write(clnt_sock,str,sizeof(str)); //关闭套接字 close(clnt_sock); close(serv_sock); return 0; }","categories":[{"name":"Socket","slug":"Socket","permalink":"https://www.delta1037.cn/categories/Socket/"}],"tags":[{"name":"socket","slug":"socket","permalink":"https://www.delta1037.cn/tags/socket/"}]},{"title":"Sqlite笔记","slug":"sqlite笔记","date":"2017-08-21T01:47:58.000Z","updated":"2019-08-03T13:37:26.508Z","comments":true,"path":"2017/08/21/sqlite笔记/","link":"","permalink":"https://www.delta1037.cn/2017/08/21/sqlite笔记/","excerpt":"","text":"在CLion中使用Sqlie参考链接 在main.c文件顶部添加头文件 并修改CMakeList.txt为 #版本信息 cmake_minimum_required(VERSION 3.8) #工程名称 project(sqlite_c) #执行的c标准 set(CMAKE_C_STANDARD 99) #添加外部头文件的目录,或者在/usr/local/include中 include_directories(/usr/include) #在目录中查找sqlite这个文件,并赋值给SQLITELIB这个变量 find_library(SQLITELIB sqlite3 /usr/lib) # set(SOURCE_FILES main.c) add_executable(sqlite_c ${SOURCE_FILES}) #为sqlite_c这个可执行文件添加库 target_link_libraries(sqlite_c ${SQLITELIB}) 详细CMake参考 不使用CLion的方法参考链接 不使用编译器,直接创建.c文件,在终端运行 如有错误:atal error: sqlite3.h: No such file or directory 则需安装一个函数库 $ sudo apt-get install libsqlite3-dev 在终端编译运行得到结果 $gcc test.c -l sqlite3 $./a.out Opened database successfully sqlite使用c语言实现数据库的增,减,删,查操作实现交互首先在程序中需要交互式操作,于是使用到了sqlite3_mprintf()函数 eg: char *sql = sqlite3_mprintf(&quot;INSERT INTO STUDENT (ID,NAME,SCORE) VALUES(%d,%Q,%d);&quot;,ID,name,score); ret =sqlite3_exec(db,sql,0,0,&amp;zErrMsg); 将需要交互式输入内容的地方替换为格式符,及其后边有相应的变量 sqlite在c中的接口参考链接 打开数据库 sqlite3_open(const char *filename, sqlite3 **ppDb) 该例程打开一个指向 SQLite 数据库文件的连接，返回一个用于其他 SQLite 程序的数据库连接对象。 如果 filename 参数是 NULL 或 ‘:memory:’，那么 sqlite3_open() 将会在 RAM 中创建一个内存数据库，这只会在 session 的有效时间内持续。 如果文件名 filename 不为 NULL，那么 sqlite3_open() 将使用这个参数值尝试打开数据库文件。如果该名称的文件不存在，sqlite3_open() 将创建一个新的命名为该名称的数据库文件并打开。 执行sqlite命令 sqlite3_exec(sqlite3*, const char *sql, sqlite_callback, void *data, char **errmsg) 该例程提供了一个执行 SQL 命令的快捷方式，SQL 命令由 sql 参数提供，可以由多个 SQL 命令组成。 在这里，第一个参数 sqlite3 是打开的数据库对象，sqlite_callback 是一个回调，data 作为其第一个参数，errmsg 将被返回用来获取程序生成的任何错误。 sqlite3_exec() 程序解析并执行由 sql 参数所给的每个命令，直到字符串结束或者遇到错误为止。 关闭数据库 sqlite3_close(sqlite3*) 该例程关闭之前调用 sqlite3_open() 打开的数据库连接。所有与连接相关的语句都应在连接关闭之前完成。 如果还有查询没有完成，sqlite3_close() 将返回 SQLITE_BUSY 禁止关闭的错误消息。 示例学生信息管理系统","categories":[{"name":"Sqlite","slug":"Sqlite","permalink":"https://www.delta1037.cn/categories/Sqlite/"}],"tags":[{"name":"clion","slug":"clion","permalink":"https://www.delta1037.cn/tags/clion/"},{"name":"sqlite","slug":"sqlite","permalink":"https://www.delta1037.cn/tags/sqlite/"}]},{"title":"hexo+github搭建博客","slug":"hexogithub搭建博客","date":"2017-08-08T11:14:55.000Z","updated":"2019-08-03T13:37:25.028Z","comments":true,"path":"2017/08/08/hexogithub搭建博客/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/hexogithub搭建博客/","excerpt":"","text":"花费了将近十个小时,查阅了上百篇资料,终于搭建好了自己的第一个博客,就以这第一篇博客纪念我走过的坑 预览网站 系统系统类型Ubuntu 17.04 环境Git 和Node.js安装Git使用以下命令 $ sudo apt-get install git 检查版本 $ git --version 安装Node.js由于用apt-get的方式,后续步骤中会出现错误,建议使用源码安装,安装前应该先安装好Python和gcc等编译器安装网址:源代码安装网址 下载后使用cd命令进入文件夹,分别执行以下命令: $ ./configure $ make $ make install 检查版本 $ node -v 安装npm执行命令 $ sudo apt-get install npm 安装hexo和注册github并创建托管博客代码的仓库安装hexohexo官网上给出的命令是 $ npm install hexo-cli -g 该命令本人验证会出错,可使用以下命令安装 $ sudo npm install --unsafe-perm --verbose -g hexo hexo init blog 不能初始化的问题: (taobao源貌似不能使用) 用nrm ls命令,列出所有的可用的源,用nrm use cnpm命令,选择cnpm 若还不能使用…… 用npm test命令测试所有原,找一个可用的源名称,使用npm use + 源名称命令更换就可以 博客初始化根目录 $ hexo init #初始化博客所在根目录 一些常用命令 $ cd blog #进入所在目录 $ npm install // ** 注意，一定要加这个命令！！！！否则生成的public\\index.html文件可能各种空白 $ hexo g #或者hexo generate //生成静态页面 $ hexo s #或者hexo server 本地查看 打开http://localhost:4000/ 已经可以看到一篇内置的blog了 $ hexo d #或者hexo deploy //部署博客到远程 $ hexo new &quot;postName&quot; #新建文章 $ hexo new page &quot;pageName&quot; #新建页面 本地查看hexo s 命令可能出现错误log 使用如下命令可以解决 $ hexo s -s 更换主题(eg:yilia)$ cd /blog/themes #切换到主题目录 $ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia #克隆主题到本地,可以在github上搜索主题,替换相应链接就可以了 修改Hexo目录下的 _config.yml 配置文件中的theme属性，将其设置为yilia(根据主题名称设定) 注册githubGithub官网 创建账户登录之后,新建一个代码仓库,注意仓库名称为 [账户名.github.io] 格式,注意的个人主页的网站内容是在master分支下的,可以通过http://username.github.io 来访问你的个人主页 使用hexo deploy部署如将代码部署到github，在配置文件 _config.xml中作如下修改： deploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master 使用如下命令,即可完成部署,即可在github上创建的仓库里看到代码 $ hexo d 该处需要安装一个拓展 $ npm install hexo-deployer-git --save 使用ssh(不需要输用户名密码,只需要输入设置的密码短语即可)参考链接 创建pubic key $ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; #该处是邮箱,大写C 在 /home/you/.ssh/id_rsa目录下(如果在选择目录时直接enter就是这个目录)会生成两个文件，id_rsa.pub和id_rsa, 然后登陆github，在SSH设置页面添加上刚才的public key文件也就是id_rsa.pub的内容即可 当Enter passphrase时,记住该语句,使用ssh时需要输这个短语,即 Enter passphrase (empty for no passphrase): [Type a passphrase] Enter same passphrase again: [Type passphrase again] 绑定域名$ cd source/ $ touch CNAME $ vim CNAME # 输入你的域名 $ git add CNAME $ git commit -m &quot;add CNAME&quot; 在注册商那里添加解析就可以了 参考链接: - 令狐葱@前端笔记","categories":[{"name":"网站","slug":"网站","permalink":"https://www.delta1037.cn/categories/网站/"}],"tags":[{"name":"github","slug":"github","permalink":"https://www.delta1037.cn/tags/github/"},{"name":"hexo","slug":"hexo","permalink":"https://www.delta1037.cn/tags/hexo/"}]},{"title":"GTK+安装","slug":"gtk安装","date":"2017-08-08T11:10:07.000Z","updated":"2019-08-03T13:37:24.944Z","comments":true,"path":"2017/08/08/gtk安装/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/gtk安装/","excerpt":"","text":"新操作…系统Ubuntu17.04配置gcc等环境配置$ sudo apt-get install build-essential 安装GTK/GNOME开发环境$ sudo apt-get install gnome-devel gnome-devel-docs 安装pkg-config 用于编译时寻找头文件的位置$ sudo apt-get install pkg-config 安装devhelp GTK文档查看程序$ sudo apt-get install devhelp 安装gtk/glib的API参考手册和其它帮助文档$ sudo apt-get install libglib2.0-doc libgtk2.0-doc 安装基于GTK的界面$ sudo apt-get install glade libglade2-dev 安装gtk3.0$ sudo apt-get install libgtk3* 测试文件新建无后缀文件进行测试 #include &lt;gtk/gtk.h&gt; void hello(GtkWidget *widget,gpointer data) { g_print(&quot;Hello Ubuntu!\\n&quot;); } gint delete_event(GtkWidget *widget,GdkEvent *event,gpointer data) { g_print (&quot;delete event occurred\\n&quot;); return(TRUE); } void destroy(GtkWidget *widget,gpointer data) { gtk_main_quit(); } int main( int argc, char *argv[] ) { GtkWidget *window; GtkWidget *button; gtk_init (&amp;argc, &amp;argv); window=gtk_window_new (GTK_WINDOW_TOPLEVEL); gtk_signal_connect (GTK_OBJECT(window),&quot;delete_event&quot;,GTK_SIGNAL_FUNC(delete_event),NULL); gtk_signal_connect (GTK_OBJECT (window), &quot;destroy&quot;,GTK_SIGNAL_FUNC (destroy), NULL); gtk_container_set_border_width (GTK_CONTAINER (window), 10); button = gtk_button_new_with_label (&quot;Hello Ubuntu!&quot;); gtk_signal_connect (GTK_OBJECT (button), &quot;clicked&quot;,GTK_SIGNAL_FUNC (hello), NULL); gtk_signal_connect_object (GTK_OBJECT (button), &quot;clicked&quot;,GTK_SIGNAL_FUNC (gtk_widget_destroy),GTK_OBJECT (window)); gtk_container_add (GTK_CONTAINER (window), button); gtk_widget_show (button); gtk_widget_show (window); /*显示一个窗口*/ gtk_main(); /*进入主循环*/ return(0); } 编译对上述新建的文件进行编译 $ gcc -o gtktest gtktest.c &apos;pkg-config --cflags --libs gtk+-3.0&apos; #该处不是单引号而是倒引号 运行运行编译好的.c文件 $ ./gtktest 看到图形框即运行成功","categories":[{"name":"GTK+","slug":"GTK","permalink":"https://www.delta1037.cn/categories/GTK/"}],"tags":[{"name":"GTK+","slug":"GTK","permalink":"https://www.delta1037.cn/tags/GTK/"}]},{"title":"LAMP+WordPress搭建网站","slug":"lampmysqlnginxphp搭建网站","date":"2017-08-08T11:02:21.000Z","updated":"2019-08-03T13:37:25.212Z","comments":true,"path":"2017/08/08/lampmysqlnginxphp搭建网站/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/lampmysqlnginxphp搭建网站/","excerpt":"","text":"搭建LAMP（Linux, Apache, MySQL, PHP）环境安装Apachesudo apt-get update sudo apt-get install apache2 安装完成之后在浏览器页面输入http://your\\_server\\_IP_address 可以看到Apache的配置页面 安装数据库MySQLsudo apt-get install mysql-server php7.0-mysql 首先，我们要让MySQL创建它的存储信息的数据库目录结构，输入以下命令 sudo mysql_install_db 然后运行一个简单的安全脚本，它会移除一些危险的默认的配置 sudo mysql_secure_installation 它将会要求输入root密码，然后问是否想要修改密码，如果对现在的密码满意，就输入n或者no；对于剩下的问题，只需要enter键接受默认的配置就可以，这将会移除一些样例用户和数据库，使远程root登录不可用，并且加载这些新的规则来做出我们所做的更新 安装PHP安装 sudo apt-get install php7.0 libapache2-mod-php7.0 php7.0-mcrypt 更改dir.conf文件： sudo nano /etc/apache2/mods-enabled/dir.conf 更改前： &lt;IfModule mod_dir.c&gt; DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm &lt;/IfModule&gt; 更改后：&lt;其中只是移动了ingdex.php的位置&gt; &lt;IfModule mod_dir.c&gt; DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm &lt;/IfModule&gt; 重启Apache： sudo service apache2 restart 测试PHP模块：创建新的文件 sudo nano /var/www/html/info.php 输入文件内容 &lt;?php phpinfo(); ?&gt; 打开http://your\\_server\\_IP_address/info.php 查看测试结果 注意删除这个文件 sudo rm /var/www/html/info.php 安装Wordpress创建数据库用户登录数据库 mysql -u root -p 创建新的用户，用户名假设为Wordpress CREATE DATABASE wordpress; 创建一个数据库用户 CREATE USER wordpressuser@localhost IDENTIFIED BY &apos;password&apos;; 给这个用户新数据库的使用权 GRANT ALL PRIVILEGES ON wordpress.* TO wordpressuser@localhost; 使操作生效并退出 FLUSH PRIVILEGES; exit 下载WordPress并配置切换到～目录并获得WordPress的最新版本 cd ~ wget http://wordpress.org/latest.tar.gz 解压该文件 tar xzvf latest.tar.gz 下载一些安装包 sudo apt-get update sudo apt-get install php7.0-gd libssh2-php 复制一个配置文件的副本 cp wp-config-sample.php wp-config.php 获得安全秘钥 curl -s https://api.wordpress.org/secret-key/1.1/salt/ 会得到类似的输出&lt;警告：不要拷贝下面的！！&gt; define(&apos;AUTH_KEY&apos;, &apos;1jl/vqfs&lt;XhdXoAPz9 DO NOT COPY THESE VALUES c_j{iwqD^&lt;+c9.k&lt;J@4H&apos;); define(&apos;SECURE_AUTH_KEY&apos;, &apos;E2N-h2]Dcvp+aS/p7X DO NOT COPY THESE VALUES {Ka(f;rv?Pxf})CgLi-3&apos;); define(&apos;LOGGED_IN_KEY&apos;, &apos;W(50,{W^,OPB%PB&lt;JF DO NOT COPY THESE VALUES 2;y&amp;,2m%3]R6DUth[;88&apos;); define(&apos;NONCE_KEY&apos;, &apos;ll,4UC)7ua+8&lt;!4VM+ DO NOT COPY THESE VALUES #`DXF+[$atzM7 o^-C7g&apos;); define(&apos;AUTH_SALT&apos;, &apos;koMrurzOA+|L_lG}kf DO NOT COPY THESE VALUES 07VC*Lj*lD&amp;?3w!BT#-&apos;); define(&apos;SECURE_AUTH_SALT&apos;, &apos;p32*p,]z%LZ+7pAu:VY DO NOT COPY THESE VALUES C-?y+K0DK_+F|0h{!_xY&apos;); 4define(&apos;LOGGED_IN_SALT&apos;, &apos;i^/G2W7!-H2OQ+t$3 DO NOT COPY THESE VALUES t6**bRVFSD[Hi])-qS`|&apos;); define(&apos;NONCE_SALT&apos;, &apos;Q6]U:K?j4L%Z]}h^q7 DO NOT COPY THESE VALUES 1%^qUswWgn+6&amp;xqHN&amp;%&apos;); 打开配置文件 nano wp-config.php 将秘钥替换配置中类似的位置 找到关于 DB_NAME, DB_USER, 和 DB_PASSWORD 的设置，并填写相应的刚刚配置数据库的信息 // ** MySQL settings - You can get this info from your web host ** // /** The name of the database for WordPress */ define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); /** MySQL database username */ define(&apos;DB_USER&apos;, &apos;wordpressuser&apos;); /** MySQL database password */ define(&apos;DB_PASSWORD&apos;, &apos;password&apos;); 拷贝文件到根目录 sudo rsync -avP ~/wordpress/ /var/www/html/ 更改文件的权限 sudo chown -R demo:www-data * 创建上传目录并赋相应的权限 mkdir /var/www/html/wp-content/uploads sudo chown -R :www-data /var/www/html/wp-content/uploads 完成安装并查看网站并完成最后的配置 http://server_domain_name_or_IP 允许Apache使用固定连接功能编辑000-default.conf sudo nano /etc/apache2/sites-available/000-default.conf 做如下更改 &lt;VirtualHost *:80&gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html ServerName server_domain_name_or_IP &lt;Directory /var/www/html/&gt; AllowOverride All &lt;/Directory&gt; . . . 重新启动部件 //sudo a2enmod rewrite sudo service apache2 restart 创建.htaccess文件 touch /var/www/html/.htaccess 赋相应权限 sudo chown :www-data /var/www/html/.htaccess 如果想要Wordpress自动更新这个文件 chmod 664 /var/www/html/.htaccess If you want to update this file manually for the sake of a small security gain, you can allow the web server only read privileges by typing: chmod 644 /var/www/html/.htaccess 网站在不同vps之间的迁移VPS1上数据打包（备份）文件数据打包cd /home/wwwroot/ tar zcvf xxx.tar.gz 网站目录（如/home/wwwroot/vmvps.com） MySQL数据导出mysqldump -u用户名 -p密码 数据库名 &gt; xxx.sql VPS2上数据转移（恢复）文件数据恢复（wget获取远程文件）cd /home/wwwroot/ wget http://www.xxx.com/xxx.tar.gz（从VPS1上获取文件） tar zxvf xxx.tar.gz MySQL数据导入*请先在phpmyadmin新建相应数据库和用户（与原数据库、用户同名）&lt;若不同名则有可能出现数据库连接错误&gt; wget http://www.xxx.com/xxx.sql mysql -u你新建的用户名 -p用户名密码 你刚才新建的数据库名 &lt; xxx.sql 参考链接How To Install Wordpress on Ubuntu 14.04 How To Install Linux, Apache, MySQL, PHP (LAMP) stack on Ubuntu 14.04 VPS之间网站数据的备份与恢复（网站迁移教程）【微魔部落原创】","categories":[{"name":"网站","slug":"网站","permalink":"https://www.delta1037.cn/categories/网站/"}],"tags":[{"name":"网站","slug":"网站","permalink":"https://www.delta1037.cn/tags/网站/"}]},{"title":"算法导论笔记","slug":"动态规划","date":"2017-08-08T10:18:14.000Z","updated":"2019-08-03T13:37:26.728Z","comments":true,"path":"2017/08/08/动态规划/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/动态规划/","excerpt":"","text":"贪心算法贪心算法：每一步在当时看起来是最佳的选择，总是做出局部最优的选择 贪心算法并不保证得到最优解，但对于很多问题可以得到最优解 首先考虑用动态规划算法，然后证明一直做贪心的选择可以得到最优解，从而得到一个贪心算法 贪心算法步骤： 确定问题的最优子结构 将最优化问题转化为对其做出一次选择之后，只剩下一个子问题需要求解的形式 证明做出贪心选择之后，原问题总是存在最优解，即贪心选择总是安全的 证明做出贪心选择之后，剩余的子问题满足性质：最优解和贪心选择组合即可得到原问题的最优解，这样就得到了最优子结构 贪心算法进行选择时可能依赖之前做出的选择，但是不会依赖将来的选择或者是子问题的解 构造赫夫曼编码 0是转向左孩子，1是转向右孩子 每次总是合并频率最低的两个节点（贪心） 动态规划动态规划（dynamic programming/DP）中的programming指的是一种表格法，并非编写计算机程序 动态规划应用于子问题重叠的情况，即不同的子问题有公共的子子问题 设计动态规划： 1.刻画最优解的结构特征 2.递归地定义最优解的值 3.计算最优解的值（通常采用自底向上的方法） 4.利用计算出的信息构造一个最优解 朴素的递归算法由于反复求解相同的子问题而效率低下；动态规划对每个子问题只求解一次，，并将其保存下来，如果再次需要这个子问题的解，只需要查找保存的结果 动态规划两种等价的实现方法： 1.带备忘的自顶向下法 仍然按自然递归的形式编写过程，但是过程会保存每个子问题的解，当需要某个子问题的解时，会先进行查找是否有这个解，否则会计算这个解，并保存 2.自低向上法（按照逆拓扑排序，反序的拓扑排序）（自底向上表格法） 当求解某个子问题时，它所依赖的那些更小的子问题都已经求解完毕 动态规划的标识： 1.最优子结构 2.子问题重叠 剪切-粘贴：假定子问题的解不是其自身的最优解，那么我们可以剪切掉这些非最优解，将最优解粘贴进去，从而可以得到原问题的一个更优的解，这与原问题是最优解的假设是矛盾的 子问题无关：同一个原问题的一个子问题的解不影响另一个子问题的解 重叠子问题的性质：递归算法反复求解相同的子问题 如果每个子问题必须求解一次，自底向上动态规划算法会比自顶向下备忘算法快，因为自底向上算法没有递归调用的开销；如果子问题中的某些子问题不需要求解，自顶向下备忘算法就比较快 动态规划求解：找到状态转移方程和状态 图- 基本的图算法：两种图的表示方法： 邻接链表适用于稀疏图 邻接矩阵适用于稠密图 邻接链表无法迅速判断一条边是否是图中的一条边，邻接矩阵则可以，但是消耗了更多的内存空间 如果使用邻接链表来表示图，一种可能的方法是用额外的数组来表示节点属性 广度优先搜索：广度优先搜索树中两个节点的简单路径就是这两个节点间的最短路径 用队列来实现广度优先搜索 广度优先搜索将每个节点涂上黑色/灰色/白色，遇到白色节点为发现，对于灰色节点，该节点周围肯能存在尚未发现的节点，对于黑色节点，该节点周围所有的节点都已经被发现 队列里面的距离差值最大为一 对图进行广度优先搜索的过程中将创建一棵广度优先搜索树 深度优先搜索：深度优先搜索的前驱子图形成一个由多棵深度优先树构成的深度优先森林 若深度优先搜索中一个节点周围没有节点，则会回退到上一个节点，然后发现该节点周围的节点 发现时间和完成时间具有括号化结构（即嵌套）： 深度优先搜索在每个节点上面盖一个时间戳，一个是发现时间，第二个是搜索完成时间，对两个节点的时间戳，若重叠则必定是包含关系 边的分类： 树边/后向边/前向边/横向边 对无向图，从来不会出现前向边和横向边 拓扑排序： 拓扑排序是图中节点的一种线性排序，其次若图中有环路则无法排出一个线性次序 与深度优先搜索有关 强连通分量：深度优先搜索的应用：将有向图分解为强连通分量 将图分解成强连通分量之后，这些算法将运行在每个连通分量上，然后根据连通分量之间的结构将各个结果组合起来，从而得到最终结果 强连通分量就是将环收缩，形成一个有向无环图 寻找强连通分量，图和改图的转置的强连通分量完全相同 分量图是一个有向无环图 最小生成树最小生成树问题： 对于带有权重的图，找到一个无环子集，既能够将所有的节点连接起来，又使其具有最小的权重 两种最小生成树算法：（贪心算法） kruskal算法 prim算法 kruskal算法： 集合a是一个森林，每次加入到集合a中的安全边永远是权重最小的连接两个不同分量的边 prim算法： 集合a是一棵树，每次加入a中的安全边是连接a与a之外的某个节点的边权重最小的 使用一个最小优先队列，算法结束时，最小优先队列为空 单源最短路径单源最短路径的子路径也是最短路径 单源最短路径包含着其它的最短路径（最优子结构） 求解最短路径的图中不能包含权值为负值的环路 事实上，最短路径也不能包含权重为正值的环路（无效环路），只要删去该环路，就可以得到一个更短的路径 松弛： 维持节点的最短路径估计属性 过程：首先测试是否可以对两个节点的最短路径进行改善，测试方法是：将一个节点到中间节点加上中间节点到另一个节点的值与当前值进行比较，如果更小则更新节点的该属性值 Dijkstra算法和用于有向无环图的最短路径算法对每条边仅仅松弛一次，Bellman——Ford算法对每条边松弛节点数减一次 Bellman——Ford算法： Bellman——Ford算法通过对边进行松弛操作，来渐进的降低从源节点到每个节点的最短路径的估计值， 先对图进行拓扑排序。。降低时间复杂度 Dijkstra算法：（贪心算法） Dijkstra算法要求所有的边的权重是非负 Dijkstra算法在运行过程中维持的关键信息是一组节点集合，从源节点到该集合中的每个节点之间的最短路径都已经找到，使用一个最小优先队列来保存节点集合 二叉树二叉搜索树上所花费的时间与这棵树的高度成正比 区分树的高度和深度 二叉搜索树： 左子树中的关键字的值小于根节点中关键字的值，右子树中关键字的值大于根节点中关键字的值 二叉搜索树的遍历： 先序遍历 中序遍历 后序遍历 其中序是指根节点的位置 二叉搜索树的查找 迭代比递归更加高效 比较关键字的值，大于向右，小于向左 插入和删除： 插入类似于查找，即查找到一个空的合适的位置，将该节点插入 删除则分为三种情况 将删除的节点没有孩子节点，直接删除 将删除的节点只有一个孩子节点，将这个孩子提升到将删除节点的位置，并修改将删除节点的父节点， 将删除的节点有两个孩子节点，查找将要删除节点的后继，并让该后继占据将要删除的节点的位置，让将删除节点的右子树部分成为那个后继的新的右子树，并且将删除节点的左子树成为那个后继的新的左子树 红黑树： 红黑树保证没有一条路径会比其它路径长出两倍，是近似平衡的，平衡二叉树是绝对平衡的 红黑树性质： 每个节点是红色的或者是黑色的 根节点是黑色的 每个叶节点是黑色的 如果一个节点是红色的，那么它的两个子节点是黑色的 对于每个节点，从该节点到其所有后代叶节点的简单路径上，均包含数目相同的黑色节点数，成为黑高 红黑树的旋转： 左旋和右旋 左旋是靠左边的节点下滑，夺取右子树的左子树作为自己的右子树，同时自己从新成为右子树的左子树 右旋是靠右边的节点下滑，夺取左子树的右子树作为自己的左子树，同事自己从新成为左子树的右子树 红黑树的插入： 红黑树的性质2或者4被破坏 插入的节点首先着色为红色 为保持红黑树的性质，调用辅助程序对红黑树的节点重新着色并进行旋转 红黑树的删除： 删除节点之后，调用辅助程序通过改变颜色和执行旋转来恢复红黑树性质 如果删除的节点是红色，则不需要对树进行恢复","categories":[{"name":"算法导论","slug":"算法导论","permalink":"https://www.delta1037.cn/categories/算法导论/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.delta1037.cn/tags/算法/"}]},{"title":"shadowsocks服务器端客户端配置","slug":"shadowsocks服务器端客户端配置","date":"2017-08-08T03:49:57.000Z","updated":"2019-08-03T13:37:26.272Z","comments":true,"path":"2017/08/08/shadowsocks服务器端客户端配置/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/shadowsocks服务器端客户端配置/","excerpt":"","text":"VPS购买注册vpsDigtalOcean的最低价格为每月5$ 配置为:512M内存 单核CPU 20G存储 学生注册github的学生pack之后会得到一个50$的优惠码,另外如果邀请别人则被邀请人可得10$,当被邀请人用满25$时,邀请人可获得相同的$ 邀请链接 if you have a student code，please use this link careful！！！ 注册DigtalOcean之后才能输入优惠码,注册时必须支付5$,这5$在注册后可以使用,支付方式可选择信用卡或者PayPal支付,学生党的话没有信用卡就选择PayPal,里面有银联支付方式 新建Droplets注册完成之后,新建一个Droplets,系统默认是Ubuntu,然后选择合适的套餐,最低为5$,512M内存 单核CPU 20G存储的配置,选择服务器的位置,网上多数推荐San Francisco,然后添加ssh(可选)添加ssh链接最后点击create 新建Droplets之后打开,可以看到有ipv4地址,若已经添加了ssh,则可以使用以下命令登录 $ ssh root@你的ipv4地址 然后就可以看到自己的服务器界面 服务器端配置(均在服务器界面运行)使用以下命令在服务器端安装shadowsocks$ apt-get install python-pip $ pip install shadowsocks 服务器端的配置新建shadowsocks.json,并用vim编辑 $ vim /etc/shadowsocks.json 在shadowsocks.json中添加以下内容,注意”,”的位置,除ipv4地址和密码外其它内容无需修改 { &quot;server&quot;: &quot;my_server_ip&quot;, //服务器的ipv4地址 &quot;server_port&quot;: 8388, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;: 1080, &quot;password&quot;: &quot;mypassword&quot;, //设置一个密码,供给客户端连接 &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;, //加密方式 &quot;fast_open&quot;: false } 点击键盘上的ESC之后,输入”:wq”保存退出,或者输入”:wq!”强制保存退出 $ ssserver -c /path/to/shadowsocks.json -d start //启动 $ ssserver -c /path/to/shadowsocks.json -d restart //重启动 $ ssserver -c /path/to/shadowsocks.json -d stop //关闭 客户端配置使用以下命令同样在客户端安装shadowsocks$ apt-get install python-pip $ pip install shadowsocks 输入以下命令运行客户端,将ip和mypassword替换成你自己的就可以了 $ nohup sslocal -s ip -p 8388 -l 1080 -k &quot;mypassword&quot; -t 300 -m aes-256-cfb &amp; //nohup *** &amp; 后台运行 可以写一个脚本文件来保存这条命令在当前目录新建一个脚本文件 $ gedit 脚本文件名称.sh 将上述运行客户端命令添加到脚本文件中,在开头加上#!/bin/bash,表示是由bash执行的命令 使用以下命令执行该文件 $ bash /路径/脚本文件名称.sh 使用以下命令给该脚本权限 $ chmod a+x 脚本文件名称.sh 然后该脚本就可以以以下命令执行 $ ./脚本文件名称.sh \\#当前目录 浏览器配置(chrome)添加组件在扩展程序中选择开发者模式,并在Google商店中搜索Proxy SwitchyOmega插件并添加 配置打开Proxy SwitchyOmega插件,选择新建情景模式,名称可以自选,类型选择代理服务器 创建之后代理协议选择socks5,代理服务器填127.0.0.1,端口填1080 在自动切换中 规则列表设置中的规则列表格式选择AutoProxy,规则列表网址为规则列表网址 ,然后选择立即更新情景模式 保存更改选择应用选项以保存更改 然后就是正确的上网打开方式了…","categories":[{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://www.delta1037.cn/categories/shadowsocks/"}],"tags":[{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://www.delta1037.cn/tags/shadowsocks/"}]},{"title":"Git笔记","slug":"git笔记","date":"2017-08-08T03:48:28.000Z","updated":"2019-08-03T13:37:24.856Z","comments":true,"path":"2017/08/08/git笔记/","link":"","permalink":"https://www.delta1037.cn/2017/08/08/git笔记/","excerpt":"","text":"参考链接:阮一峰的网络日志 基本概念:工作区:电脑里能看到的目录 暂存区(索引):.git目录下的index文件 版本库:隐藏的目录.git 创建仓库#使用当前目录,初始化仓库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 配置# 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; 增加删除文件# 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 提交代码# 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 分支#列出所有本地分支 $ git branch #列出所有远程分支 $ git branch -r #列出所有本地分支和远程分支 $ git branch -a #新建一个分支，但依然停留在当前分支 $ git branch [branch-name] #新建一个分支，并切换到该分支 $ git checkout -b [branch] #新建一个分支，指向指定commit $ git branch [branch] [commit] #新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] #切换到指定分支，并更新工作区 $ git checkout [branch-name] #切换到上一个分支 $ git checkout - #建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] #合并指定分支到当前分支 $ git merge [branch] #选择一个commit，合并进当前分支 $ git cherry-pick [commit] #删除分支 $ git branch -d [branch-name] #删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 标签# 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 查看信息# 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat &quot;@{0 day ago}&quot; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 远程同步# 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all 撤销# 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 其它# 生成一个可供发布的压缩包 $ git archive emmm。。。$ git checkout . / git checkout--&lt;file&gt; #会用暂存区全部或者指定文件替换工作区的文件.危险操作! 会清除工作区中未添加到暂存区的活动 $ git checkout HEAD . / git checkout HEAD &lt;file&gt; #会用HEAD指向的master分支中的全部或者部分文件替换暂存区以及工作区中的文件. #**危险操作******! 不但会清除工作区中未提交的改动,也会清除暂存区中未提交的改动 Git服务器自己搭建一台Git服务器作为私有仓库使用 因吹斯听…have a try","categories":[{"name":"Git","slug":"Git","permalink":"https://www.delta1037.cn/categories/Git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.delta1037.cn/tags/git/"}]}]}